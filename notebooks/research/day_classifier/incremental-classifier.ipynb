{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental Deep Learning for Image Classification\n",
    "\n",
    "This notebook implements an incremental learning approach for image classification using deep learning. The idea is to train a deep learning model on a small dataset and then incrementally train the model on new data.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Setup and Imports](#setup)\n",
    "2. [Data Pipeline](#data-pipeline)\n",
    "3. [Model Architecture](#model-architecture)\n",
    "4. [Training Pipeline](#training)\n",
    "5. [Evaluation](#evaluation)\n",
    "6. [Results](#results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Imports <a id='setup'></a>\n",
    "\n",
    "Configures logging and import required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 12:53:14.521313: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-19 12:53:14.537031: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732042394.552316  305468 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732042394.555898  305468 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-19 12:53:14.567852: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Pipeline <a id='data-pipeline'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configures the data split object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataSplit:\n",
    "    train_paths: List[str]\n",
    "    val_paths: List[str]\n",
    "    test_paths: List[str]\n",
    "    class_mapping: Dict[str, int]\n",
    "    num_classes: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_path: str,\n",
    "        img_size: Tuple[int, int] = (224, 224),\n",
    "        val_split: float = 0.15,\n",
    "        test_split: float = 0.15,\n",
    "        random_seed: int = 42,\n",
    "    ):\n",
    "        self.data_dir = Path(base_path)\n",
    "        self.img_size = img_size\n",
    "        self.val_split = val_split\n",
    "        self.test_split = test_split\n",
    "\n",
    "        self.seed = random_seed\n",
    "        self.class_counts = self._get_class_counts()\n",
    "        self.sorted_classes = self._sort_classes_by_size()\n",
    "        self.class_mapping = self._create_class_mapping()\n",
    "\n",
    "    def _get_class_counts(self) -> Dict[str, int]:\n",
    "        \"\"\"\n",
    "        Counts the number of images in each class directory.\n",
    "        \"\"\"\n",
    "\n",
    "        class_counts: dict = {}\n",
    "        if not self.data_dir.exists():\n",
    "            raise ValueError(f\"Data directory {self.data_dir} does not exist.\")\n",
    "\n",
    "        for class_dir in self.data_dir.iterdir():\n",
    "            if class_dir.is_dir():\n",
    "                class_counts[class_dir.name] = len(list(class_dir.glob(\"*.jpg\")))\n",
    "\n",
    "        return class_counts\n",
    "\n",
    "    def _sort_classes_by_size(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Sorts the classes by the number of images in each class.\n",
    "\n",
    "        Returns:\n",
    "          List[str]: List of class names sorted by the number of images in each class.\n",
    "        \"\"\"\n",
    "\n",
    "        return sorted(\n",
    "            self.class_counts.keys(),\n",
    "            key=lambda x: (self.class_counts[x], int(x)),\n",
    "            reverse=True,\n",
    "        )\n",
    "\n",
    "    def _create_class_mapping(self) -> Dict[str, int]:\n",
    "        \"\"\"\n",
    "        Creates a mapping from class names to class indices.\n",
    "\n",
    "        Returns:\n",
    "          Dict[str, int]: Dictionary mapping class names to class indices.\n",
    "        \"\"\"\n",
    "\n",
    "        return {\n",
    "            class_name: idx\n",
    "            for idx, class_name in enumerate(\n",
    "                sorted(self.class_counts.keys(), key=lambda x: int(x))\n",
    "            )\n",
    "        }\n",
    "\n",
    "    def get_class_subset(self, num_classes: int) -> List[str]:\n",
    "        \"\"\"\n",
    "        Gets the top `num_classes` classes sorted by the number of images in each class.\n",
    "\n",
    "        Args:\n",
    "          num_classes (int): Number of classes to include in the dataset.\n",
    "\n",
    "        Returns:\n",
    "          List[str]: List of class names.\n",
    "        \"\"\"\n",
    "\n",
    "        if num_classes > len(self.sorted_classes):\n",
    "            raise ValueError(\n",
    "                f\"Requested {num_classes} classes, but only {len(self.sorted_classes)} available.\"\n",
    "            )\n",
    "\n",
    "        return self.sorted_classes[:num_classes]\n",
    "\n",
    "    def _collect_image_paths(self, classes: List[str]) -> Tuple[List[str], List[str]]:\n",
    "        \"\"\"\n",
    "        Collects all image paths and their corresponding labels for the\n",
    "        given classes.\n",
    "\n",
    "        Args:\n",
    "          classes (List[str]): List of class names to include in the dataset.\n",
    "\n",
    "        Returns:\n",
    "          Tuple[List[str], List[str]]: Tuple containing the image paths and their corresponding labels.\n",
    "        \"\"\"\n",
    "\n",
    "        image_paths, labels = [], []\n",
    "\n",
    "        for class_name in classes:\n",
    "            class_path = self.data_dir / class_name\n",
    "\n",
    "            if not class_path.exists():\n",
    "                logger.warning(f\"Class directory {class_path} does not exist.\")\n",
    "                continue\n",
    "\n",
    "            image_files = []\n",
    "            for ext in [\"*.jpg\"]:\n",
    "                image_files.extend(list(class_path.glob(ext)))\n",
    "\n",
    "            if not image_files:\n",
    "                logger.warning(f\"No images found in {class_path}\")\n",
    "                continue\n",
    "\n",
    "            image_paths.extend([str(img) for img in image_files])\n",
    "            labels.extend([class_name] * len(image_files))\n",
    "\n",
    "            logger.info(f\"Collected {len(image_files)} images for class {class_name}\")\n",
    "\n",
    "            if not image_paths:\n",
    "                raise ValueError(f\"No images found for classes {classes}\")\n",
    "\n",
    "        return image_paths, labels\n",
    "\n",
    "    def prepare_data_split(self, classes: List[str]) -> DataSplit:\n",
    "        \"\"\"\n",
    "        Prepares the data split for the given classes. It first\n",
    "        divides the data into train_val and test sets, and then\n",
    "        further divides the train_val set into train and validation\n",
    "\n",
    "        Args:\n",
    "            classes (List[str]): List of class names to include in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            DataSplit: DataSplit object containing the train, validation, and test splits.\n",
    "        \"\"\"\n",
    "\n",
    "        image_paths, labels = self._collect_image_paths(classes)\n",
    "        subset_mapping = {cls: self.class_mapping[cls] for cls in classes}\n",
    "\n",
    "        train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(\n",
    "            image_paths,\n",
    "            labels,\n",
    "            test_size=self.test_split,\n",
    "            stratify=labels,\n",
    "            random_state=self.seed,\n",
    "        )\n",
    "\n",
    "        train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "            train_val_paths,\n",
    "            train_val_labels,\n",
    "            test_size=self.val_split / (1 - self.test_split),\n",
    "            stratify=train_val_labels,\n",
    "            random_state=self.seed,\n",
    "        )\n",
    "\n",
    "        logger.info(\n",
    "            f\"Split sizes - Train: {len(train_paths)}, Val: {len(val_paths)}, Test: {len(test_paths)}\"\n",
    "        )\n",
    "\n",
    "        return DataSplit(\n",
    "            train_paths=train_val_paths,\n",
    "            val_paths=val_paths,\n",
    "            test_paths=test_paths,\n",
    "            class_mapping=subset_mapping,\n",
    "            num_classes=len(classes),\n",
    "        )\n",
    "\n",
    "    def plot_class_distribution(self, classes: Optional[List[str]] = None):\n",
    "        \"\"\"\n",
    "        Plots the class distribution for the given classes.\n",
    "\n",
    "        Args:\n",
    "            clases (Optional[List[str]]): List of class names to include in the plot.\n",
    "        \"\"\"\n",
    "\n",
    "        if classes is None:\n",
    "            classes = self.sorted_classes\n",
    "\n",
    "        counts = [self.class_counts[cls] for cls in classes]\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.bar(classes, counts)\n",
    "        plt.title(\"Class Distribution\")\n",
    "        plt.xlabel(\"Class\")\n",
    "        plt.ylabel(\"Number of Images\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, img_size: Tuple[int, int], batch_size: int = 32):\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = batch_size\n",
    "        self.train_datagen = self._create_train_datagen()\n",
    "        self.test_datagen = self._create_test_datagen()\n",
    "        self.label_to_index = None\n",
    "        self.num_classes = None\n",
    "\n",
    "    def _create_train_datagen(self) -> tf.keras.preprocessing.image.ImageDataGenerator:\n",
    "        \"\"\"\n",
    "        Creates the training data generator with data augmentation. The following augmentations are applied:\n",
    "        - Rotation\n",
    "        - Width and height shift\n",
    "        - Shear\n",
    "        - Zoom\n",
    "        - Horizontal and vertical flip\n",
    "        - Brightness\n",
    "\n",
    "        Returns:\n",
    "            tf.keras.preprocessing.image.ImageDataGenerator: Training data generator.\n",
    "        \"\"\"\n",
    "\n",
    "        return tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rotation_range=360,\n",
    "            width_shift_range=0.3,\n",
    "            height_shift_range=0.3,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            fill_mode=\"constant\",\n",
    "            brightness_range=(0.6, 1.4),\n",
    "            channel_shift_range=0.2,\n",
    "        )\n",
    "\n",
    "    def _create_test_datagen(self) -> tf.keras.preprocessing.image.ImageDataGenerator:\n",
    "        \"\"\"\n",
    "        Creates the test data generator with only the input preprocessing function.\n",
    "\n",
    "        Returns:\n",
    "            tf.keras.preprocessing.image.ImageDataGenerator: Test data generator\n",
    "        \"\"\"\n",
    "\n",
    "        return tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            preprocessing_function=self._preprocess_input,\n",
    "        )\n",
    "\n",
    "    def _preprocess_input(self, x):\n",
    "        \"\"\"\n",
    "        Preprocesses the input image by scaling pixel values to the range of [-1, 1].\n",
    "\n",
    "        Args:\n",
    "            x (np.ndarray): Input image.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Preprocessed image.\n",
    "        \"\"\"\n",
    "\n",
    "        x = tf.cast(x, tf.float32)\n",
    "\n",
    "        return tf.image.per_image_standardization(x)\n",
    "\n",
    "    def create_generators(self, data_split: DataSplit):\n",
    "        \"\"\"\n",
    "        Creates the generators for training, validation, and testing.\n",
    "\n",
    "        Args:\n",
    "            data_split (DataSplit): DataSplit object containing the train, validation, and test splits.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[tf.data.Dataset, tf.data.Dataset, tf.data.Dataset]: Tuple containing the training, validation, and test datasets.\n",
    "        \"\"\"\n",
    "\n",
    "        self.label_to_index = data_split.class_mapping\n",
    "        self.num_classes = data_split.num_classes\n",
    "\n",
    "        def create_df(paths: List[str]) -> pd.DataFrame:\n",
    "            return pd.DataFrame(\n",
    "                {\n",
    "                    \"filename\": paths,\n",
    "                    \"class\": [Path(p).parent.name for p in paths],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        train_df = create_df(data_split.train_paths)\n",
    "        val_df = create_df(data_split.val_paths)\n",
    "        test_df = create_df(data_split.test_paths)\n",
    "\n",
    "        logger.info(\n",
    "            f\"Training set class distribution:\\n{train_df['class'].value_counts()}\"\n",
    "        )\n",
    "\n",
    "        train_ds = self._create_dataset(train_df, is_training=True)\n",
    "        val_ds = self._create_dataset(val_df, is_training=False)\n",
    "        test_ds = self._create_dataset(test_df, is_training=False)\n",
    "\n",
    "        return train_ds, val_ds, test_ds\n",
    "\n",
    "    def _create_dataset(\n",
    "        self, df: pd.DataFrame, is_training: bool = False\n",
    "    ) -> tf.data.Dataset:\n",
    "        \"\"\"\n",
    "        Creates the tf.data.Dataset object from the given DataFrame.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing the image paths and their corresponding labels.\n",
    "            is_training (bool): Whether the dataset is for training or not.\n",
    "\n",
    "        Returns:\n",
    "            tf.data.Dataset: Dataset object.\n",
    "        \"\"\"\n",
    "\n",
    "        datagen = self.train_datagen if is_training else self.test_datagen\n",
    "        filenames = df[\"filename\"].values\n",
    "        labels = df[\"class\"].map(self.label_to_index).values\n",
    "\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "        dataset = dataset.map(self._parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "        dataset = dataset.batch(self.batch_size)\n",
    "\n",
    "        if is_training:\n",
    "            dataset = dataset.shuffle(\n",
    "                buffer_size=len(df), reshuffle_each_iteration=True\n",
    "            )\n",
    "\n",
    "        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        steps = len(df) // self.batch_size\n",
    "        if is_training:\n",
    "            self.steps_per_epoch = steps\n",
    "\n",
    "        else:\n",
    "            self.validation_steps = steps\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    @tf.function\n",
    "    def _parse_function(self, filename, label):\n",
    "        \"\"\"\n",
    "        Loads and preprocesses the image and its corresponding label.\n",
    "\n",
    "        Args:\n",
    "            filename (tf.Tensor): Image filename.\n",
    "            label (tf.Tensor): Image label.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[tf.Tensor, tf.Tensor]: Tuple containing the image and its label\n",
    "        \"\"\"\n",
    "\n",
    "        image = tf.io.read_file(filename)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, self.img_size)\n",
    "        label = tf.one_hot(label, self.num_classes)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def get_steps(self):\n",
    "        return self.steps_per_epoch, self.validation_steps\n",
    "\n",
    "    def get_num_classes(self):\n",
    "        return self.num_classes\n",
    "\n",
    "    def get_class_mapping(self):\n",
    "        return self.label_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Trained Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_size: Tuple[int, int] = (224, 224),\n",
    "        model_dir: str = \"models\",\n",
    "        initial_lr: float = 1e-4,\n",
    "    ):\n",
    "        self.img_size = img_size\n",
    "        self.model_dir = Path(model_dir)\n",
    "        self.model_dir.mkdir(exist_ok=True, parents=True)\n",
    "        self.initial_lr = initial_lr\n",
    "        self.model = None\n",
    "        self.base_model = None\n",
    "\n",
    "    def build_model(self, num_classes: int) -> tf.keras.Model:\n",
    "        if self.model is None:\n",
    "            self.base_model = tf.keras.applications.MobileNetV3Large(\n",
    "                weights=\"imagenet\", include_top=False, input_shape=(*self.img_size, 3)\n",
    "            )\n",
    "\n",
    "            self.base_model.trainable = False\n",
    "\n",
    "            inputs = tf.keras.Input(shape=(*self.img_size, 3))\n",
    "            x = tf.keras.applications.mobilenet_v3.preprocess_input(inputs)\n",
    "\n",
    "            x = self.base_model(x, training=False)\n",
    "            x1 = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "            x2 = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "            x = tf.keras.layers.Concatenate()([x1, x2])\n",
    "            x = tf.keras.layers.Dense(512, use_bias=False)(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "            x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "            x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "            x = tf.keras.layers.Dropout(0.3)(x)\n",
    "            outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "            self.model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "        self.current_classes = num_classes\n",
    "        self._compile_model(num_classes=num_classes)\n",
    "        return self.model\n",
    "\n",
    "    def _compile_model(self, num_classes):\n",
    "        optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=self.initial_lr, clipnorm=1.0\n",
    "        )\n",
    "\n",
    "        f1_score = tf.keras.metrics.F1Score(\n",
    "            average=\"macro\", threshold=None, name=\"f1_score\"\n",
    "        )\n",
    "\n",
    "        def sparse_f1_score(y_true, y_pred):\n",
    "            y_true_one_hot = tf.one_hot(tf.cast(y_true, tf.int32), num_classes)\n",
    "            return f1_score(y_true_one_hot, y_pred)\n",
    "\n",
    "        self.model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\", sparse_f1_score],\n",
    "        )\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        train_ds,\n",
    "        val_ds,\n",
    "        iteration: int,\n",
    "        epochs: int = 50,\n",
    "        class_weights: Optional[Dict] = None,\n",
    "    ) -> tf.keras.callbacks.History:\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                str(self.model_dir / f\"best_model_iter_{iteration}.keras\"),\n",
    "                monitor=\"val_accuracy\",\n",
    "                mode=\"max\",\n",
    "                save_best_only=True,\n",
    "                verbose=1,\n",
    "            ),\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_accuracy\",\n",
    "                patience=10,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1,\n",
    "            ),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-6, verbose=1\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        history = self.model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            class_weight=class_weights,\n",
    "        )\n",
    "\n",
    "        return history\n",
    "\n",
    "    def fine_tune(\n",
    "        self,\n",
    "        train_ds,\n",
    "        val_ds,\n",
    "        iteration: int,\n",
    "        num_layers_to_unfreeze: int = 75,\n",
    "        epochs: int = 30,\n",
    "        class_weights: Optional[Dict] = None,\n",
    "    ) -> tf.keras.callbacks.History:\n",
    "        self.load_best_model(iteration)\n",
    "        self.base_model.trainable = True\n",
    "\n",
    "        for layer in self.base_model.layers[:-num_layers_to_unfreeze]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        self.initial_lr = self.initial_lr * 0.1\n",
    "        self._compile_model()\n",
    "\n",
    "        return self.train(\n",
    "            train_ds,\n",
    "            val_ds,\n",
    "            iteration=f\"{iteration}_ft\",\n",
    "            epochs=epochs,\n",
    "            class_weights=class_weights,\n",
    "        )\n",
    "\n",
    "    def prepare_next_iteration(\n",
    "        self, previous_iteration: int, new_num_classes: int\n",
    "    ) -> None:\n",
    "        self.load_best_model(f\"{previous_iteration}_ft\")\n",
    "\n",
    "        old_weights = [layer.get_weights() for layer in self.model.layers[:-1]]\n",
    "        self.build_model(new_num_classes)\n",
    "\n",
    "        for layer, weights in zip(self.model.layers[:-1], old_weights):\n",
    "            if weights:\n",
    "                layer.set_weights(weights)\n",
    "\n",
    "    def load_best_model(self, iteration: str) -> None:\n",
    "        model_path = self.model_dir / f\"best_model_iter_{iteration}.keras\"\n",
    "        if not model_path.exists():\n",
    "            raise ValueError(f\"No saved model found for iteration {iteration}\")\n",
    "\n",
    "        self.model = tf.keras.models.load_model(str(model_path))\n",
    "        logger.info(f\"Loaded best model from iteration {iteration}\")\n",
    "\n",
    "    def save_iteration_info(self, iteration: int, metrics: Dict) -> None:\n",
    "        info = {\n",
    "            \"iteration\": iteration,\n",
    "            \"metrics\": metrics,\n",
    "            \"model_config\": self.model.get_config(),\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "        }\n",
    "\n",
    "        with open(self.model_dir / f\"iteration_{iteration}_info.json\", \"w\") as f:\n",
    "            json.dump(info, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_subplot(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history[\"accuracy\"], label=\"Training\")\n",
    "    plt.plot(history.history[\"val_accuracy\"], label=\"Validation\")\n",
    "    plt.title(\"Model Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history[\"loss\"], label=\"Training\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"Validation\")\n",
    "    plt.title(\"Model Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    def __init__(self, model_manager: ModelManager):\n",
    "        self.model_manager = model_manager\n",
    "        self.evaluation_history: Dict[int, Dict] = {}\n",
    "\n",
    "    def evaluate_iteration(\n",
    "        self,\n",
    "        iteration: int,\n",
    "        test_ds: tf.data.Dataset,\n",
    "        class_names: List[str],\n",
    "        plot: bool = True,\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Evaluates the model for a given iteration and stores the results.\n",
    "        \"\"\"\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "\n",
    "        for images, labels in test_ds:\n",
    "            predictions = self.model_manager.model.predict(images, verbose=0)\n",
    "            y_pred.extend(np.argmax(predictions, axis=1))\n",
    "            y_true.extend(np.argmax(labels, axis=1))\n",
    "\n",
    "        unique_labels = np.unique(y_true)\n",
    "        actual_class_names = [class_names[i] for i in unique_labels]\n",
    "\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        report = classification_report(\n",
    "            y_true, y_pred, target_names=actual_class_names, output_dict=True\n",
    "        )\n",
    "\n",
    "        results = {\n",
    "            \"confusion_matrix\": cm,\n",
    "            \"classification_report\": report,\n",
    "            \"class_names\": actual_class_names,\n",
    "        }\n",
    "        self.evaluation_history[iteration] = results\n",
    "\n",
    "        if plot:\n",
    "            self.plot_confusion_matrix(iteration)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def plot_confusion_matrix(\n",
    "        self, iteration: int, figsize: Tuple[int, int] = (20, 8), cmap: str = \"Blues\"\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Plots normalized and raw confusion matrices side by side.\n",
    "        \"\"\"\n",
    "        if iteration not in self.evaluation_history:\n",
    "            raise ValueError(f\"No evaluation data found for iteration {iteration}\")\n",
    "\n",
    "        results = self.evaluation_history[iteration]\n",
    "        cm = results[\"confusion_matrix\"]\n",
    "        class_names = results[\"class_names\"]\n",
    "\n",
    "        # Create figure with two subplots side by side\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "        # Plot normalized confusion matrix\n",
    "        cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "        sns.heatmap(\n",
    "            cm_normalized,\n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            cmap=cmap,\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names,\n",
    "            ax=ax1,\n",
    "        )\n",
    "        ax1.set_title(f\"Normalized Confusion Matrix - Iteration {iteration}\")\n",
    "        ax1.set_ylabel(\"True Label\")\n",
    "        ax1.set_xlabel(\"Predicted Label\")\n",
    "        plt.setp(ax1.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "\n",
    "        # Plot raw counts confusion matrix\n",
    "        sns.heatmap(\n",
    "            cm,\n",
    "            annot=True,\n",
    "            fmt=\"d\",\n",
    "            cmap=cmap,\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names,\n",
    "            ax=ax2,\n",
    "        )\n",
    "        ax2.set_title(f\"Raw Counts Confusion Matrix - Iteration {iteration}\")\n",
    "        ax2.set_ylabel(\"True Label\")\n",
    "        ax2.set_xlabel(\"Predicted Label\")\n",
    "        plt.setp(ax2.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def print_classification_report(self, iteration: int) -> None:\n",
    "        \"\"\"Prints the classification report for a given iteration.\"\"\"\n",
    "        if iteration not in self.evaluation_history:\n",
    "            raise ValueError(f\"No evaluation data found for iteration {iteration}\")\n",
    "\n",
    "        report = self.evaluation_history[iteration][\"classification_report\"]\n",
    "        print(f\"\\nClassification Report - Iteration {iteration}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        for class_name in report.keys():\n",
    "            if class_name in [\"accuracy\", \"macro avg\", \"weighted avg\"]:\n",
    "                continue\n",
    "            metrics = report[class_name]\n",
    "            print(\n",
    "                f\"{class_name::<15} Precision: {metrics['precision']:.3f}  \"\n",
    "                f\"Recall: {metrics['recall']:.3f}  \"\n",
    "                f\"F1-score: {metrics['f1-score']:.3f}\"\n",
    "            )\n",
    "\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"Accuracy: {report['accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_iterations_performance(evaluator, iterations=[1, 2]):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "\n",
    "    for iteration in iterations:\n",
    "        if iteration in evaluator.evaluation_history:\n",
    "            report = evaluator.evaluation_history[iteration][\"classification_report\"]\n",
    "            classes = evaluator.evaluation_history[iteration][\"class_names\"]\n",
    "\n",
    "            # Get F1 scores for each class\n",
    "            f1_scores = [report[cls][\"f1-score\"] for cls in classes]\n",
    "\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(\n",
    "                range(len(classes)),\n",
    "                f1_scores,\n",
    "                marker=\"o\",\n",
    "                label=f\"Iteration {iteration}\",\n",
    "            )\n",
    "            plt.xticks(range(len(classes)), classes, rotation=45)\n",
    "            plt.ylabel(\"F1 Score\")\n",
    "            plt.title(\"F1 Score by Class\")\n",
    "            plt.legend()\n",
    "\n",
    "            # Get accuracies\n",
    "            accuracies = [report[cls][\"precision\"] for cls in classes]\n",
    "\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(\n",
    "                range(len(classes)),\n",
    "                accuracies,\n",
    "                marker=\"o\",\n",
    "                label=f\"Iteration {iteration}\",\n",
    "            )\n",
    "            plt.xticks(range(len(classes)), classes, rotation=45)\n",
    "            plt.ylabel(\"Precision\")\n",
    "            plt.title(\"Precision by Class\")\n",
    "            plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_manager = DataManager(\n",
    "    base_path=\"../../../data/extended/day/\", img_size=(224, 224)\n",
    ")\n",
    "data_generator = DataGenerator(img_size=(224, 224), batch_size=32)\n",
    "model_manager = ModelManager(img_size=(224, 224), model_dir=\"saved_models\")\n",
    "evaluator = ModelEvaluator(model_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:matplotlib.category:Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "INFO:matplotlib.category:Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKAAAAJICAYAAABWnpxpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABlpUlEQVR4nO3deViU9f7/8dc9yOioIKKIW26oJIoetdxSUcsWFdPItFwy0dxaTuUxj2GlmVqZZOYSZqWkqeRyOqaV1clT54i/U2aLW4q7KWGGKCAgzO8Pv0ySWswttzfg83FdXSP3/Zl73vc7GIbXfO7PGG632y0AAAAAAADAIg67CwAAAAAAAEDpRgAFAAAAAAAASxFAAQAAAAAAwFIEUAAAAAAAALAUARQAAAAAAAAsRQAFAAAAAAAASxFAAQAAAAAAwFIEUAAAAAAAALAUARQAAAAAAAAsRQAFAACKpV27dunvf/+7unXrpvDwcLVs2VJ9+/bVwoULlZqa6hk3ePBgDR482L5CLyM0NNTzX5MmTXTjjTeqd+/eevrpp7Vt27aLxh85ckShoaFavXq1V4/zz3/+U2+//bZX97nUY82ZM0ehoaE6efKkV8f6I3v37tWcOXN05MiRi/ZNmDBB3bp1K7LHAgAAxVsZuwsAAAD4vZUrV2ry5MmqX7++oqOj1bBhQ507d04//PCDli9frm3btmnu3Ll2l/mnbrvtNg0bNkxut1tnzpzRnj17tHbtWq1YsUKDBw9WTEyMZ2y1atW0YsUK1alTx6vHWLdunfbs2aOhQ4cW+j5mH8tbe/fu1WuvvaY2bdqodu3aBfaNGTNGQ4YMsfTxAQBA8UEABQAAipVvvvlGzz77rDp06KB58+bJ6XR69t1000164IEH9MUXX9hYYeFVrVpVf/nLXzxfd+rUSffff78mTZqk+Ph4NWjQQPfdd58kyel0FhhrhdzcXOXm5l6Vx/ozVodfAACgeOESPAAAUKy8/vrrMgxDzz33XIHwKZ/T6dTNN9/8h8d47bXX1K9fP7Vp00atWrVS3759lZCQILfbXWDc5s2bNXjwYLVt21bNmzdXly5d9PDDDyszM9MzZtmyZerdu7datmypli1b6vbbb9esWbNMn5+Pj4+efvppVa5cWYsWLfJsv9RlcSdPntSkSZMUERGhZs2aqV27dhowYID++9//Sjp/+eHnn3+uo0ePFrjk78LjLVy4UPPmzfNcypiYmPiHl/sdP35cDz30kFq1aqXWrVtr3LhxF12WFxoaqjlz5lx0327dumnChAmSpNWrV+vRRx+VJA0ZMsRTW/5jXuoSvKysLL388svq1q2bmjVrpk6dOmny5MlKS0u76HFGjhypf//73+rbt6+aN2+u22+/Xe+9917h/icAAICrjhlQAACg2MjNzVViYqKaNm2qGjVqmD7O0aNH1b9/f9WsWVOStG3bNk2dOlXJycl66KGHJJ0PaEaOHKkbbrhBzz//vPz9/ZWcnKwvvvhCOTk5crlc+uCDDzR58mQNHjxYTz75pBwOhw4ePKi9e/de0XmWK1dOHTp00AcffKDjx4+revXqlxz3t7/9TTt27NBjjz2mevXqKS0tTTt27PCsgfXMM89o0qRJOnz4sF577bVLHiM+Pl716tXTk08+qYoVK6pu3bp/WNtDDz2k22+/XQMGDNDevXs1e/ZsJSUlaeXKlfL19S30OXbp0kWPP/64Zs2apaefflpNmzaVdPmZT263W2PGjFFiYqIefPBB3XDDDdq9e7fmzJmjbdu2acWKFQUCyV27dumFF17QiBEjVLVqVSUkJOipp55S3bp1deONNxa6TgAAcHUQQAEAgGLj119/VWZm5kXrBXlr+vTpnn/n5eWpTZs2crvdWrJkicaOHSvDMLR9+3ZlZWVp/Pjxuv766z3jIyMjPf/eunWr/P39C6zV1L59+yuqLV9+OPbzzz9fNoDaunWr+vXrp3vuucez7ZZbbvH8u2HDhvL39//DS+rKli2rRYsWFQiPLrUoeL7u3btr/PjxkqSOHTuqSpUqGjdunDZs2KDevXsX+vwCAwM9YVfDhg3/9JK/L7/8Ul9++aX+9re/afjw4ZLOX3JZvXp1PfbYY1q7dm2BPvz666969913PX288cYblZiYqH/+858EUAAAFENcggcAAEqdzZs3a+jQoWrdurWaNGmipk2b6tVXX1Vqaqp++eUXSVKTJk3k6+urSZMmac2aNTp8+PBFxwkPD1daWpoef/xxffLJJ0X6CXG/vxzwUpo3b641a9Zo3rx52rZtm3Jycrx+nG7dunk1c+nCAE6S7rjjDpUpU0Zbtmzx+rG9kZiYKEm66667Lnr88uXLa/PmzQW2N2nSxBM+SeeDtnr16umnn36ytE4AAGAOARQAACg2KleuLJfL9YczdP7Md999p+joaEnSc889p3fffVfvvfeeRo0aJUk6e/aspPOXgr399tuqUqWKpkyZoltuuUW33HKLFi9e7DlWnz59NG3aNP3000965JFH1KFDB/Xr10//+c9/ruAsz8sPSqpVq3bZMbGxserTp4/ee+899e/fX23atNH48eOVkpJS6McJCgryqq7fjy9TpowCAgI8l/1ZJTU1VWXKlFFgYGCB7YZhqGrVqhc9fkBAwEXHcDqdysrKsrBKAABgFgEUAAAoNnx8fNSuXTtt375dx48fN3WMDz74QGXKlNHrr7+uHj16qFWrVgoPD7/k2BtuuEELFizQV199pZUrV+ovf/mLpk2bpg8++MAzJioqSsuXL9dXX32l119/XW63WyNHjtTRo0dN1SedD8H++9//qk6dOpe9/E46fxnbU089pc8++0z/+te/9MQTT2jjxo2ehb4LwzAMr2r7fbh17tw5paamFgh8nE6nsrOzL7rvr7/+6tVjXSggIEDnzp27aJaZ2+3WiRMnVLlyZdPHBgAA9iOAAgAAxcrIkSPldrsVExNzyZAjJydHn3322WXvbxiGfHx85HD89jLn7Nmzev/99y97Hx8fH7Vo0ULPPPOMJGn79u0XjSlfvrwiIiI0atQo5eTkmF6IPDc3V1OmTFFqaqpGjBhR6PvVrFlTgwYNUocOHbRjxw7PdqfT6ZnVVRT++c9/Fvh6w4YNOnfunNq0aePZVqtWLe3evbvAuM2bNysjI6PAtvxFwwtTX/7aWr////TRRx8pIyOjyNbeAgAA9mARcgAAUKy0bNlSzz77rCZPnqyoqCgNGDBAjRo10rlz57Rjxw6tXLlSjRo1Urdu3S55/4iICL311lt64okn1L9/f6WmpmrRokUFPkFNkt59910lJiaqS5cuqlGjhrKysrRq1SpJUocOHSRJMTExKleunFq1aqWgoCClpKQoLi5Ofn5+l51VdaETJ05o27ZtcrvdSk9P1549e7R27Vrt2rVLQ4cOLbCo9u+dPn1aQ4YMUa9evdSgQQNVqFBB33//vb744gt1797dM65x48b6+OOPtWzZMjVr1kyGYRSqtsvZuHGjfHx8dNNNN2nPnj2aPXu2rr/+et1xxx2eMXfeeadmz56t2bNnq02bNtq7d6/eeecd+fn5FThWo0aNJEkrV65UhQoVVLZsWdWuXfuSs5luuukmdezYUTNnztSZM2fUqlUr7d69W6+++qrCwsJ05513mj4nAABgPwIoAABQ7Nxzzz1q3ry53n77bb3xxhtKSUmRr6+v6tWrp169emnQoEGXvW/79u01bdo0LVy4UKNGjVJwcLDuuecez+Vs+Zo0aaL//Oc/mjNnjlJSUlS+fHk1btxY8+fPV8eOHSWdv0Rv9erV2rBhg06dOqXKlSurdevWeuGFFy5aq+hSPvroI3300UdyOBwqX768atasqZYtW2ry5Ml/+qlwZcuWVfPmzfWPf/xDR48e1blz51SjRg2NGDHC8ylxkjRkyBDt2bNHsbGxOn36tNxu90Wzk7wxZ84czZkzR++++64Mw1C3bt00ceLEAgFedHS0zpw5ozVr1ujNN99U8+bNNXv2bI0ZM6bAsa677jpNnDhRS5Ys0ZAhQ5Sbm6vp06dftNC4dH7m2rx58zRnzhytXr1aCxYsUEBAgO688049/vjjFwWIAACgZDHchfkIFgAAAAAAAMAk1oACAAAAAACApQigAAAAAAAAYCkCKAAAAAAAAFiKAAoAAAAAAACWIoACAAAAAACApQigAAAAAAAAYKkydhdQ3H3zzTdyu93y9fW1uxQAAAAAAIBiIycnR4ZhqGXLln86lhlQf8LtdsvtdttdRonmdruVnZ1NH02gd+bQN3Pomzn0zRz6Zh69M4e+mUPfzKFv5tA3c+ibefTuynmTmTAD6k/kz3wKDw+3uZKSKyMjQzt37lTDhg1Vvnx5u8spUeidOfTNHPpmDn0zh76ZR+/MoW/m0Ddz6Js59M0c+mYevbty33//faHHMgMKAAAAAAAAliKAAgAAAAAAgKUIoAAAAAAAAGApAigAAAAAAABYigAKAAAAAAAAliKAAgAAAAAAgKUIoAAAAAAAAGApAigAAAAAAABYigAKAAAAAAAAliKAAgAAAAAAgKUIoAAAAAAAAGApAigAAAAAAABYigAKAAAAAAAAliKAAgAAAAAAgKUIoAAAAAAAAGApAigAAAAAAABYigAKAAAAAAAAliKAAgAAAAAAgKUIoAAAAAAAAGApAigAAAAAAABYigAKljMMQy6XS4Zh2F0KAAAAAACwQRm7C8DVk5fnlsNx9UMgl8ulsLCwq/64F7Lr3AEAAAAAAAHUNcXhMDRz6dc6knza7lKuqtrBfho3sLXdZQAAAAAAcM0igLrGHEk+raSjp+wuAwAAAAAAXENYAwoAAAAAAACWIoACAAAAAACApQigAAAAAAAAYCkCKAAAAAAAAFiKAAooxgzDkMvlkmEYdpcCAAAAAIBpfAoe8Cfy8txyOOwJgFwul8LCwmx5bMnecwcAAAAAlB4EUMCfcDgMzVz6tY4kn7a7lKuqdrCfxg1sbXcZAAAAAIBSgAAKKIQjyaeVdPSU3WUAAAAAAFAisQYUAAAAAAAALEUABQAAAAAAAEsRQAEAAAAAAMBSBFAAAAAAAACwFAEUAAAAAAAALEUABQAAAAAAAEsRQAEAAAAAAMBSBFAAAAAAAACwFAEUAAAAAAAALEUABQAAAAAAAEsRQAEAAAAAAMBSBFAAAAAAAACwFAEUAAAAAAAALEUABQAAAAAAAEsRQAEAAAAAAMBSBFAAAAAAAACwVLEJoBISEtS7d2+Fh4erffv2GjVqVIH9mzZtUp8+fRQeHq7u3btr6dKllzzOokWL1K1bN4WHhysqKkpbtmy5GuUDAAAAAADgMopFADVnzhzNmDFDkZGRWrRokaZMmaJq1ap59n/zzTcaM2aMwsLCtHDhQvXt21dTp05VQkJCgeMsWrRIsbGxGjhwoOLi4lS3bl2NGDFCu3fvvtqnBAAAAAAAgP9Txu4CkpKSNH/+fMXFxaljx46e7d27d/f8e+7cuQoLC9O0adMkSe3atdOxY8c0e/ZsRUVFyeFwKDs7W/Pnz9eQIUMUHR0tSWrTpo0iIyO1YMECxcbGXt0TAwAAAAAAgKRiMANq9erVuu666wqETxfKzs5WYmKievbsWWB7ZGSkUlJStGPHDknS1q1bdfr0afXq1cszxsfHRz169NCmTZvkdrutOwkAAAAAAABclu0B1LfffqvGjRtr7ty5at++vZo1a6ZBgwZp586dkqRDhw4pJydHDRo0KHC/hg0bSjo/g+rC29+PCwkJUXp6upKTk60+FQAAAAAAAFyC7ZfgpaSkaPv27dqzZ48mT54sX19fvfbaa3rggQf08ccf69SpU5Ikf3//AvfL/zp/f1pampxOp8qVK1dgXKVKlSRJqampql69uqka3W63MjIyTN23uDAMQy6Xy+4ybJWZmen1TDj6Zq5vdsvMzCxwi8Khb+bQN3Pom3n0zhz6Zg59M4e+mUPfzKFv5tG7K+d2u2UYRqHG2h5A5Yc7c+bMUaNGjSRJTZs21c0336wVK1aoVatWknTZE7pw+6XG5P/hXNiGXEpOTo5nRlZJ5XK5FBYWZncZttq/f7/XTyz0zVzfiosDBw7YXUKJRN/MoW/m0Dfz6J059M0c+mYOfTOHvplD38yjd1fG6XQWapztAVSlSpVUtWpVT/gkSdWqVVODBg20d+9ede3aVdJvM53ypaWlSfptJpS/v7+ysrKUlZWlsmXLXjQufyaUGb6+vp5L/kqqKwngSov69eubmgF1rTPTN7tlZmbqwIEDqlev3jU/g80b9M0c+mYOfTOP3plD38yhb+bQN3Pomzn0zTx6d+X27t1b6LG2B1AhISH66aefLtrudrvlcDhUp04d+fr6at++fercubNnf/5JhoSEFLhNSkoqMGMlKSlJFSpUUHBwsOkaDcNQ+fLlTd8fxQNPKOaU5L65XC5+dk2gb+bQN3Pom3n0zhz6Zg59M4e+mUPfzKFv5tE787yZtGH7IuRdunTRiRMn9OOPP3q2JScna9++fQoNDZXT6VS7du20YcOGAvdbt26dgoKCPGFTq1at5Ofnp/Xr13vG5ObmasOGDYqIiGAmCwAAAAAAgE1snwHVvXt3NW3aVA8//LAeffRROZ1OzZ07V4GBgbrnnnskSWPHjtWgQYMUExOjyMhIbd26VQkJCZoyZYocjvMZmtPp1OjRoxUbG6vAwECFhYUpISFBhw8f1qxZs+w8RQAAAAAAgGua7QGUj4+PFi5cqGnTpunpp5/WuXPndOONN+rll1/2TIFr2bKl5s2bp1mzZmnt2rWqXr26YmJi1K9fvwLHGjZsmNxut+Lj43XixAk1btxYcXFxCg0NtePUAAAAAAAAoGIQQElSlSpV9PLLL//hmIiICEVERPzhGMMwNHz4cA0fPrwoywMAAAAAAMAVsH0NKAAAAAAAAJRuBFAAAAAAAACwFAEUAAAAAAAALEUABQAAAAAAAEsRQAEodQzDkMvlkmEYdpcCAAAAAFAx+RQ8AKVPXp5bDoc9AZDL5VJYWJgtjy3Ze+4AAAAAUBwRQAGwhMNhaObSr3Uk+bTdpVxVtYP9NG5ga7vLAAAAAIBihQAKgGWOJJ9W0tFTdpcBAAAAALAZa0ABAAAAAADAUgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABLEUABAAAAAADAUgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABLEUABAAAAAADAUgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABLEUABAAAAAADAUgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABLEUABAAAAAADAUgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABLEUABAAAAAADAUgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABLEUABAAAAAADAUgRQAABJkmEYcrlcMgzD7lIAAAAAlDJl7C4AAFBQXp5bDsfVD4FcLpfCwsKu+uPms+u8AQAAAFiPAAoAihmHw9DMpV/rSPJpu0u5amoH+2ncwNZ2lwEAAADAIgRQAFAMHUk+raSjp+wuAwAAAACKBGtAAQAAAAAAwFIEUAAAAAAAALAUARQAAAAAAAAsRQAFAAAAAAAASxFAAQAAAAAAwFIEUAAAAAAAALAUARQAAAAAAAAsRQAFAAAAAAAASxFAAQAAAAAAwFIEUAAAAAAAALAUARQAAAAAAAAsRQAFAMAVMAxDLpdLhmHYXQoAAABQbJWxuwAAAIpCXp5bDsfVD4FcLpfCwsKu+uPms+u8AQAAAG8QQAEASgWHw9DMpV/rSPJpu0u5amoH+2ncwNZ2lwEAAAD8KQIoAECpcST5tJKOnrK7DAAAAAC/wxpQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABLEUABAAAAAADAUgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABL2R5ArV69WqGhoRf9N3PmzALjNm3apD59+ig8PFzdu3fX0qVLL3m8RYsWqVu3bgoPD1dUVJS2bNlyNU4DAAAAAAAAl1HG7gLyvfHGG/Lz8/N8HRwc7Pn3N998ozFjxujOO+/UhAkTtHXrVk2dOlVOp1P9+vXzjFu0aJFiY2P12GOPKSwsTAkJCRoxYoQSEhIUGhp6Vc8HAAAAAAAA5xWbAKpp06YKDAy85L65c+cqLCxM06ZNkyS1a9dOx44d0+zZsxUVFSWHw6Hs7GzNnz9fQ4YMUXR0tCSpTZs2ioyM1IIFCxQbG3vVzgUAAAAAAAC/sf0SvD+TnZ2txMRE9ezZs8D2yMhIpaSkaMeOHZKkrVu36vTp0+rVq5dnjI+Pj3r06KFNmzbJ7XZf1boBAAAAAABwXrEJoHr16qUmTZro5ptv1uuvv67c3FxJ0qFDh5STk6MGDRoUGN+wYUNJUlJSUoHb348LCQlRenq6kpOTrT4FAAAAAAAAXILtl+AFBQXp4YcfVosWLWQYhj777DO98sorSk5O1tNPP61Tp05Jkvz9/QvcL//r/P1paWlyOp0qV65cgXGVKlWSJKWmpqp69eqmanS73crIyDB13+LCMAy5XC67y7BVZmam1zPh6Bt9M8tM3yR6R9/MMds3O2VmZha4ReHRO3Pomzn0zRz6Zg59M4e+mUfvrpzb7ZZhGIUaa3sA1alTJ3Xq1MnzdceOHVW2bFktXrxYo0aN8my/3AlduP1SY/JfkBe2IZeSk5OjnTt3mr5/ceByuRQWFmZ3Gbbav3+/108s9I2+mWWmbxK9o2/mmO1bcXDgwAG7Syix6J059M0c+mYOfTOHvplD38yjd1fG6XQWapztAdSl3HHHHXrzzTe1c+dO1apVS9JvM53ypaWlSfptJpS/v7+ysrKUlZWlsmXLXjQufyaUGb6+vp5L/kqqKwngSov69eubmslzraNv5pjpm0Tv6Js5Zvtmp8zMTB04cED16tW7pmevmUHvzKFv5tA3c+ibOfTNHPpmHr27cnv37i302GIZQF2oTp068vX11b59+9S5c2fP9vyTDAkJKXCblJRU4F3wpKQkVahQQcHBwaZrMAxD5cuXN31/FA88oZhD38yhb+bQN3NKct9cLhe/Y02id+bQN3Pomzn0zRz6Zg59M4/emefNG8HFZhHyC61fv14+Pj4KCwuT0+lUu3bttGHDhgJj1q1bp6CgIE/Y1KpVK/n5+Wn9+vWeMbm5udqwYYMiIiKu+XfHAQAAAAAA7GL7DKjo6Gi1a9dOjRs3liR9+umnWrlypYYMGaKgoCBJ0tixYzVo0CDFxMQoMjJSW7duVUJCgqZMmSKH43yG5nQ6NXr0aMXGxiowMFBhYWFKSEjQ4cOHNWvWLNvODwAAAAAA4FpnewBVv359vffeezp+/Ljy8vJUr149TZw4UYMHD/aMadmypebNm6dZs2Zp7dq1ql69umJiYtSvX78Cxxo2bJjcbrfi4+N14sQJNW7cWHFxcQoNDb3apwUAAAAAAID/Y3sAFRMTU6hxERERioiI+MMxhmFo+PDhGj58eFGUBgAAAAAAgCJQLNeAAgAAAAAAQOlBAAUAAAAAAABLEUABAAAAAADAUgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABLEUABAAAAAADAUgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABLEUABAAAAAADAUgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABLEUABAAAAAADAUgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABLEUABAAAAAADAUgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABLEUABAAAAAADAUgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABLEUABAAAAAADAUgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABLEUABAAAAAADAUgRQAAAAAAAAsFQZb++QlZWlnJwcVaxY0bNt/fr12rFjh2666Sa1b9++SAsEAAAAAABAyeb1DKi//e1vmjp1qufrJUuW6PHHH9cbb7yhYcOGadOmTUVaIAAAAAAAAEo2rwOo77//Xp06dfJ8HR8fr969e+urr75S9+7dtWjRoiItEAAAAAAAACWb1wHUyZMnFRwcLEk6fPiwDh8+rEGDBqlixYq6++67tWfPniIvEgAAAAAAACWX1wFUuXLldPr0aUnS119/rfLlyys8PFySVLZsWWVkZBRthQAAAAAAACjRvF6EvHHjxlq6dKlq1qypZcuWqW3btjIMQ5J07NgxVa1atciLBAAAAAAAQMnl9QyoMWPG6H//+5/69OmjXbt2afjw4Z59n3/+uZo2bVqkBQIAAAAAAKBk83oGVPv27bV+/Xpt375dTZo00XXXXefZ165dOzVp0qRICwQAAAAAAEDJ5nUAJUm1atVSrVq1Lto+YMCAKy4IAAAAAAAApYvXl+BJUnZ2tpYvX67HH39cDzzwgA4cOCBJ+uSTT3T48OGirA8AAAAAAAAlnNczoE6ePKn7779fe/bsUdWqVfXLL78oPT1dkvTpp5/qyy+/1LPPPlvUdQIAAAAAAKCE8noG1EsvvaS0tDStWrVKn3/+udxut2df27Zt9b///a9ICwQAAAAAAEDJ5nUA9fnnn+uRRx5R06ZNZRhGgX3BwcE6fvx4kRUHAAAAAACAks/rAOrMmTOqWbPmJfedO3dOubm5V1wUAAAAAAAASg+vA6jatWtr27Ztl9z33XffqX79+ldaEwAAAAAAAEoRrwOoyMhILVy4UJ988oln/SfDMPTdd99pyZIluvPOO4u8SAAAAAAAAJRcXn8K3ogRI7R161Y99NBDqlSpkiQpOjpaqamp6tSpk4YMGVLkRQIAAAAAAKDk8jqA8vX11cKFC7V+/Xp9/vnn+uWXX1S5cmV16dJFPXv2lMPh9aQqAAAAAAAAlGJeB1DS+UvuevbsqZ49exZ1PQAAAAAAAChlmK4EAAAAAAAAS3k9A6pbt24yDOOS+xwOh/z8/BQeHq4hQ4YoJCTkigsEAAAAAABAyeb1DKg2bdrI7XYrOTlZtWrVUosWLVSzZk0lJycrNzdXNWrU0MaNGxUVFaXvv//eipoBAAAAAABQgngdQHXs2FFOp1MbN27UkiVLNGvWLMXHx+vjjz+W0+nULbfcoo8++kj16tXTnDlzrKgZAAAAAAAAJYjXAdSCBQv08MMPq0aNGgW216xZU2PHjlVcXJz8/Pw0dOhQbdu2rajqBAAAAAAAQAnldQB18OBBVaxY8ZL7/P39dfToUUlSrVq1lJmZeWXVAQAAAAAAoMTzOoCqWbOm1qxZc8l9q1at8syMSk1NVaVKla6sOgAAAAAAAJR4Xn8KXnR0tJ5++mkNGDBAt99+u6pWraoTJ07oww8/1LfffqspU6ZIkrZs2aJmzZoVecEAAAAAAAAoWbwOoO655x653W7NmTNHM2bM8GyvWrWqJk+erH79+kmSRo0aJafT6dWx09PTdccddyg5OVnvvfeewsPDPfs2bdqk2NhYJSUlqXr16ho6dKgGDhx40TEWLVqkpUuXKiUlRY0bN9b48ePVtm1bb08TAAAAAAAARcTrAEqS+vfvr3vuuUf79u1TamqqAgIC1KBBAxmG4RlTtWpVr487b9485ebmXrT9m2++0ZgxY3TnnXdqwoQJ2rp1q6ZOnSqn0+kJvKTz4VNsbKwee+wxhYWFKSEhQSNGjFBCQoJCQ0PNnCoAAAAAAACukNdrQOUzDEMhISFq3bq1QkJCCoRPZiQlJWnZsmV6+OGHL9o3d+5chYWFadq0aWrXrp3GjBmju+++W7Nnz1ZeXp4kKTs7W/Pnz9eQIUMUHR2t9u3b66WXXlLt2rW1YMGCK6oNAAAAAAAA5pmaASVJP/74o5KSkpSVlXXRvj59+nh9vOeff14DBgxQ/fr1C2zPzs5WYmKixo0bV2B7ZGSkVq5cqR07dqhZs2baunWrTp8+rV69ennG+Pj4qEePHnrzzTfldruvOCQDAAAAAACA97wOoDIzMzV69GglJibKMAy53W5JKhDueBtAffjhh9q1a5deffVVbd++vcC+Q4cOKScnRw0aNCiwvWHDhpLOz5xq1qyZkpKSJOmicSEhIUpPT1dycrKqV6/uVV0AAAAAAAC4cl4HUPPmzdPRo0f1zjvvaNCgQXrttddUoUIFvfvuu/rxxx/1yiuveHW8zMxMzZgxQ48//rgqVqx40f5Tp05Jkvz9/Qtsz/86f39aWpqcTqfKlStXYFylSpUkSampqaYDKLfbrYyMDFP3LS4Mw5DL5bK7DFtlZmZ6AtPCom/0zSwzfZPoHX0zx2zf7JSZmVngFoVH78yhb+bQN3Pomzn0zRz6Zh69u3LeXG3mdQD16aefasSIEWrZsqUkqUaNGmratKnat2+vJ554QsuWLdOUKVMKfbz58+erSpUquuuuu/5w3OVO6MLtlxpzqRla3srJydHOnTtN3784cLlcCgsLs7sMW+3fv9/rJxb6Rt/MMtM3id7RN3PM9q04OHDggN0llFj0zhz6Zg59M4e+mUPfzKFv5tG7K+N0Ogs1zusA6ujRo2rQoIF8fHxkGEaBF7yRkZF66qmnCh1AHT16VG+++abmzp2rM2fOSJJnplFGRobS09M9M5jyZzrlS0tLk/TbTCh/f39lZWUpKytLZcuWvWhc/nHM8PX19VzyV1Kx/pVUv359UzN5rnX0zRwzfZPoHX0zx2zf7JSZmakDBw6oXr161/TsNTPonTn0zRz6Zg59M4e+mUPfzKN3V27v3r2FHut1AOXn5+cJiapUqaKDBw/qhhtukCSdO3fOq0vVjhw5opycHD344IMX7RsyZIhatGihd955R76+vtq3b586d+7s2Z9/kiEhIQVuk5KSCrwLnpSUpAoVKig4ONjLM/2NYRgqX7686fujeOAJxRz6Zg59M4e+mVOS++ZyufgdaxK9M4e+mUPfzKFv5tA3c+ibefTOPG/eCPY6gAoNDdWBAwfUuXNntW3bVq+//rrq1q0rp9OpuXPn6vrrry/0sZo0aaIlS5YU2LZz505Nnz5dkydPVnh4uJxOp9q1a6cNGzZo6NChnnHr1q1TUFCQJ2xq1aqV/Pz8tH79es+23NxcbdiwQREREdf8u+MAAAAAAAB28TqAioqK0sGDByVJf/3rX3Xfffdp8ODBks5fBhcXF1foY/n7+6tt27aX3Ne0aVM1bdpUkjR27FgNGjRIMTExioyM1NatW5WQkKApU6bI4XBIOn/N4ejRoxUbG6vAwECFhYUpISFBhw8f1qxZs7w9TQAAAAAAABQRrwOoHj16eP593XXX6aOPPlJiYqIMw1DLli0VEBBQlPVJklq2bKl58+Zp1qxZWrt2rapXr66YmBj169evwLhhw4bJ7XYrPj5eJ06cUOPGjRUXF6fQ0NAirwkAAAAAAACF43UA9Xvly5dXt27diqIWSVLbtm21e/fui7ZHREQoIiLiD+9rGIaGDx+u4cOHF1k9AAAAAAAAuDKmA6j09HQdO3ZMWVlZF+3Lv3QOAAAAAAAA8DqAOnnypGJiYvSvf/3ron1ut1uGYWjnzp1FUhwAAAAAAABKPq8DqKefflqJiYkaMmSIQkJC5Ovra0VdAACgFDMMQy6Xi0+pBQAAuEZ4HUAlJiZqwoQJuueee6yoBwAAXEV5eW45HFc/BHK5XAoLC7vqj3shu84dAADgWuR1AOVyuVSzZk0ragEAAFeZw2Fo5tKvdST5tN2lXFW1g/00bmBru8sAAAC4ZngdQN1555368MMP1bFjRyvqAQAAV9mR5NNKOnrK7jIAAABQinkdQP31r3/VU089pbFjx6pLly6qVKnSRWNuvfXWIikOAAAAAAAAJZ/XAdSRI0f07bff6sCBA/r0008v2s+n4AEAAAAAAOBCXgdQkyZN0pkzZzRx4kQ+BQ8AAAAAAAB/yusA6rvvvtPzzz+vXr16WVEPAAAAAAAAShmHt3eoUqWK/Pz8rKgFAAAAAAAApZDXAdS9996rFStWWFELAAAAAAAASiGvL8FzOBzavXu3+vbtq86dOysgIKDAfsMwNHTo0CIqDwAAAAAAACWd1wHUSy+9JEk6evToJT/tjgAKAAAAAAAAF/I6gPr000+tqAMAAAAAAACllNcBVK1atayoAwAAAAAAAKWU14uQAwAAAAAAAN4o1AyoUaNGFfqAhmFo/vz5pgsCAAAAAABA6VKoAOrHH38s9AENwzBdDAAAAAAAAEqfQgVQn332mdV1AAAAAAAAoJRiDSgAAAAAAABYigAKAAAAAAAAliKAAgAAAAAAgKUIoAAAAAAAAGApAigAAAAAAABYqlAB1PTp03Xs2DFJ0k8//aScnBxLiwIAAAAAAEDpUagAavHixUpJSZEk3Xzzzdq5c6elRQEAAAAAAKD0KFQAValSJZ04cUKS5Ha7LS0IAAAAAAAApUuZwgxq0aKFnnrqKTVv3lyS9MILL8jPz++SYw3D0Pz584uuQgAAAAAAAJRohQqgnnnmGU2bNk179+6VYRg6ePCgnE7nJccahlGkBQIAAAAAAKBkK1QAVatWLc2dO1eSdP3112vevHme2VAAAAAAAADAHynUGlAXWrJkiUJCQqyoBQAAAAAAAKVQoWZAXahNmzaSpIMHDyoxMVGpqamqXLmy2rZtq7p16xZ5gQAAAAAAACjZvA6g3G63nnvuOS1fvlx5eXme7Q6HQ/fdd59iYmKKtEAAAAD8xjAMuVwu1t0EAAAlitcB1Ntvv61ly5bp3nvvVd++fRUcHKzk5GStXbtWy5YtU+3atTV06FALSgUAACge8vLccjjsCYBcLpfCwsJseWzJ3nMHAAAll9cBVEJCggYNGlRgplNwcLCaN28uh8OhlStXEkABAIBSzeEwNHPp1zqSfNruUq6q2sF+Gjewtd1lAACAEsjrAOrw4cPq2rXrJfd17dpVK1asuOKiAAAAirsjyaeVdPSU3WUAAACUCF5/Cp6fn59++umnS+776aefVLFixSsuCgAAAAAAAKWH1wFUhw4d9Morr+iHH34osH3nzp169dVX1bFjxyIrDgAAAAAAACWf15fgPfHEE+rfv7/69eunhg0bKigoSCkpKdq7d6+qVaumJ554woo6AQAAAAAAUEJ5PQOqRo0aWrt2rYYPHy6Xy6UjR47I5XLpwQcf1Jo1a1S9enUr6gQAAAAAAEAJ5fUMKEkKDAxkphMAAAAAAAAKxesZUAAAAAAAAIA3CKAAAAAAAABgKQIoAAAAAAAAWIoACgAAAAAAAJbyOoDKzs6W2+22ohYAAAAAAACUQl4FUFlZWWrRooU++eQTq+oBAAAAAABAKeNVAFW2bFkFBATI5XJZVQ8AAAAAAABKGa8vwevatas2btxoRS0AAAAAAAAohcp4e4eePXvqqaee0t///nfdeuutCgoKkmEYBcY0bdq0yAoEAAAAAABAyeZ1ABUdHS1JWrNmjdauXVtgn9vtlmEY2rlzZ5EUBwAAAAAAgJLP6wBq+vTpVtQBAAAAAACAUsrrAKpv375W1AEAAAAAAIBSyutFyC+0b98+ff3118rIyCiqegAAAAAAAFDKmAqg1q5dq86dO6tnz54aNGiQ9u/fL0l69NFHtXLlyiItEAAAAAAAACWb1wHUhg0bNGHCBIWFhWnSpElyu92efU2bNtWGDRuKtEAAAAAAAACUbF4HUHFxcbrrrru0YMEC9e/fv8C+Bg0aaO/evUVWHAAAAAAAAEo+rwOopKQk9ezZ85L7AgIClJqa6tXxvvjiCw0aNEjt2rVTs2bNdPPNN2v69Ok6ffp0gXGbNm1Snz59FB4eru7du2vp0qWXPN6iRYvUrVs3hYeHKyoqSlu2bPGqHgAAAAAAABQtrwMol8t1UTiULzk5WZUqVfLqeKdOnVLLli313HPPadGiRXrggQe0du1aPfroo54x33zzjcaMGaOwsDAtXLhQffv21dSpU5WQkFDgWIsWLVJsbKwGDhyouLg41a1bVyNGjNDu3bu9PU0AAAAAAAAUkTLe3qFly5ZaunSpbrvttov2rV69Wm3atPHqeL169VKvXr08X7dt21ZOp1OTJk1ScnKygoODNXfuXIWFhWnatGmSpHbt2unYsWOaPXu2oqKi5HA4lJ2drfnz52vIkCGKjo6WJLVp00aRkZFasGCBYmNjvT1VAAAAAAAAFAGvZ0CNHTtW27Zt09133634+HgZhqGPP/5Yo0aN0ldffaVRo0ZdcVEBAQGSpHPnzik7O1uJiYkXXfYXGRmplJQU7dixQ5K0detWnT59ukCY5ePjox49emjTpk0FFksHAAAAAADA1eN1ABUeHq6FCxcqIyNDM2bMkNvt1uuvv679+/crLi5OjRs3NlVIbm6usrKytH37ds2dO1ddu3ZVrVq1dOjQIeXk5KhBgwYFxjds2FDS+TWpLrz9/biQkBClp6crOTnZVF0AAAAAAAC4Ml5fgiedvwRuw4YNOnTokE6cOKHKlSurfv36V1RI165dPSFRp06dNGvWLEnn14iSJH9//wLj87/O35+Wlian06ly5coVGJe/JlVqaqqqV69uqja3262MjAxT9y0uDMOQy+WyuwxbZWZmej0Tjr7RN7PM9E2id/TNHPpmHs9x5pj9nrNTZmZmgVsUDn0zh76ZQ9/MoW/m0bsr53a7ZRhGocaaCqDy1alTR3Xq1LmSQ3jExcUpIyNDe/fu1bx58zRq1Ci99dZbnv2XO6ELt19qTP6Lo8I25FJycnK0c+dO0/cvDlwul8LCwuwuw1b79+/3+omFvtE3s8z0TaJ39M0c+mYez3HmmP2eKw4OHDhgdwklEn0zh76ZQ9/MoW/m0bsr43Q6CzXOVAB15MgRxcXFacuWLUpNTVVAQIDatm2rESNG6LrrrjNzSF1//fWSpFatWiksLExRUVHauHGj51K7/JlO+dLS0iT9NhPK399fWVlZysrKUtmyZS8a5+2n813I19fXU0dJdSUBXGlRv359U+9yX+vomzlm+ibRO/pmDn0zj+c4c8x+z9kpMzNTBw4cUL169a75GWzeoG/m0Ddz6Js59M08enfl9u7dW+ixXgdQO3fu1JAhQ5SZmamWLVuqadOmSklJ0erVq7V+/XrFx8erSZMm3h62gCZNmsjHx0eHDh1St27d5Ovrq3379qlz586eMfknGRISUuA2KSmpwLuSSUlJqlChgoKDg03XYxiGypcvb/r+KB54QjGHvplD38yhb+bQN/PonTkluW8ul4vXdSbQN3Pomzn0zRz6Zh69M8+bN+a8XoR82rRpCgwM1Mcff6z4+HjNmjVL8fHx+uijj1SlShVNmzbN20Ne5JtvvlFubq5q164tp9PpWXPqQuvWrVNQUJAnbGrVqpX8/Py0fv16z5jc3Fxt2LBBERERvFsJAAAAAABgE69nQH333Xd6/vnnVbNmzQLba9WqpYceekgxMTFeHe+hhx5Ss2bNFBoaqnLlymnXrl164403FBoaqltuuUWSNHbsWA0aNEgxMTGKjIzU1q1blZCQoClTpsjhOJ+hOZ1OjR49WrGxsQoMDFRYWJgSEhJ0+PBhz4LmAAAAAAAAuPq8DqD8/Pzk5+d3yX3+/v6qWLGiV8dr3ry51q9fr7i4OLndbtWqVUv33HOPoqOjPQtZtWzZUvPmzdOsWbO0du1aVa9eXTExMerXr1+BYw0bNkxut1vx8fE6ceKEGjdurLi4OIWGhnp7mgAAAAAAACgiXgdQvXr1UkJCgiIiIi7at3LlSvXs2dOr4z344IN68MEH/3RcRETEJR/zQoZhaPjw4Ro+fLhXNQAAAAAAAMA6hQqgPv74Y8+/mzZtqo8++kh33323evXqpapVq+rEiRNat26dTp48qdtvv92yYgEAAAAAAFDyFCqAeuSRR2QYhtxut+f22LFj+uGHHy4aO378eEVGRhZ5oQAAAAAAACiZChVALVmyxOo6AAAAAAAAUEoVKoBq06aN1XUAAAAAAACglHLYXQAAAAAAAABKN68/BU+SPvnkE73//vv66aeflJWVVWCfYRh6//33i6Q4AAAAAAAAlHxeB1BvvPGGZs6cqcDAQNWpU0cul8uKugAAAAAAAFBKeB1ALVu2TFFRUZoyZYp8fHysqAkAAAAAAACliNdrQKWmpqpXr16ETwAAAAAAACgUrwOoVq1aad++fVbUAgAAAAAAgFLI6wBq4sSJWrp0qT799FNlZ2dbURMAAAAAAABKEa/XgKpbt646dOighx56SIZhqFy5cgX2G4ahr7/+usgKBAAAAAAAQMnmdQD10ksv6Z133lGTJk3UoEEDOZ1OK+oCAAAAAABAKeF1ALVmzRqNGDFCTzzxhBX1AAAAAAAAoJTxeg2o3NxcdejQwYpaAAAAAAAAUAp5HUDddNNN+vbbb62oBQAAAAAAAKWQ15fgjRkzRo899phcLpe6dOmiSpUqXTQmICCgKGoDAAAAAABAKeB1AHXnnXdKkmbMmKEZM2ZccszOnTuvrCoAAAAAAACUGl4HUGPHjpVhGFbUAgAAAAAAgFLI6wDq4YcftqIOAAAAAAAAlFJeL0IOAAAAAAAAeMPrGVCvvfbaH+43DENjx441XRAAAAAAAABKFwIoAAAAAAAAWMrrAGrXrl0XbUtNTdUnn3yixYsXKy4urkgKAwAAAAAAQOlQJGtABQQE6O6771ZkZKSmTp1aFIcEAAAAAABAKVGki5CHh4dr8+bNRXlIAAAAAAAAlHBFGkDt3r1b5cuXL8pDAgAAAAAAoITzeg2otWvXXrQtOztbu3fv1qpVq9S7d++iqAsAAAAAAAClhNcB1IQJEy65vWzZsurdu7fGjx9/xUUBAAAAAACg9PA6gPr0008v2la2bFlVrVq1SAoCAAAAAABA6eJ1AFWrVi0r6gAAAAAAAEApVaSLkAMAAAAAAAC/V6gZUJGRkYU+oGEYev/9900XBAAAAAAAgNKlUAFUQEDAn47JyMjQ9u3bZRjGldYEAAAAAACAUqRQAVR8fPxl9507d04rVqzQvHnzZBiGevXqVWTFAQAAAEXBMAy5XC7eLAUAwCZeL0J+oQ0bNuiVV17RoUOH1KFDB40bN05NmjQpqtoAAABQiuTlueVw2BMAuVwuhYWF2fLYkr3nDgBAcWAqgNqyZYtmzpyp77//XmFhYXrzzTfVvn37oq4NAAAApYjDYWjm0q91JPm03aVcVbWD/TRuYGu7ywAAwFZeBVC7d+/WzJkz9eWXX6p27dp6+eWX1bNnT6tqAwAAQClzJPm0ko6esrsMAABwlRUqgDp27JheeeUVrVu3TpUqVdLEiRM1YMAA+fr6Wl0fAAAAAAAASrhCBVC33XabcnJy1KlTJw0fPlwVKlTQjz/+eNnxTZs2LbICAQAAAAAAULIVKoDKzs6WJP373//WF198cdlxbrdbhmFo586dRVMdAAAAAAAASrxCBVDTp0+3ug4AAAAAAACUUoUKoPr27Wt1HQAAAAAAACilHHYXAAAAAAAAgNKNAAoAAAAAAACWIoACAAAAAACApQigAAAAAAAAYCkCKAAAAAAAAFiKAAoAAAAAAACWIoACAAAAAACApQigAAAAAAAAYCkCKAAAAAAAAFiKAAoAAAAAAACWIoACAAAAAACApQigAAAAAAAAYCkCKAAAAAAAAFiKAAoAAAAAAACWIoACAAAAAACApQigAAAAAAAAYCnbA6gNGzZozJgxioiI0F/+8hdFRkZq2bJlysvLKzBu06ZN6tOnj8LDw9W9e3ctXbr0ksdbtGiRunXrpvDwcEVFRWnLli1X4zQAAACAUscwDLlcLhmGYXcpAIASzvYA6q233pLT6dT48eO1YMEC3XLLLXr++ef10ksvecZ88803GjNmjMLCwrRw4UL17dtXU6dOVUJCQoFjLVq0SLGxsRo4cKDi4uJUt25djRgxQrt3777apwUAAAAUmbw8ty2P63K5FBYWJpfLZcvj23XeAICiV8buAhYsWKDAwEDP1+3atVNGRoaWLl2qxx57TE6nU3PnzlVYWJimTZvmGXPs2DHNnj1bUVFRcjgcys7O1vz58zVkyBBFR0dLktq0aaPIyEgtWLBAsbGxtpwfAAAAcKUcDkMzl36tI8mn7S7lqqkd7KdxA1vbXQYAoIjYHkBdGD7la9KkibKyspSamqqAgAAlJiZq3LhxBcZERkZq5cqV2rFjh5o1a6atW7fq9OnT6tWrl2eMj4+PevTooTfffFNut5upwwAAACixjiSfVtLRU3aXAQCAKbZfgncpX3/9tQICAlSlShUdOnRIOTk5atCgQYExDRs2lCQlJSUVuP39uJCQEKWnpys5OfkqVA4AAAAAAIDfs30G1O99//33Wr16tcaOHSsfHx+dOnX+XR5/f/8C4/K/zt+flpYmp9OpcuXKFRhXqVIlSVJqaqqqV69uqia3262MjAxT9y0u8heQvJZlZmbK7fZuHQH6Rt/MMtM3id7RN3Pom3k8x5lD38zhZ9Ucs32zU2ZmZoFbFA59M4e+mUfvrpw3V5sVqwAqJSVFjzzyiMLDwzVixIgC+y53Qhduv9SY/F9WV3L5XU5Ojnbu3Gn6/sVB/gKS17L9+/d7/cRC3+ibWWb6JtE7+mYOfTOP5zhz6Js5/KyaY7ZvxcGBAwfsLqFEom/m0Dfz6N2VcTqdhRpXbAKo06dPa8SIESpXrpzmz58vX19fSb/NYMqf6ZQvLS1N0m8zofz9/ZWVlaWsrCyVLVv2onH5xzHD19fXc8lfScX6V1L9+vVNvVt7raNv5pjpm0Tv6Js59M08nuPMoW/m8LNqjtm+2SkzM1MHDhxQvXr1runZa96ib+bQN/Po3ZXbu3dvoccWiwAqKytLo0eP1okTJ7RixQpVrlzZs69OnTry9fXVvn371LlzZ8/2/JMMCQkpcJuUlFTgHaKkpCRVqFBBwcHBpuszDEPly5c3fX8UDzyhmEPfzKFv5tA3c+ibefTOHPpmDn0zpyT3zeVy8XeECfTNHPpmHr0zz5s3SWxfhPzcuXN69NFHtWvXLr3xxhuqVatWgf1Op1Pt2rXThg0bCmxft26dgoKCPGFTq1at5Ofnp/Xr13vG5ObmasOGDYqIiLjm3zkCAAAAAACwi+0zoKZMmaJ//etf+tvf/qazZ89q27Ztnn0NGzZUxYoVNXbsWA0aNEgxMTGKjIzU1q1blZCQoClTpsjhOJ+hOZ1OjR49WrGxsQoMDFRYWJgSEhJ0+PBhzZo1y6azAwAAAAAAgO0B1JdffilJeumlly7at2TJErVt21YtW7bUvHnzNGvWLK1du1bVq1dXTEyM+vXrV2D8sGHD5Ha7FR8frxMnTqhx48aKi4tTaGjoVTkXAAAAAAAAXMz2AOqzzz4r1LiIiAhFRET84RjDMDR8+HANHz68KEoDAAAAAABAEbB9DSgAAAAAAACUbgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABLEUABAAAAAADAUgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABLEUABAAAAAADAUgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABLEUABAAAAAADAUgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABLEUABAAAAAADAUgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABLEUABAAAAAADAUgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABLEUABAAAAQBEyDEMul0uGYdhdCgAUG2XsLgAAAAAArJCX55bDcfVDIJfLpbCwsKv+uPnsOm8A+CMEUAAAAABKJYfD0MylX+tI8mm7S7lqagf7adzA1naXAQAXIYACAAAAUGodST6tpKOn7C4DAK55rAEFAAAAAAAASxFAAQAAAAAAwFIEUAAAAAAAALAUARQAAAAAAAAsRQAFAAAAAAAASxFAAQAAAAAAwFIEUAAAAAAAALAUARQAAAAAAAAsRQAFAAAAAAAASxFAAQAAAAAAwFIEUAAAAAAAALAUARQAAAAAAAAsRQAFAAAAAAAASxFAAQAAAAAAwFIEUAAAAAAAALAUARQAAAAAAAAsRQAFAAAAAAAASxFAAQAAAAAAwFIEUAAAAAAAALAUARQAAAAAAAAsRQAFAAAAAAAASxFAAQAAAAAAwFIEUAAAAAAAALAUARQAAAAAAAAsRQAFAAAAAAAASxFAAQAAAAAAwFIEUAAAAAAAALAUARQAAAAAAAAsRQAFAAAAAAAASxFAAQAAAAAAwFK2B1AHDx7U008/rTvvvFNhYWHq1avXJcdt2rRJffr0UXh4uLp3766lS5dectyiRYvUrVs3hYeHKyoqSlu2bLGyfAAAAAAAAPwJ2wOoPXv2aNOmTapbt65CQkIuOeabb77RmDFjFBYWpoULF6pv376aOnWqEhISCoxbtGiRYmNjNXDgQMXFxalu3boaMWKEdu/efTVOBQAAAAAAAJdQxu4CunXrpltuuUWSNGHCBP3www8XjZk7d67CwsI0bdo0SVK7du107NgxzZ49W1FRUXI4HMrOztb8+fM1ZMgQRUdHS5LatGmjyMhILViwQLGxsVfvpAAAAAAAAOBh+wwoh+OPS8jOzlZiYqJ69uxZYHtkZKRSUlK0Y8cOSdLWrVt1+vTpApfw+fj4qEePHtq0aZPcbnfRFw8AAAAAAIA/ZXsA9WcOHTqknJwcNWjQoMD2hg0bSpKSkpIK3P5+XEhIiNLT05WcnHwVqgUAAAAAAMDv2X4J3p85deqUJMnf37/A9vyv8/enpaXJ6XSqXLlyBcZVqlRJkpSamqrq1aubqsHtdisjI8PUfYsLwzDkcrnsLsNWmZmZXs+Eo2/0zSwzfZPoHX0zh76Zx3OcOfTNHH5WzaFv5pjtm50yMzML3KJw6Jt59O7Kud1uGYZRqLHFPoDKd7kTunD7pcbkP+kWtiGXkpOTo507d5q+f3HgcrkUFhZmdxm22r9/v9dPLPSNvpllpm8SvaNv5tA383iOM4e+mcPPqjn0zRyzfSsODhw4YHcJJRJ9M4/eXRmn01moccU+gMqfwZQ/0ylfWlqapN9mQvn7+ysrK0tZWVkqW7bsRePyj2OGr6+v55K/kupKArjSon79+qberb3W0TdzzPRNonf0zRz6Zh7PcebQN3P4WTWHvpljtm92yszM1IEDB1SvXr1revaat+ibefTuyu3du7fQY4t9AFWnTh35+vpq37596ty5s2d7/kmGhIQUuE1KSirwTkdSUpIqVKig4OBg0zUYhqHy5cubvj+KB55QzKFv5tA3c+ibOfTNPHpnDn0zh76ZQ9/MKcl9c7lc/P1lAn0zj96Z503YX+wXIXc6nWrXrp02bNhQYPu6desUFBTkCZtatWolPz8/rV+/3jMmNzdXGzZsUERExDX/DggAAAAAAIBdbJ8BlZmZqU2bNkmSjh49qjNnzujDDz+UJLVp00aBgYEaO3asBg0apJiYGEVGRmrr1q1KSEjQlClT5HCcz9CcTqdGjx6t2NhYBQYGKiwsTAkJCTp8+LBmzZpl2/kBAAAAAABc62wPoH755Rc9+uijBbblf71kyRK1bdtWLVu21Lx58zRr1iytXbtW1atXV0xMjPr161fgfsOGDZPb7VZ8fLxOnDihxo0bKy4uTqGhoVftfAAAAAAAAFCQ7QFU7dq1tXv37j8dFxERoYiIiD8cYxiGhg8fruHDhxdVeQAAAAAAALhCxX4NKAAAAAAAAJRsBFAAAAAAAACwFAEUAAAAAAAALEUABQAAAAAAAEsRQAEAAAAAAMBSBFAAAAAAAACwFAEUAAAAAAAALEUABQAAAAAAAEsRQAEAAAAAAMBSBFAAAAAAAACwFAEUAAAAAAAALEUABQAAAAAAAEsRQAEAAAAAAMBSBFAAAAAAAACwFAEUAAAAAAAALEUABQAAAAAAAEsRQAEAAAAAbGcYhlwulwzDsLsUABYoY3cBAAAAAIDiIy/PLYfj6odALpdLYWFhV/1xL2TXuQPXAgIoAAAAAICHw2Fo5tKvdST5tN2lXFW1g/00bmBru8sASi0CKAAAAABAAUeSTyvp6Cm7ywBQirAGFAAAAAAAACxFAAUAAAAAAABLEUABAAAAAADAUgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABLEUABAAAAAADAUgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABLEUABAAAAAADAUgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAAABLEUABAAAAAADAUgRQAAAAAAAAsBQBFAAAAAAAACxFAAUAAAAAQAllGIZcLpcMw7C7FOAPlbG7AAAAAAAASrq8PLccjqsfArlcLoWFhV31x72QXeeOkoUACgAAAACAK+RwGJq59GsdST5tdylXVe1gP40b2NruMlACEEABAAAAAFAEjiSfVtLRU3aXARRLrAEFAAAAAAAASxFAAQAAAAAAwFIEUAAAAAAAALAUARQAAAAAAAAsRQAFAAAAAAAASxFAAQAAAAAAwFIEUAAAAAAAALAUARQAAAAAAAAsRQAFAAAAAAAASxFAAQAAAAAAwFIEUAAAAAAAALAUARQAAAAAAAAsRQAFAAAAAAAASxFAAQAAAAAAwFIEUAAAAAAAALAUARQAAAAAAAAsRQAFAAAAAAAASxFAAQAAAAAAwFKlLoDav3+/oqOj9Ze//EXt27fX1KlTdfbsWbvLAgAAAAAAuGaVsbuAopSWlqb7779fNWvW1KuvvqqTJ09q+vTpSk1N1cyZM+0uDwAAAAAAFBOGYcjlcskwDLtLuSaUqgBq+fLlSktL09q1axUYGChJ8vHx0bhx4zR69GiFhITYXCEAAAAAAMiXl+eWw2FPAORyuRQWFmbLY0v2nrsdSlUA9e9//1vt27f3hE+SdNttt2nixInatGkTARQAAAAAAMWIw2Fo5tKvdST5tN2lXFW1g/00bmBru8u4qkpVAJWUlKSoqKgC25xOp+rUqaOkpCSbqgIAAAAAAJdzJPm0ko6esrsMWMxwu91uu4soKk2bNtWjjz6qBx98sMD2e++9V1WqVNFrr73m9TG3bt0qt9stX1/foirTNoZh6NSZbJ3LzbO7lKuqjI9DlSo6ZfZbnb7RN29cad+ka7N39M0c+mYez3Hm0Ddz+Fk1h76ZQ9/M4znOHPpmTlH8rBYHOTk5MgxDrVq1+tOxpWoG1OW43W7Ti4rl36+0LEpWqaLT7hJscyX/D+mbOfTNvGu1d/TNHPpmHs9x5tA3c/hZNYe+mUPfzOM5zhz6Zk5JzxoMwyj0OZSqAMrf319paWkXbT99+rTp9Z9atmx5pWUBAAAAAABc0xx2F1CUQkJCLlrrKTs7W4cOHWIBcgAAAAAAAJuUqgCqc+fOSkxM1K+//urZtnHjRmVnZysiIsLGygAAAAAAAK5dpWoR8rS0NPXq1Uu1atXSmDFj9Msvv2jGjBnq2LGjZs6caXd5AAAAAAAA16RSFUBJ0v79+zV16lR9/fXXKleunHr16qVx48apXLlydpcGAAAAAABwTSp1ARQAAAAAAACKl1K1BhQAAAAAAACKHwIoAAAAAAAAWIoACgAAAAAAAJYigAIAAAAAAIClCKAAAAAAAABgKQIoAAAAAAAAWIoACgAAAAAAAJYigIIl3G633SWUWPTOe9nZ2Tpz5ozdZZRYfM95Ly8vz+4ScA3Jzs7Wjz/+aHcZuMbwPGcOfQOAyyOAQpE7c+aMXn75ZR05csTuUkqU3Nxc5eTk6MSJE3aXUqJkZGQoMjJSL774otLS0uwup0Q6e/as3SWUKOnp6YqJidHGjRvtLqXEys3NtbuEEiM9PV19+/bV66+/bncpJUpOTo5+/vlngjsTcnNzlZeXp/T0dLtLKVHyg6fs7GybKyk9eIMMKH3K2F0ASpczZ87o9ttvV1hYmAICAuwup8RIT0/XtGnT9OOPP+rnn39WVFSUHnnkEbvLKhH+97//6eDBgzp48KDcbreefPJJVaxY0e6yir2MjAwtXLhQu3btUmZmprp3766BAwfaXVaxd+bMGd1zzz3y9/dX7dq11bVrV5Upw6/SwsjIyNCnn36qyMhI+fj4KC8vTw4H74P9kTNnzigqKkpHjx7VoUOH9OWXX6pjx452l1Xspaen64knntD+/ft18OBB9ejRQ2PHjlVISIjdpRV7Z86c0TPPPKPDhw/r7Nmz6tSpk/r27auGDRvaXVqxlp6erhdeeEH79++Xj4+POnTooL59+yooKMju0kqUnJwcJScnq0yZMqpQoYL8/PzsLqlEcLvdMgzD7jJKpLy8PGVlZens2bNyuVwqV64cr08sxqtmFJkzZ87ozjvvVKNGjTRlyhRCgEI6c+aM7r77blWtWlUtW7ZUXl6e5s2bpzJlymjMmDF2l1fsXX/99WrdurVuuukmLVy4ULm5uZo4cSLff38gPT1d/fv3V8WKFVWlShX5+Pjoueee04kTJ/Too4/aXV6xde7cOY0bN05BQUGaPn26qlWrRvhUSJmZmbrvvvu0a9cupaSkaNiwYXI4HLzI+wNnzpxR7969Va9ePU2cOFFPPfWUNm7cqPbt28swDPp2GRkZGRowYICqVaumwYMHy+l06qWXXlK5cuU0bdo0u8sr1jIzM9W/f39VrVpVN954o9xut5YtW6YvvvhC/fv3502Ky8jIyFBUVJQCAgJUv359ud1uvfLKK/r000/1wAMP6Pbbb7e7xBLhzJkzGjt2rJKTk3Xq1ClVrVpVDz/8sDp16iSXy2V3ecVWRkaG3nzzTd12221q1KiR3eWUKOnp6Zo8ebIOHjyo48ePq0WLFnr44YfVqFEjQj0L8coZRSL/Mqj88KlatWqSpFOnTsnHx0fp6ekKDg62ucriJysrS6NHj1aNGjU0ZcoUXXfddZLOvwO0efNmAqhCqFKlitLS0mQYhp599lk99dRTcjgcGj9+vPz9/e0ur9jJzs7WuHHjFBwcrGeeeUZ16tRRWlqaFi1apLfeektdunRRixYt7C6zWDp58qSOHz+uUaNGqWbNmpKkH3/8Ub/88ouys7PVokULZn5ewrlz5/Tiiy/q559/VsuWLbV48WLl5uZqxIgRhFCXkR8+1alTRy+88IKCgoLUp08fvfPOO4qOjladOnV4cXwZ8fHxMgxDkyZNUr169SSdD1YWL16s7OxsOZ1OewssxjZu3KisrCw9++yzql+/viRp0KBBevLJJxUfH69Tp07xuuQS4uPj5XA4NH36dE/fevfurb/+9a968cUXderUKfXv39/mKou37OxsDRkyRP7+/nr88cf1yy+/KDExUY8++qgGDx6sgQMHqm7dunaXWeycPXtWgwYN0o4dO5ScnKxhw4Z5vgfxx9LT0zVgwAD5+/urc+fOOnnypDZv3qwJEybotddeU40aNewusdTiFR+KxNq1a3Xs2DE1a9ZM1atXl8Ph0KZNm/TYY48pMjJS9957r2bOnKnk5GS7Sy1WEhMTJUlDhw5V7dq1PdurVaumatWq6eOPP9b777+vn376ya4Si7W8vDyVKVNGN998s2cG3tNPP61//OMfmjlzprKzsxUbG6tdu3bZXWqxkZiYqOPHj+uee+7xfM/5+/ura9euMgxDR48etbnC4is9PV0nT55UgwYNJEnr16/X4MGD9dhjj2nkyJG6//779c4779hcZfFz+PBhbd68WZ07d9bTTz+ttm3bKj4+XgsXLpQkTwiF8/Ly8jR69GjVqVNHL774oqpWrSpJioyMVKVKlTR37lxlZ2cTPl1GUlKSXC6X6tWr51k/Jv+S2TVr1ujtt9/Wd999Z3OVxdPPP/+s3Nxczx+w2dnZqlmzpmbNmqXGjRvr/fffV3x8vM1VFj8HDhxQxYoVPX3Lzc1Vhw4d9Pe//13Hjh3TihUrtH79epurLN527dql9PR0Pfroo7r11lt17733atasWZo4caKWLFmiefPm6eDBg3aXWazk5eVp/vz5Sk1NVZcuXfTJJ58oLi5O+/fvt7u0Yi8nJ0fPPPOMAgMD9eKLL2rs2LGaNGmSHnjgAR05ckQ//PCDJNYgswoBFIpEz549NWzYMM2bN0+rVq3S5s2bNWrUKFWoUEHdu3dXx44dtXjxYj377LP65Zdf7C632GjRooUGDBjguaRCOv9O7fvvv6+vvvpK06ZNU0xMjB566CH95z//sbna4id/1kTjxo21bt06nTx5Ur1799Zzzz2nNWvW6I477tDy5ctZEPQCtWvXVsWKFXXTTTfJ4XB4frn+5S9/Ua1atfTtt99KYpHoS6lQoYIyMzP13Xff6ddff9XkyZM1ZMgQLVy4UOvWrZO/v7/effddrVixwu5Si5UaNWooOjpaEyZMUJMmTTRixAjdeOONF4VQfM+d53A4NG3aNM2aNUvVqlXz/G5o3LixbrzxRiUmJnrelCC4u1jt2rV18OBBfffddzIMQ2lpaXrjjTe0f/9+rVy5Uq+99pqefPJJrVq1yu5Si51GjRrp559/1ubNmyVJTqdT586dU1BQkCZNmqQaNWpo5cqV2r59u82VFi/16tXTiRMndOjQIUmSj4+PJKl69eqqWLGiTp48qZUrVyojI8POMou1U6dO6eDBg56Z63l5efLx8dHgwYM1Y8YM/eMf/9CSJUv4xOMLpKSkaM+ePWrSpIkWLFig4cOH61//+hchVCHs3r1b/+///T/17NlTtWrV8mzv16+fAgMD9a9//UuSeKPHIgRQKBKVKlXSmDFjNHToUD311FMaOXKkHnvsMU2bNk0TJ07U5MmT9dprr2nTpk1aunSp3eUWGwEBAerRo4ecTqfy8vKUm5urvn37yt/fX3PmzNE//vEPrVmzRsnJyVq8eLHd5RZLbrdbzZo1k7+/v9LS0lSuXDn17t1boaGhOnbsmMLDw5mOfIEGDRooLi5OFStWVF5engzD8IRQLpfL84l4+S+g8Ztq1arprrvu0vLly7V06VI1bNhQAwYMUHh4uBo2bKiZM2fK399fq1at0rlz5+wut9goV66c7r77bgUEBOjcuXNq1KiRxowZc1EIlb8wOaGKdN111ykwMNDzdf7P6qOPPqrMzEzPTDsuXbxYVFSUatWqpeHDh2v48OHq0aOHypUrp8WLF2vVqlXasGGDypcvr6VLl/LH7O+0aNFC4eHhevfddz1hSpkyZTwh1LRp03Ts2DHCu9/p3r270tPTtXz58gKziA3DUJMmTTR9+nRt3bpV//znP22ssnirV6+errvuOn3yySfKysoqMDO2T58+mjRpkpYuXeoJBpiZIgUHB6tPnz6aOnWqJCk6OloPPPDARSEUvbpYaGiobrzxRnXq1MmzLf/7rWHDhvr5558LbEPR4pULikzFihX10EMPaeTIkerevbtuv/12z6dX5ObmqlOnTrrtttv0ySefKDU1lSfE/5OfrjscDvn4+GjAgAF69dVX1bx5c1WqVEkhISGaOHGivvjiC+3Zs4e+/Y5hGKpTp45cLpc++ugjSdLjjz+uw4cPa8iQIfr666/1zDPP8IfGBfIX88z/4zX/F2zFihWVlZXlGXfmzBmtW7eOS2cvcO+99yonJ0erV69WVlaWqlSpIun8em7BwcGaMGGCvvvuO2YI/E7+81z+ou0hISEFQqg33nhDknTs2DGtXLlSJ0+etK3W4ij/Z7Vq1aq69dZbtXHjRs8lAiioVq1amjdvnp544gn17t1b1atX1+jRo9WgQQPl5uYqKChIzzzzjHbs2KHvv//e7nKLlYCAAE2cOFFffvmlli9f7nnuL1OmjLKzs1WjRg2NGjVKmzZt0s8//8zrkf/ToEEDvfrqq1q6dKlmzJihpUuXas2aNXrooYdUu3ZttW/fXn369NGBAwfsLrXYyZ/5et111yk0NFQrVqzQjz/+KKng5dkDBw7UnXfeqdjYWJ08efKan5mSk5MjSbr11ltVuXJlz0z/kSNHFgihkpKSPL3KH3OthyrZ2dny9fXVSy+9pBo1anj6kd+nkJAQpaamSvqtV/nPddd674oKARSKVMWKFRUdHa0RI0aoTp06ks7/0JYpU0YOh0OGYahMmTKqVKnSNf/L4/fyn9yGDh160cJ3x44dU506dVSzZk369jv5vwxat26to0ePaty4cdq8ebNeeeUVPfbYYxo/fry2bNnC1Pc/kD/bqUKFCvr1118lSadPn9a0adM0btw4/si4QL169fTcc88pJSVFP/zwgzZu3ChJKlu2rCQpNTVVVatW5VMYCyEkJESjR49WmzZttGTJEs2aNUsvvPCCnn32Wc+LaxTkcrnUp08f/fzzz/rvf/8riRfElxIcHKz+/furffv22rdvn3x9fSX9NssuJSVFVatWLTDLDOc1b95cc+fO1Ztvvqn4+HgdPnxYkjyLtzscDpUpU0YVK1bk9cgF2rZtq7ffflsnT57UzJkz9cILL6h379569tlnJUnHjx9njcX/k5GR4ZkN5uPj4wlGZsyYobJly2ry5MmeGXgXhlDdunVTenq653XKtebCvvn6+hZ47s+/kkIqGEItWrRI+/fvV3JysiZMmKCdO3dekzNnL+xdfq/y+5B/m/98ln/ptnQ+fD9z5oymTp16zfbOCnwKHoqcv7+/5xru3Nxczx+3x48fV0pKisLCwpSTkyNfX19evFzgwl5c+OlGv/zyi3bs2KGwsDCe+C4hvycdO3ZUdHS0KlWqpFmzZqldu3YyDENRUVHq2bMnn4j3B/K/38qWLau0tDRlZmbqxRdf1IcffqhVq1apevXqdpdYrDRv3lzLly/XsGHDNGnSJGVlZalXr146dOiQPv74Y/n5+aly5cp2l1ns5eXlqWHDhho9erTOnj2ruLg4VapUSatXr+ZTU//ADTfcoLvuuktvvfWWbr/9ds+bPbiYn5+fateurc8//1zXX3+9goODdfLkSX3++eeqVq2agoKC7C6xWGrfvr3efPNNjR07VseOHdOAAQN044036sSJE9q7d6+qVatG8HkJLVu21BtvvKFffvlFGRkZaty4sSTpyJEjysrKUocOHWyu0H6ZmZm67777tGvXLqWkpGjYsGFyOp3Kzs5WxYoV9cILL+ivf/2rnnjiCU2ePFkNGzb0hJ9VqlSRy+W6Jt+guFTffv8pshd+PXLkSBmGoTfffFOZmZk6deqU/vvf/+rBBx+0+UyuvsL07kIul8szM+/MmTOaOXOmli9frn79+l3t0kstAihYxu12e8KngwcPasGCBfrxxx/17LPP8jHIfyI/fEpKStIbb7yhzZs365133vFcOoWLtW/fXrNmzVJgYKBuvPFGTw+dTiffb3/iwgDK7XZr+vTpev/99/Xuu+8qLCzM7vKKpaZNm2rZsmWaMWOGxo0bp5dffllOp1Pp6elauHAhMysKIf+Fn7+/v9LT0+Xn5+dZWwt/rHv37lq1apU2btyoYcOG8WbOZZQrV05PPfWUoqOjdfDgQQUFBenEiRPavn27Fi9ezM/pH+jQoYPefvttTZ48WcOHD1edOnXkcDh0/PhxLV68mFmel+FyuQp8qvHu3bv1zjvvaO/evZoyZYqNldnv3LlzevHFF/Xzzz+rZcuWWrx4sXJzczVixAjP67TmzZvrlVde0fjx4/Xwww/r/vvv1x133KGMjAytXbtW5cuXV7Vq1Ww+k6vrj/p2qRAq/83/Bx98UKdOndKiRYtUsWJFrV27Vtdff73NZ3N1edO7fJUrV1ZmZqaSk5P1yiuvaP369VqzZs011zsrEUDBMvkviGNjY/Xtt99q3759evvttxUSEmJzZSXDnDlztG3bNu3fv19vvfUWffsTDodDd9xxB3+ImZD/yzcoKEirV6/Wzp07CZ8KISQkRLNnz9YPP/ygbdu2KTg4WK1bty7wxwf+WGZmpmbMmKHNmzdr7dq1hE+F1KVLF/Xo0UNdunThOe9PtG3bVkuXLtWrr76qPXv2KDQ0VBMnTuR3aiG0aNFCCxcu1JYtW7R161bVrl1bXbt2Vd26de0urUTYtWuXFixYoG+++UaLFi265vt2+PBhbd68WZ07d9b999+vt956S/Hx8ZKkESNGeMblzzIeP3683nrrLU2fPl316tXT6dOnr8k3eP6sb78PUvIvNT527JiOHDkif39/LVu27Jr8/ept76Tzlze63W699NJL+vjjj7V8+XI1adLErlMolQw3i3vAYj/88INWrFih6Oho1atXz+5ySozdu3frww8/1F133aXrrrvO7nJwDdixY4eGDx+u+Ph4/jjDVfPll18qKChIoaGhdpdSIlx4iTYKL3+dGUnMisVVcfbsWX311VeqW7cur+N0vh///Oc/1b17dwUEBGjPnj1asGCB/ve//2nw4MGeECo7O9vzM7pz507t2bNHAQEBatSo0UVrpF4LCtu3C5c9ycnJ0ZIlS/Tyyy/rvffeu2bfUDTTu/fff1/jx49XpUqV9PbbbxM+WYAAClfFuXPnPJ9+hMK78AkRuBrOnj2rcuXK2V0GAAAoZfID9Py/C5KSkjRv3rw/DKFQ+L7lr83mcDi0c+dO+fv7q1atWnaWbjtveudwOJSamqrx48friSee4I0xixBAAQAAAACuugsDgSFDhmj48OE6evSovvjiC3Xt2pUPpbiMy/Xt3//+t7p3766qVavaXWKxdbneff7557r99ttVqVIlJk5YiM4CAAAAAK66kJAQjR49WoZhaMmSJUpLS9OBAwf08ccfq2vXrnaXV2zRN/P+qHe33HIL4ZPF6C4AAAAA4KrLy8tTw4YNNXr0aJ09e1ZxcXGqVKmSVq9ezeynP/BHfatevbrd5RVrfM/ZiwAKAAAAAHDV5X8Cmb+/v9LT0+Xn56elS5dek5/a5g36Zh69sxcBFAAAAADAFpmZmZoxY4Y2b96stWvXEgQUEn0zj97Zh0XIAQAAAAC2+fLLLxUUFMQnj3mJvplH7+xBAAUAAAAAAABLOewuAAAAAAAAAKUbARQAAAAAAAAsRQAFAAAAAAAASxFAAQAAAAAAwFIEUAAAAAAAALAUARQAAAAAAAAsRQAFAAAAAAAAS5WxuwAAAIBrwa5du7R48WJt2bJFKSkpKlOmjOrVq6cePXqoX79+CggI0ODBgyVJ8fHxNlcLAABQtAigAAAALLZy5UpNnjxZ9evXV3R0tBo2bKhz587phx9+0PLly7Vt2zbNnTvX7jIBAAAsQwAFAABgoW+++UbPPvusOnTooHnz5snpdHr23XTTTXrggQf0xRdf2FghAACA9QigAAAALPT666/LMAw999xzBcKnfE6nUzfffPNl7//aa69p06ZNOnjwoM6dO6e6devqvvvu09133y3DMDzjNm/erHnz5unHH39UZmamAgMDFR4erhdffFEul0uStGzZMi1fvlyHDx+WJAUHB+vWW2/V448/XsRnDQAAUBABFAAAgEVyc3OVmJiopk2bqkaNGqaOcfToUfXv3181a9aUJG3btk1Tp05VcnKyHnroIUnSkSNHNHLkSN1www16/vnn5e/vr+TkZH3xxRfKycmRy+XSBx98oMmTJ2vw4MF68skn5XA4dPDgQe3du7fIzhcAAOByCKAAAAAs8uuvvyozM1O1a9c2fYzp06d7/p2Xl6c2bdrI7XZryZIlGjt2rAzD0Pbt25WVlaXx48fr+uuv94yPjIz0/Hvr1q3y9/dXTEyMZ1v79u1N1wUAAOANh90FAAAA4PI2b96soUOHqnXr1mrSpImaNm2qV199Vampqfrll18kSU2aNJGvr68mTZqkNWvWeC6xu1B4eLjS0tL0+OOP65NPPtHJkyev9qkAAIBrGAEUAACARSpXriyXy6UjR46Yuv93332n6OhoSdJzzz2nd999V++9955GjRolSTp79qwkqU6dOnr77bdVpUoVTZkyRbfccotuueUWLV682HOsPn36aNq0afrpp5/0yCOPqEOHDurXr5/+85//XOFZAgAA/DkuwQMAALCIj4+P2rVrpy+++ELHjx9X9erVvbr/Bx98oDJlyuj1119X2bJlPds/+eSTi8becMMNuuGGG5Sbm6sffvhB8fHxmjZtmqpWraqePXtKkqKiohQVFaWMjAz973//05w5czRy5Eh99NFHqlWr1pWdLAAAwB9gBhQAAICFRo4cKbfbrZiYGGVnZ1+0PycnR5999tkl72sYhnx8fORw/PaS7ezZs3r//fcv+3g+Pj5q0aKFnnnmGUnS9u3bLxpTvnx5RUREaNSoUcrJyWEhcgAAYDlmQAEAAFioZcuWevbZZzV58mRFRUVpwIABatSokc6dO6cdO3Zo5cqVatSokbp163bRfSMiIvTWW2/piSeeUP/+/ZWamqpFixbJ6XQWGPfuu+8qMTFRXbp0UY0aNZSVlaVVq1ZJkjp06CBJiomJUbly5dSqVSsFBQUpJSVFcXFx8vPzU3h4uPWNAAAA1zTD7Xa77S4CAACgtNu1a5fefvttbdmyRSkpKfL19VW9evXUtWtXDRo0SIGBgRo8eLAkKT4+3nO/VatWaeHChTp69KiCg4N1zz33KDAwUE899ZQ+/fRT1a5dW9u2bdMbb7yhHTt2KCUlReXLl1fjxo31wAMPeIKttWvXavXq1UpKStKpU6dUuXJltW7dWqNHj1ZoaKgtPQEAANcOAigAAAAAAABYijWgAAAAAAAAYCkCKAAAAAAAAFiKAAoAAAAAAACWIoACAAAAAACApQigAAAAAAAAYCkCKAAAAAAAAFiKAAoAAAAAAACWIoACAAAAAACApQigAAAAAAAAYCkCKAAAAAAAAFiKAAoAAAAAAACWIoACAAAAAACApf4/o9TV/PltT2YAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_manager.plot_class_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Execution: Top 5 classes with highest probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Collected 646 images for class 5\n",
      "INFO:__main__:Collected 635 images for class 3\n",
      "INFO:__main__:Collected 584 images for class 4\n",
      "INFO:__main__:Collected 543 images for class 2\n",
      "INFO:__main__:Collected 522 images for class 6\n",
      "INFO:__main__:Collected 385 images for class 1\n",
      "INFO:__main__:Collected 342 images for class 7\n",
      "INFO:__main__:Split sizes - Train: 2559, Val: 549, Test: 549\n"
     ]
    }
   ],
   "source": [
    "initial_classes = dataset_manager.get_class_subset(num_classes=7)\n",
    "data_split = dataset_manager.prepare_data_split(initial_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Training set class distribution:\n",
      "class\n",
      "5    549\n",
      "3    540\n",
      "4    496\n",
      "2    461\n",
      "6    444\n",
      "1    327\n",
      "7    291\n",
      "Name: count, dtype: int64\n",
      "I0000 00:00:1732042396.092277  305468 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3586 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "train_gen, val_gen, test_gen = data_generator.create_generators(data_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Class Weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = sum(dataset_manager.class_counts[cls] for cls in initial_classes)\n",
    "\n",
    "class_weights = {\n",
    "    data_split.class_mapping[cls]: total_samples\n",
    "    / (len(initial_classes) * dataset_manager.class_counts[cls])\n",
    "    for cls in initial_classes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Steps per epoch: 97, Validation steps: 17\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch, validation_steps = data_generator.get_steps()\n",
    "logger.info(f\"Steps per epoch: {steps_per_epoch}, Validation steps: {validation_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
       "\n",
       " input_layer_1        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                                               \n",
       "\n",
       " MobileNetV3Large     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,996,352</span>  input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                                                          \n",
       "\n",
       " global_average_poo  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  MobileNetV3Large \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool</span>                                                   \n",
       "\n",
       " global_max_pooling  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  MobileNetV3Large \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2</span>                                                   \n",
       "\n",
       " concatenate          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  global_average_p \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       global_max_pooli \n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">983,040</span>  concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " batch_normalization  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span>  dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " activation_20        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                                                          \n",
       "\n",
       " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  activation_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span>  dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "\n",
       " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "\n",
       " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">1,799</span>  dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " input_layer_1        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,            \u001b[38;5;34m0\u001b[0m  -                 \n",
       " (\u001b[38;5;33mInputLayer\u001b[0m)         \u001b[38;5;34m3\u001b[0m)                                               \n",
       "\n",
       " MobileNetV3Large     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m)   \u001b[38;5;34m2,996,352\u001b[0m  input_layer_1[\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mFunctional\u001b[0m)                                                          \n",
       "\n",
       " global_average_poo  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m960\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  MobileNetV3Large \n",
       " (\u001b[38;5;33mGlobalAveragePool\u001b[0m                                                   \n",
       "\n",
       " global_max_pooling  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m960\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  MobileNetV3Large \n",
       " (\u001b[38;5;33mGlobalMaxPooling2\u001b[0m                                                   \n",
       "\n",
       " concatenate          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1920\u001b[0m)                \u001b[38;5;34m0\u001b[0m  global_average_p \n",
       " (\u001b[38;5;33mConcatenate\u001b[0m)                                       global_max_pooli \n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)           \u001b[38;5;34m983,040\u001b[0m  concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " batch_normalization  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)             \u001b[38;5;34m2,048\u001b[0m  dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " activation_20        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       " (\u001b[38;5;33mActivation\u001b[0m)                                                          \n",
       "\n",
       " dropout (\u001b[38;5;33mDropout\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  activation_20[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " dense_1 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           \u001b[38;5;34m131,328\u001b[0m  dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "\n",
       " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "\n",
       " dense_2 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)               \u001b[38;5;34m1,799\u001b[0m  dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,114,567</span> (15.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,114,567\u001b[0m (15.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,117,191</span> (4.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,117,191\u001b[0m (4.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,997,376</span> (11.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,997,376\u001b[0m (11.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = model_manager.build_model(data_generator.get_num_classes())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "FBetaScore expects 2D inputs with shape (batch_size, output_dim). Received input shapes: y_pred.shape=(None, 7) and y_true.shape=(None, 7, 7).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 92\u001b[0m, in \u001b[0;36mModelManager.train\u001b[0;34m(self, train_ds, val_ds, iteration, epochs, class_weights)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     67\u001b[0m     train_ds,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     class_weights: Optional[Dict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     72\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mHistory:\n\u001b[1;32m     73\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     74\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[1;32m     75\u001b[0m             \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model_iter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00miteration\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     89\u001b[0m         ),\n\u001b[1;32m     90\u001b[0m     ]\n\u001b[0;32m---> 92\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[9], line 57\u001b[0m, in \u001b[0;36mModelManager._compile_model.<locals>.sparse_f1_score\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msparse_f1_score\u001b[39m(y_true, y_pred):\n\u001b[1;32m     56\u001b[0m     y_true_one_hot \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mone_hot(tf\u001b[38;5;241m.\u001b[39mcast(y_true, tf\u001b[38;5;241m.\u001b[39mint32), num_classes)\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true_one_hot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: FBetaScore expects 2D inputs with shape (batch_size, output_dim). Received input shapes: y_pred.shape=(None, 7) and y_true.shape=(None, 7, 7)."
     ]
    }
   ],
   "source": [
    "history = model_manager.train(\n",
    "    train_gen,\n",
    "    val_gen,\n",
    "    iteration=1,\n",
    "    epochs=100,\n",
    "    class_weights=class_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_subplot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_finetune = model_manager.fine_tune(\n",
    "    train_gen,\n",
    "    val_gen,\n",
    "    iteration=1,\n",
    "    num_layers_to_unfreeze=50,\n",
    "    epochs=30,\n",
    "    class_weights=class_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_subplot(history_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = evaluator.evaluate_iteration(\n",
    "    iteration=1, test_ds=test_gen, class_names=initial_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.print_classification_report(iteration=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Iteration: The next classes with highest probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes = dataset_manager.get_class_subset(num_classes=9)\n",
    "new_classes = all_classes[7:]\n",
    "\n",
    "print(f\"Original classes: {all_classes[:7]}\")\n",
    "print(f\"New classes: {new_classes}\")\n",
    "print(f\"All classes: {all_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = dataset_manager.prepare_data_split(all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen, val_gen, test_gen = data_generator.create_generators(data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = sum(dataset_manager.class_counts[cls] for cls in all_classes)\n",
    "class_weights = {\n",
    "    data_split.class_mapping[cls]: total_samples\n",
    "    / (len(all_classes) * dataset_manager.class_counts[cls])\n",
    "    for cls in all_classes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ModelEvaluator(model_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.prepare_next_iteration(\n",
    "    previous_iteration=1,\n",
    "    new_num_classes=len(all_classes),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_manager.train(\n",
    "    train_gen,\n",
    "    val_gen,\n",
    "    iteration=2,\n",
    "    epochs=100,\n",
    "    class_weights=class_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_subplot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_finetune = model_manager.fine_tune(\n",
    "    train_gen,\n",
    "    val_gen,\n",
    "    iteration=2,\n",
    "    num_layers_to_unfreeze=50,\n",
    "    epochs=30,\n",
    "    class_weights=class_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_subplot(history_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = evaluator.evaluate_iteration(\n",
    "    iteration=2, test_ds=test_gen, class_names=all_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.print_classification_report(iteration=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
