{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 15:07:13.963137: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-19 15:07:14.134557: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732050434.196491    3996 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732050434.212581    3996 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-19 15:07:14.357835: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from collections import deque\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    epochs: int = 100\n",
    "    image_size: int = 250\n",
    "    batch_size: int = 16\n",
    "    device: str = \"0\"\n",
    "    patience: int = 20\n",
    "    dropout: float = 0.2\n",
    "    augment: bool = True\n",
    "    mosaic: float = 1.0\n",
    "    mixup: float = 0.3\n",
    "    copy_paste: float = 0.3\n",
    "    degrees: float = 45.0\n",
    "    translate: float = 0.2\n",
    "    scale: float = 0.5\n",
    "    shear: float = 10.0\n",
    "    perspective: float = 0.0005\n",
    "    flipud: float = 0.5\n",
    "    fliplr: float = 0.5\n",
    "    hsv_h: float = 0.015\n",
    "    hsv_s: float = 0.7\n",
    "    hsv_v: float = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DetectionConfig:\n",
    "    conf_threshold: float = 0.30\n",
    "    iou_threshold: float = 0.60\n",
    "    min_area: int = 500\n",
    "    max_overlap_ratio: float = 0.8\n",
    "    temporal_window: int = 3\n",
    "    enable_nms: bool = True\n",
    "    enable_temporal: bool = True\n",
    "    enable_size_filter: bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ConsistencyConfig:\n",
    "    num_inference_passes: int = 3\n",
    "    confidence_threshold: float = 0.3\n",
    "    consistency_threshold: float = 0.7\n",
    "\n",
    "    enable_tta: bool = True\n",
    "    tta_scales: List[float] = None\n",
    "    tta_flips: bool = True\n",
    "\n",
    "    min_detection_votes: int = 2\n",
    "    calibrate_confidence: bool = True\n",
    "    confidence_scaling_factor: float = 1.2\n",
    "    min_relative_size: float = 0.01\n",
    "    max_relative_size: float = 0.8\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.tta_scales is None:\n",
    "            self.tta_scales = [0.9, 1.0, 1.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection Tracker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionTracker:\n",
    "    def __init__(self, window_size: int = 3):\n",
    "        self.window_size = window_size\n",
    "        self.detection_history = deque(maxlen=window_size)\n",
    "\n",
    "    def update(self, detections: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Updates the detection history with the new detections and returns the\n",
    "        filtered detections.\n",
    "\n",
    "        Args:\n",
    "            detections (np.ndarray): The detections to be added to the history.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The filtered detections.\n",
    "        \"\"\"\n",
    "        if len(detections) == 0:\n",
    "            return detections\n",
    "\n",
    "        self.detection_history.append(detections)\n",
    "\n",
    "        if len(self.detection_history) < 2:\n",
    "            return detections\n",
    "\n",
    "        weights = np.linspace(0.5, 1.0, len(self.detection_history))\n",
    "        weights /= np.sum(weights)\n",
    "\n",
    "        smoothed = np.zeros_like(detections)\n",
    "        for i, (det, w) in enumerate(zip(self.detection_history, weights)):\n",
    "            if det.shape == detections.shape:\n",
    "                smoothed += w * det\n",
    "\n",
    "        return smoothed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOBase:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path: Union[str, Path],\n",
    "        detection_config: Optional[DetectionConfig] = None,\n",
    "    ):\n",
    "        self.model_path = Path(model_path)\n",
    "        self.detection_config = detection_config or DetectionConfig()\n",
    "        self.tracker = DetectionTracker(self.detection_config.temporal_window)\n",
    "        self.model = None\n",
    "\n",
    "    def _load_model(self, weights_path: Optional[Path] = None) -> bool:\n",
    "        try:\n",
    "            if weights_path is not None and weights_path.exists():\n",
    "                self.model = YOLO(str(self.model_path))\n",
    "                self.model.load(str(weights_path))\n",
    "                logging.info(\n",
    "                    f\"Loaded base model from {self.model_path} with weights from {weights_path}\"\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                self.model = YOLO(str(self.model_path))\n",
    "                logging.info(f\"Loaded model from {self.model_path}\")\n",
    "\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to load model: {e}\")\n",
    "            return False\n",
    "\n",
    "    def _compute_intersection(self, box1: np.ndarray, box2: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Computes the intersection area between two bounding boxes.\n",
    "\n",
    "        Args:\n",
    "            box1 (np.ndarray): The first bounding box.\n",
    "            box2 (np.ndarray): The second bounding box.\n",
    "\n",
    "        Returns:\n",
    "            float: The intersection area.\n",
    "        \"\"\"\n",
    "        x1 = max(box1[0], box2[0])\n",
    "        y1 = max(box1[1], box2[1])\n",
    "        x2 = min(box1[2], box2[2])\n",
    "        y2 = min(box1[3], box2[3])\n",
    "\n",
    "        return max(0, x2 - x1) * max(0, y2 - y1)\n",
    "\n",
    "    def post_process_detection(\n",
    "        self, boxes: np.ndarray, scores: np.ndarray, class_ids: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Post-processes the raw detections by applying NMS and size filtering.\n",
    "\n",
    "        Args:\n",
    "            boxes (np.ndarray): The detected bounding boxes.\n",
    "            scores (np.ndarray): The detection scores.\n",
    "            class_ids (np.ndarray): The detected class IDs.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray, np.ndarray]: The post-processed detections.\n",
    "        \"\"\"\n",
    "\n",
    "        if len(boxes) == 0:\n",
    "            return boxes, scores, class_ids\n",
    "\n",
    "        if self.detection_config.enable_nms:\n",
    "            indices = cv2.dnn.NMSBoxes(\n",
    "                boxes.tolist(),\n",
    "                scores.tolist(),\n",
    "                self.detection_config.conf_threshold,\n",
    "                self.detection_config.iou_threshold,\n",
    "            )\n",
    "            boxes = boxes[indices.flatten()]\n",
    "            scores = scores[indices.flatten()]\n",
    "            class_ids = class_ids[indices.flatten()]\n",
    "\n",
    "        if self.detection_config.enable_size_filter:\n",
    "            areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "            mask = areas >= self.detection_config.min_area\n",
    "            boxes = boxes[mask]\n",
    "            scores = scores[mask]\n",
    "            class_ids = class_ids[mask]\n",
    "\n",
    "        final_boxes, final_scores, final_class_ids = [], [], []\n",
    "        for idx in range(len(boxes)):\n",
    "            overlap_too_high = False\n",
    "            box_area = (boxes[idx, 2] - boxes[idx, 0]) * (boxes[idx, 3] - boxes[idx, 1])\n",
    "\n",
    "            for j in range(len(final_boxes)):\n",
    "                intersection = self._compute_intersection(boxes[idx], final_boxes[j])\n",
    "                if intersection / box_area > self.detection_config.max_overlap_ratio:\n",
    "                    overlap_too_high = True\n",
    "                    break\n",
    "\n",
    "            if not overlap_too_high:\n",
    "                final_boxes.append(boxes[idx])\n",
    "                final_scores.append(scores[idx])\n",
    "                final_class_ids.append(class_ids[idx])\n",
    "\n",
    "        return np.array(final_boxes), np.array(final_scores), np.array(final_class_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOTrainer(YOLOBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path: Union[str, Path] = \"yolov8n.pt\",\n",
    "        training_config: Optional[TrainingConfig] = None,\n",
    "        detection_config: Optional[DetectionConfig] = None,\n",
    "    ):\n",
    "        super().__init__(model_path, detection_config)\n",
    "\n",
    "        self.training_config = training_config or TrainingConfig()\n",
    "        self._load_model()\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        data_yaml_path: Union[str, Path],\n",
    "        epochs: Optional[int] = 50,\n",
    "        image_size: Optional[int] = 320,\n",
    "        batch_size: Optional[int] = 16,\n",
    "    ):\n",
    "        data_yaml_path = Path(data_yaml_path).resolve()\n",
    "        data_dir = data_yaml_path.parent\n",
    "\n",
    "        train_path = (data_dir / \"train\" / \"images\").resolve()\n",
    "        val_path = (data_dir / \"valid\" / \"images\").resolve()\n",
    "        self._verify_data_paths(train_path, val_path)\n",
    "\n",
    "        data_config = self._create_data_config(train_path, val_path)\n",
    "        with open(data_yaml_path, \"w\") as f:\n",
    "            yaml.safe_dump(data_config, f, sort_keys=False)\n",
    "\n",
    "        self.results = self.model.train(\n",
    "            data=data_yaml_path,\n",
    "            epochs=epochs or self.training_config.epochs,\n",
    "            imgsz=image_size or self.training_config.image_size,\n",
    "            batch=batch_size or self.training_config.batch_size,\n",
    "            device=self.training_config.device,\n",
    "            patience=self.training_config.patience,\n",
    "            save=True,\n",
    "            plots=True,\n",
    "            augment=self.training_config.augment,\n",
    "            dropout=self.training_config.dropout,\n",
    "            **{\n",
    "                k: v\n",
    "                for k, v in vars(self.training_config).items()\n",
    "                if k in [\"mosaic\", \"mixup\", \"copy_paste\"]\n",
    "            },\n",
    "        )\n",
    "\n",
    "        return self.model, self.results\n",
    "\n",
    "    def _create_data_config(self, train_path: Path, val_path: Path) -> dict:\n",
    "        \"\"\"Create YOLO training configuration\"\"\"\n",
    "        config = {\n",
    "            \"train\": str(train_path),\n",
    "            \"val\": str(val_path),\n",
    "            \"nc\": 1,\n",
    "            \"names\": [\"cow\"],\n",
    "        }\n",
    "\n",
    "        augment_params = {\n",
    "            k: v\n",
    "            for k, v in vars(self.training_config).items()\n",
    "            if k\n",
    "            in [\n",
    "                \"mosaic\",\n",
    "                \"mixup\",\n",
    "                \"copy_paste\",\n",
    "                \"degrees\",\n",
    "                \"translate\",\n",
    "                \"scale\",\n",
    "                \"shear\",\n",
    "                \"perspective\",\n",
    "                \"flipud\",\n",
    "                \"fliplr\",\n",
    "                \"hsv_h\",\n",
    "                \"hsv_s\",\n",
    "                \"hsv_v\",\n",
    "            ]\n",
    "        }\n",
    "        config.update(augment_params)\n",
    "        return config\n",
    "\n",
    "    def _verify_data_paths(self, train_path: Path, val_path: Path):\n",
    "        \"\"\"Verify that data paths exist\"\"\"\n",
    "        if not train_path.exists():\n",
    "            raise FileNotFoundError(f\"Training directory not found: {train_path}\")\n",
    "\n",
    "        if not val_path.exists():\n",
    "            raise FileNotFoundError(f\"Validation directory not found: {val_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOInference:\n",
    "    def __init__(\n",
    "        self, model_path: str = \"yolov8m.pt\", weights_path: Optional[str] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize YOLO model with optional custom weights\n",
    "        \"\"\"\n",
    "        if weights_path:\n",
    "            self.model = YOLO(weights_path)\n",
    "\n",
    "        else:\n",
    "            self.model = YOLO(model_path)\n",
    "\n",
    "    def predict_image(\n",
    "        self,\n",
    "        image_path: str,\n",
    "        save_path: Optional[str] = None,\n",
    "        conf_threshold: float = 0.3,\n",
    "        iou_threshold: float = 0.7,\n",
    "    ) -> Tuple[np.ndarray, Any]:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Could not read image: {image_path}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Run inference with NMS parameters\n",
    "        results = self.model(\n",
    "            image, verbose=False, conf=conf_threshold, iou=iou_threshold, max_det=20\n",
    "        )[0]\n",
    "\n",
    "        # Draw boxes\n",
    "        annotated_image = image.copy()\n",
    "        if results.boxes is not None and len(results.boxes) > 0:\n",
    "            boxes = results.boxes.cpu().numpy()\n",
    "\n",
    "            # Sort boxes by confidence\n",
    "            confidences = [float(box.conf[0]) for box in boxes]\n",
    "            sorted_indices = np.argsort(confidences)[::-1]\n",
    "\n",
    "            for idx in sorted_indices:\n",
    "                box = boxes[idx]\n",
    "                # Get coordinates and confidence\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                confidence = float(box.conf[0])\n",
    "\n",
    "                # Draw box\n",
    "                cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "                # Create label\n",
    "                label = f\"{confidence:.2f}\"\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                font_scale = 0.6\n",
    "                thickness = 2\n",
    "\n",
    "                # Get label size\n",
    "                (label_width, label_height), baseline = cv2.getTextSize(\n",
    "                    label, font, font_scale, thickness\n",
    "                )\n",
    "\n",
    "                # Draw label background\n",
    "                label_patch = (\n",
    "                    np.ones(\n",
    "                        (label_height + 2 * baseline, label_width + 2 * baseline, 3),\n",
    "                        dtype=np.uint8,\n",
    "                    )\n",
    "                    * 255\n",
    "                )\n",
    "                cv2.putText(\n",
    "                    label_patch,\n",
    "                    label,\n",
    "                    (baseline, label_height),\n",
    "                    font,\n",
    "                    font_scale,\n",
    "                    (0, 0, 0),\n",
    "                    thickness,\n",
    "                )\n",
    "\n",
    "                # Calculate label position\n",
    "                label_y = max(y1 - label_height - baseline, 0)\n",
    "                label_x = max(x1, 0)\n",
    "\n",
    "                # Add label to image using alpha blending\n",
    "                if (\n",
    "                    label_y + label_height <= image.shape[0]\n",
    "                    and label_x + label_width <= image.shape[1]\n",
    "                ):\n",
    "                    alpha = 0.7\n",
    "                    label_height, label_width = label_patch.shape[:2]\n",
    "                    roi = annotated_image[\n",
    "                        label_y : label_y + label_height,\n",
    "                        label_x : label_x + label_width,\n",
    "                    ]\n",
    "                    try:\n",
    "                        cv2.addWeighted(label_patch, alpha, roi, 1 - alpha, 0, roi)\n",
    "                    except Exception:\n",
    "                        # Fallback to simpler label if blending fails\n",
    "                        cv2.putText(\n",
    "                            annotated_image,\n",
    "                            label,\n",
    "                            (label_x, label_y + label_height),\n",
    "                            font,\n",
    "                            font_scale,\n",
    "                            (0, 0, 0),\n",
    "                            thickness,\n",
    "                        )\n",
    "\n",
    "        # Save if path provided\n",
    "        if save_path:\n",
    "            save_dir = Path(save_path).parent\n",
    "            save_dir.mkdir(parents=True, exist_ok=True)\n",
    "            cv2.imwrite(save_path, cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        return annotated_image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inference_pipeline(\n",
    "    base_model_path: str = \"yolov8m.pt\",\n",
    "    weights_path: str = \"runs/detect/train29/weights/last.pt\",\n",
    "    **config_kwargs,\n",
    ") -> YOLOInference:\n",
    "    \"\"\"Creates an inference pipeline with specified weights.\"\"\"\n",
    "    consistency_config = ConsistencyConfig(\n",
    "        **{k: v for k, v in config_kwargs.items() if hasattr(ConsistencyConfig, k)}\n",
    "    )\n",
    "\n",
    "    detection_config = DetectionConfig(\n",
    "        **{k: v for k, v in config_kwargs.items() if hasattr(DetectionConfig, k)}\n",
    "    )\n",
    "\n",
    "    return YOLOInference(\n",
    "        model_path=base_model_path,\n",
    "        weights_path=weights_path,\n",
    "        consistency_config=consistency_config,\n",
    "        detection_config=detection_config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOEvaluator:\n",
    "    def __init__(self, detector: YOLOInference):\n",
    "        self.detector = detector\n",
    "\n",
    "    def calculate_metrics(\n",
    "        self,\n",
    "        ground_truth_path: str,\n",
    "        iou_threshold: float = 0.5,\n",
    "        conf_threshold: float = 0.3,\n",
    "    ) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calculate precision, recall, and F1 score for the model.\n",
    "\n",
    "        Args:\n",
    "            ground_truth_path (str): The path to the ground truth directory.\n",
    "            iou_threshold (float): The IoU threshold for matching detections.\n",
    "            conf_threshold (float): The confidence threshold for filtering detections.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, float]: The calculated metrics.\n",
    "        \"\"\"\n",
    "\n",
    "        true_positives, false_positives, false_negatives = 0, 0, 0\n",
    "        gt_dir = Path(ground_truth_path)\n",
    "        image_files = list(gt_dir.glob(\"**/*.jpg\"))\n",
    "\n",
    "        for image_file in image_files:\n",
    "            label_file = image_file.with_suffix(\".txt\")\n",
    "            if not label_file.exists():\n",
    "                continue\n",
    "\n",
    "            gt_boxes = self._read_yolo_labels(label_file)\n",
    "            _, results = self.detector.predict_image(\n",
    "                str(image_file),\n",
    "                conf_threshold=conf_threshold,\n",
    "                iou_threshold=iou_threshold,\n",
    "            )\n",
    "\n",
    "            if results.boxes is None:\n",
    "                false_negatives += len(gt_boxes)\n",
    "                continue\n",
    "\n",
    "            pred_boxes = results.boxes.cpu().numpy()\n",
    "            matched_gt = set()\n",
    "\n",
    "            for pred in pred_boxes:\n",
    "                pred_box = pred.xyxy[0]\n",
    "                best_iou = 0\n",
    "                best_gt_idx = -1\n",
    "\n",
    "                for gt_idx, gt_box in enumerate(gt_boxes):\n",
    "                    if gt_idx in matched_gt:\n",
    "                        continue\n",
    "\n",
    "                    iou = self._calculate_iou(pred_box, gt_box)\n",
    "                    if iou > best_iou:\n",
    "                        best_iou = iou\n",
    "                        best_gt_idx = gt_idx\n",
    "\n",
    "                if best_iou > iou_threshold:\n",
    "                    true_positives += 1\n",
    "                    matched_gt.add(best_gt_idx)\n",
    "\n",
    "                else:\n",
    "                    false_positives += 1\n",
    "\n",
    "            false_negatives += len(gt_boxes) - len(matched_gt)\n",
    "\n",
    "        precision = (\n",
    "            true_positives / (true_positives + false_positives)\n",
    "            if (true_positives + false_positives) > 0\n",
    "            else 0\n",
    "        )\n",
    "        recall = (\n",
    "            true_positives / (true_positives + false_negatives)\n",
    "            if (true_positives + false_negatives) > 0\n",
    "            else 0\n",
    "        )\n",
    "        f1_score = (\n",
    "            2 * (precision * recall) / (precision + recall)\n",
    "            if (precision + recall) > 0\n",
    "            else 0\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1_score,\n",
    "            \"true_positives\": true_positives,\n",
    "            \"false_positives\": false_positives,\n",
    "            \"false_negatives\": false_negatives,\n",
    "        }\n",
    "\n",
    "    def _read_yolo_labels(self, label_file: Path) -> List[np.ndarray]:\n",
    "        boxes = []\n",
    "\n",
    "        if label_file.exists():\n",
    "            with open(label_file) as f:\n",
    "                for line in f:\n",
    "                    class_id, x_center, y_center, width, height = map(\n",
    "                        float, line.strip().split()\n",
    "                    )\n",
    "\n",
    "                    x1 = x_center - width / 2\n",
    "                    y1 = y_center - height / 2\n",
    "\n",
    "                    x2 = x_center + width / 2\n",
    "                    y2 = y_center + height / 2\n",
    "\n",
    "                    boxes.append(np.array([x1, y1, x2, y2]))\n",
    "\n",
    "        return boxes\n",
    "\n",
    "    def _calculate_iou(self, box1: np.ndarray, box2: np.ndarray) -> float:\n",
    "        x1 = max(box1[0], box2[0])\n",
    "        y1 = max(box1[1], box2[1])\n",
    "        x2 = min(box1[2], box2[2])\n",
    "        y2 = min(box1[3], box2[3])\n",
    "\n",
    "        intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "\n",
    "        union = area1 + area2 - intersection\n",
    "        return intersection / union if union > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_config = DetectionConfig(\n",
    "    conf_threshold=0.3, iou_threshold=0.6, min_area=500, temporal_window=3\n",
    ")\n",
    "\n",
    "training_config = TrainingConfig(epochs=50, image_size=640, batch_size=16, dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8x.pt to 'yolov8x.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131M/131M [00:14<00:00, 9.56MB/s] \n",
      "2024-11-19 15:07:37,432 - INFO - Loaded model from yolov8x.pt\n"
     ]
    }
   ],
   "source": [
    "trainer = YOLOTrainer(\n",
    "    model_path=\"yolov8x.pt\",\n",
    "    training_config=training_config,\n",
    "    detection_config=detection_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.34 ðŸš€ Python-3.10.13 torch-2.4.1.post302 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=/home/carlos/developer/cow-project/data/yolo/data.yaml, epochs=50, time=None, patience=20, batch=16, imgsz=320, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.2, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.3, copy_paste=0.3, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8718931  ultralytics.nn.modules.head.Detect           [1, [320, 640, 640]]          \n",
      "Model summary: 365 layers, 68,153,571 parameters, 68,153,555 gradients, 258.1 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 8.98MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/carlos/developer/cow-project/data/yolo/train/labels... 6469 images, 1218 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7283/7283 [00:07<00:00, 921.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/carlos/developer/cow-project/data/yolo/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlos/miniconda3/envs/ml/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/carlos/developer/cow-project/data/yolo/valid/labels... 1618 images, 144 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1658/1658 [00:02<00:00, 749.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/carlos/developer/cow-project/data/yolo/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 320 train, 320 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      4.95G      1.238      1.124      1.467         47        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [03:19<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:17<00:00,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.842       0.83      0.885      0.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      4.57G      1.254      1.073      1.488         29        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:46<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.877      0.862      0.893       0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      4.55G      1.204      1.011      1.458         28        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:45<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:13<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.897      0.898      0.925      0.677\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      4.51G      1.139     0.9545      1.421         25        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:45<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:13<00:00,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.897      0.885      0.928      0.686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      4.55G        1.1     0.9071      1.395         11        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:46<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.905       0.91      0.941      0.728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      4.55G      1.053     0.8669      1.365         20        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:47<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:15<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.911      0.925      0.946      0.735\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      4.56G       1.04     0.8577      1.359         16        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:44<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:15<00:00,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.904      0.933      0.949      0.736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      4.54G      1.012     0.8228      1.339         44        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:47<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.902      0.934      0.944      0.736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      4.54G     0.9952     0.8047       1.33         17        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:48<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.917      0.929      0.952      0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      4.54G     0.9832      0.794      1.321         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:47<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.923      0.934      0.953      0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      4.56G     0.9671      0.778       1.31         27        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:47<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:15<00:00,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.917      0.929      0.943      0.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50       4.5G     0.9628     0.7719      1.311         47        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:44<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:15<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.917      0.938      0.954      0.764\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      4.56G     0.9488     0.7593        1.3         23        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:44<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.918      0.937      0.952      0.764\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      4.51G     0.9348     0.7482      1.292         25        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:47<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636       0.91      0.947      0.951      0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      4.52G     0.9195     0.7387      1.281         32        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:48<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.916      0.941      0.953      0.777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      4.52G      0.916     0.7284      1.276         53        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:48<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.916      0.938      0.955       0.78\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      4.54G     0.9044     0.7198       1.27         38        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:46<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:15<00:00,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636       0.92       0.94      0.951      0.777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50       4.5G     0.8935     0.7105      1.262         32        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:47<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.924      0.937      0.955      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      4.55G     0.8922     0.7069       1.26         32        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:48<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:13<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.917      0.946      0.952      0.783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50       4.5G      0.882     0.6983      1.253         44        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:47<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.918      0.947      0.955      0.788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50       4.5G     0.8829     0.6966      1.253         27        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:47<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:15<00:00,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.928      0.946      0.958      0.787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50       4.5G     0.8684     0.6855      1.246         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:44<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:15<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.921      0.947      0.956      0.791\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      4.55G      0.861     0.6826      1.241         11        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:48<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.918      0.951      0.954      0.788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      4.57G     0.8599     0.6799      1.241         11        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:48<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.922       0.94      0.955      0.789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      4.55G     0.8589     0.6712       1.24         12        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:48<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:14<00:00,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636       0.92      0.946      0.957      0.792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      4.56G     0.8477      0.673      1.234         44        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:48<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:15<00:00,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.914      0.949      0.956      0.795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      4.55G     0.8363      0.657      1.222         16        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:46<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:15<00:00,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636       0.92      0.946      0.957        0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      4.57G     0.8404     0.6611      1.225         41        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:49<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.928      0.937      0.959        0.8\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      4.55G     0.8279     0.6531      1.221         35        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:50<00:00,  2.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.917      0.952      0.955      0.798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50      4.55G     0.8222     0.6515       1.22         41        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:50<00:00,  2.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:13<00:00,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.919       0.94      0.953      0.797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      4.49G      0.815     0.6446      1.211         22        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:50<00:00,  2.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.922      0.943      0.958      0.805\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      4.56G     0.8151      0.637      1.212         44        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:45<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:17<00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.919      0.948      0.957      0.802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      4.53G     0.8099      0.635      1.203         31        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:47<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.921      0.951      0.956      0.805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      4.55G     0.8012     0.6337      1.198         25        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:51<00:00,  2.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.927      0.945      0.957      0.805\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      4.53G     0.7905     0.6254      1.195         30        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:46<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 33/52 [00:08<00:04,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.917      0.948      0.956      0.801\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      4.55G     0.7888     0.6162       1.19         30        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:46<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  23%|â–ˆâ–ˆâ–Ž       | 12/52 [00:02<00:09,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.918      0.949      0.957      0.808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      4.51G     0.7845     0.6188       1.19         47        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:51<00:00,  2.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.919      0.951      0.956      0.808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      4.51G     0.7754     0.6114      1.183         27        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:51<00:00,  2.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:13<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.919      0.951      0.959       0.81\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      4.54G     0.7708     0.6096       1.18         30        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:51<00:00,  2.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:13<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.919      0.954      0.956      0.809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      4.52G     0.7703     0.6039      1.181         16        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:51<00:00,  2.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:17<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.924      0.948      0.958      0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      4.55G     0.6385     0.4959      1.099         16        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:45<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.921      0.947      0.956      0.811\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      4.55G     0.6289     0.4903       1.09          7        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:49<00:00,  2.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636       0.92      0.953      0.957       0.81\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50       4.5G     0.6188     0.4807      1.083         19        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:49<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.921      0.953      0.956      0.803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      4.55G     0.6085     0.4735      1.078         14        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:48<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.922      0.948      0.955      0.807\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      4.55G     0.5985     0.4689      1.073          6        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:48<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.921      0.948      0.959      0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      4.51G     0.5943     0.4658      1.066         14        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:48<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.919       0.95      0.957      0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      4.55G     0.5874     0.4584      1.061         13        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:49<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.923      0.949      0.957      0.811\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      4.55G     0.5811     0.4581      1.062         15        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:44<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:17<00:00,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.922      0.949      0.957      0.813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      4.55G     0.5735     0.4493      1.058         13        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:44<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636       0.92      0.951      0.956      0.811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      4.55G     0.5694     0.4451      1.055         12        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [02:44<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.918      0.951      0.957      0.814\n",
      "\n",
      "50 epochs completed in 2.556 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 136.7MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 136.7MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics 8.3.34 ðŸš€ Python-3.10.13 torch-2.4.1.post302 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "Model summary (fused): 268 layers, 68,124,531 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:26<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.919      0.945      0.958       0.81\n",
      "Speed: 0.0ms preprocess, 9.8ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model, results = trainer.train(\"../../data/yolo/data.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = YOLOInference(\"yolov8x.pt\", \"runs/detect/train/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 detections\n"
     ]
    }
   ],
   "source": [
    "image, results = detector.predict_image(\n",
    "    \"../../data/extended/day/5/2024-05-13-18-20-03_jpg.rf.c5fbf2f48caf77a7b952411adc0cdf39.jpg\",\n",
    "    save_path=\"output.jpg\",\n",
    ")\n",
    "\n",
    "print(f\"Found {len(results.boxes) if results.boxes is not None else 0} detections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples_per_class(\n",
    "    detector: YOLOInference,\n",
    "    data_dir: str = \"../../data\",\n",
    "    samples_per_class: int = 10,\n",
    "    figsize: tuple = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize detection results for samples from each class\n",
    "    \"\"\"\n",
    "    class_dirs = sorted([d for d in Path(data_dir).glob(\"day/*\") if d.is_dir()])\n",
    "    n_classes = len(class_dirs)\n",
    "\n",
    "    if figsize is None:\n",
    "        figsize = (20, 4 * len(class_dirs))\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    for class_idx, class_dir in enumerate(class_dirs):\n",
    "        print(f\"Processing class {class_dir.name}\")\n",
    "\n",
    "        all_samples = list(class_dir.rglob(\"*.jpg\"))\n",
    "        if not all_samples:\n",
    "            continue\n",
    "\n",
    "        selected_samples = random.sample(all_samples, min(10, len(all_samples)))\n",
    "        for sample_idx, sample in enumerate(selected_samples):\n",
    "            try:\n",
    "                image, results = detector.predict_image(str(sample))\n",
    "\n",
    "                ax = fig.add_subplot(n_classes, 10, class_idx * 10 + sample_idx + 1)\n",
    "\n",
    "                ax.imshow(image)\n",
    "                ax.set_title(f\"Class {class_dir.name}\\n{len(results.boxes)} dets\")\n",
    "                ax.axis(\"off\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {sample}: {e}\")\n",
    "                continue\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"outputs_inference\")\n",
    "output_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [02:15<00:00, 10.45s/it]\n"
     ]
    }
   ],
   "source": [
    "for class_dir in tqdm(list(Path(\"../../data/extended/day/\").glob(\"*\"))):\n",
    "    if not class_dir.is_dir():\n",
    "        continue\n",
    "\n",
    "    class_output = output_dir / class_dir.name\n",
    "    class_output.mkdir(exist_ok=True)\n",
    "\n",
    "    for sample in class_dir.rglob(\"*.jpg\"):\n",
    "        image, results = detector.predict_image(\n",
    "            str(sample), save_path=str(class_output / sample.name)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 10/11 [01:35<00:09,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 2.050s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [01:43<00:00,  9.40s/it]\n"
     ]
    }
   ],
   "source": [
    "for class_dir in tqdm(list(Path(\"../../data/extended/night/\").glob(\"*\"))):\n",
    "    if not class_dir.is_dir():\n",
    "        continue\n",
    "\n",
    "    class_output = output_dir / class_dir.name\n",
    "    class_output.mkdir(exist_ok=True)\n",
    "\n",
    "    for sample in class_dir.rglob(\"*.jpg\"):\n",
    "        image, results = detector.predict_image(\n",
    "            str(sample), save_path=str(class_output / sample.name)\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
