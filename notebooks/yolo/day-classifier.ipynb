{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from collections import deque\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    epochs: int = 100\n",
    "    lr: float = 0.001\n",
    "    image_size: int = 250\n",
    "    batch_size: int = 16\n",
    "    device: str = \"0\"\n",
    "    patience: int = 20\n",
    "    dropout: float = 0.2\n",
    "    augment: bool = True\n",
    "    mosaic: float = 1.0\n",
    "    mixup: float = 0.3\n",
    "    copy_paste: float = 0.3\n",
    "    degrees: float = 45.0\n",
    "    translate: float = 0.2\n",
    "    scale: float = 0.5\n",
    "    shear: float = 10.0\n",
    "    perspective: float = 0.0005\n",
    "    flipud: float = 0.5\n",
    "    fliplr: float = 0.5\n",
    "    hsv_h: float = 0.015\n",
    "    hsv_s: float = 0.7\n",
    "    hsv_v: float = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DetectionConfig:\n",
    "    conf_threshold: float = 0.30\n",
    "    iou_threshold: float = 0.60\n",
    "    min_area: int = 500\n",
    "    max_overlap_ratio: float = 0.8\n",
    "    temporal_window: int = 3\n",
    "    enable_nms: bool = True\n",
    "    enable_temporal: bool = True\n",
    "    enable_size_filter: bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ConsistencyConfig:\n",
    "    num_inference_passes: int = 3\n",
    "    confidence_threshold: float = 0.3\n",
    "    consistency_threshold: float = 0.7\n",
    "\n",
    "    enable_tta: bool = True\n",
    "    tta_scales: List[float] = None\n",
    "    tta_flips: bool = True\n",
    "\n",
    "    min_detection_votes: int = 2\n",
    "    calibrate_confidence: bool = True\n",
    "    confidence_scaling_factor: float = 1.2\n",
    "    min_relative_size: float = 0.01\n",
    "    max_relative_size: float = 0.8\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.tta_scales is None:\n",
    "            self.tta_scales = [0.9, 1.0, 1.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection Tracker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionTracker:\n",
    "    def __init__(self, window_size: int = 3):\n",
    "        self.window_size = window_size\n",
    "        self.detection_history = deque(maxlen=window_size)\n",
    "\n",
    "    def update(self, detections: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Updates the detection history with the new detections and returns the\n",
    "        filtered detections.\n",
    "\n",
    "        Args:\n",
    "            detections (np.ndarray): The detections to be added to the history.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The filtered detections.\n",
    "        \"\"\"\n",
    "        if len(detections) == 0:\n",
    "            return detections\n",
    "\n",
    "        self.detection_history.append(detections)\n",
    "\n",
    "        if len(self.detection_history) < 2:\n",
    "            return detections\n",
    "\n",
    "        weights = np.linspace(0.5, 1.0, len(self.detection_history))\n",
    "        weights /= np.sum(weights)\n",
    "\n",
    "        smoothed = np.zeros_like(detections)\n",
    "        for i, (det, w) in enumerate(zip(self.detection_history, weights)):\n",
    "            if det.shape == detections.shape:\n",
    "                smoothed += w * det\n",
    "\n",
    "        return smoothed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOBase:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path: Union[str, Path],\n",
    "        detection_config: Optional[DetectionConfig] = None,\n",
    "    ):\n",
    "        self.model_path = Path(model_path)\n",
    "        self.detection_config = detection_config or DetectionConfig()\n",
    "        self.tracker = DetectionTracker(self.detection_config.temporal_window)\n",
    "        self.model = None\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def _load_model(self, weights_path: Optional[Path] = None) -> bool:\n",
    "        try:\n",
    "            if weights_path is not None and weights_path.exists():\n",
    "                self.model = YOLO(str(self.model_path))\n",
    "                self.model.to(self.device)\n",
    "                self.model.load(str(weights_path))\n",
    "\n",
    "                logging.info(\n",
    "                    f\"Loaded base model from {self.model_path} with weights from {weights_path}\"\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                self.model = YOLO(str(self.model_path))\n",
    "                self.model.to(self.device)\n",
    "                logging.info(f\"Loaded model from {self.model_path}\")\n",
    "\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to load model: {e}\")\n",
    "            return False\n",
    "\n",
    "    def _compute_intersection(self, box1: np.ndarray, box2: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Computes the intersection area between two bounding boxes.\n",
    "\n",
    "        Args:\n",
    "            box1 (np.ndarray): The first bounding box.\n",
    "            box2 (np.ndarray): The second bounding box.\n",
    "\n",
    "        Returns:\n",
    "            float: The intersection area.\n",
    "        \"\"\"\n",
    "        x1 = max(box1[0], box2[0])\n",
    "        y1 = max(box1[1], box2[1])\n",
    "        x2 = min(box1[2], box2[2])\n",
    "        y2 = min(box1[3], box2[3])\n",
    "\n",
    "        return max(0, x2 - x1) * max(0, y2 - y1)\n",
    "\n",
    "    def post_process_detection(\n",
    "        self, boxes: np.ndarray, scores: np.ndarray, class_ids: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Post-processes the raw detections by applying NMS and size filtering.\n",
    "\n",
    "        Args:\n",
    "            boxes (np.ndarray): The detected bounding boxes.\n",
    "            scores (np.ndarray): The detection scores.\n",
    "            class_ids (np.ndarray): The detected class IDs.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray, np.ndarray]: The post-processed detections.\n",
    "        \"\"\"\n",
    "\n",
    "        if len(boxes) == 0:\n",
    "            return boxes, scores, class_ids\n",
    "\n",
    "        if self.detection_config.enable_nms:\n",
    "            indices = cv2.dnn.NMSBoxes(\n",
    "                boxes.tolist(),\n",
    "                scores.tolist(),\n",
    "                self.detection_config.conf_threshold,\n",
    "                self.detection_config.iou_threshold,\n",
    "            )\n",
    "            boxes = boxes[indices.flatten()]\n",
    "            scores = scores[indices.flatten()]\n",
    "            class_ids = class_ids[indices.flatten()]\n",
    "\n",
    "        if self.detection_config.enable_size_filter:\n",
    "            areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "            mask = areas >= self.detection_config.min_area\n",
    "            boxes = boxes[mask]\n",
    "            scores = scores[mask]\n",
    "            class_ids = class_ids[mask]\n",
    "\n",
    "        final_boxes, final_scores, final_class_ids = [], [], []\n",
    "        for idx in range(len(boxes)):\n",
    "            overlap_too_high = False\n",
    "            box_area = (boxes[idx, 2] - boxes[idx, 0]) * (boxes[idx, 3] - boxes[idx, 1])\n",
    "\n",
    "            for j in range(len(final_boxes)):\n",
    "                intersection = self._compute_intersection(boxes[idx], final_boxes[j])\n",
    "                if intersection / box_area > self.detection_config.max_overlap_ratio:\n",
    "                    overlap_too_high = True\n",
    "                    break\n",
    "\n",
    "            if not overlap_too_high:\n",
    "                final_boxes.append(boxes[idx])\n",
    "                final_scores.append(scores[idx])\n",
    "                final_class_ids.append(class_ids[idx])\n",
    "\n",
    "        return np.array(final_boxes), np.array(final_scores), np.array(final_class_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOTrainer(YOLOBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path: Union[str, Path] = \"yolov8n.pt\",\n",
    "        training_config: Optional[TrainingConfig] = None,\n",
    "        detection_config: Optional[DetectionConfig] = None,\n",
    "    ):\n",
    "        super().__init__(model_path, detection_config)\n",
    "\n",
    "        self.training_config = training_config or TrainingConfig()\n",
    "        self._load_model()\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        data_yaml_path: Union[str, Path],\n",
    "        epochs: Optional[int] = 50,\n",
    "        image_size: Optional[int] = 320,\n",
    "        batch_size: Optional[int] = 16,\n",
    "    ):\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        else:\n",
    "            print(\"Using CPU\")\n",
    "            return\n",
    "\n",
    "        data_yaml_path = Path(data_yaml_path).resolve()\n",
    "        data_dir = data_yaml_path.parent\n",
    "\n",
    "        train_path = (data_dir / \"train\" / \"images\").resolve()\n",
    "        val_path = (data_dir / \"valid\" / \"images\").resolve()\n",
    "        self._verify_data_paths(train_path, val_path)\n",
    "\n",
    "        data_config = self._create_data_config(train_path, val_path)\n",
    "        with open(data_yaml_path, \"w\") as f:\n",
    "            yaml.safe_dump(data_config, f, sort_keys=False)\n",
    "\n",
    "        torch.cuda.set_device(0)\n",
    "        self.results = self.model.train(\n",
    "            data=data_yaml_path,\n",
    "            epochs=epochs or self.training_config.epochs,\n",
    "            imgsz=image_size or self.training_config.image_size,\n",
    "            batch=batch_size or self.training_config.batch_size,\n",
    "            device=self.training_config.device,\n",
    "            patience=self.training_config.patience,\n",
    "            save=True,\n",
    "            plots=True,\n",
    "            augment=self.training_config.augment,\n",
    "            dropout=self.training_config.dropout,\n",
    "            **{\n",
    "                k: v\n",
    "                for k, v in vars(self.training_config).items()\n",
    "                if k in [\"mosaic\", \"mixup\", \"copy_paste\"]\n",
    "            },\n",
    "        )\n",
    "\n",
    "        return self.model, self.results\n",
    "\n",
    "    def _create_data_config(self, train_path: Path, val_path: Path) -> dict:\n",
    "        \"\"\"Create YOLO training configuration\"\"\"\n",
    "        config = {\n",
    "            \"train\": str(train_path),\n",
    "            \"val\": str(val_path),\n",
    "            \"nc\": 1,\n",
    "            \"names\": [\"cow\"],\n",
    "        }\n",
    "\n",
    "        augment_params = {\n",
    "            k: v\n",
    "            for k, v in vars(self.training_config).items()\n",
    "            if k\n",
    "            in [\n",
    "                \"mosaic\",\n",
    "                \"mixup\",\n",
    "                \"copy_paste\",\n",
    "                \"degrees\",\n",
    "                \"translate\",\n",
    "                \"scale\",\n",
    "                \"shear\",\n",
    "                \"perspective\",\n",
    "                \"flipud\",\n",
    "                \"fliplr\",\n",
    "                \"hsv_h\",\n",
    "                \"hsv_s\",\n",
    "                \"hsv_v\",\n",
    "            ]\n",
    "        }\n",
    "        config.update(augment_params)\n",
    "        return config\n",
    "\n",
    "    def _verify_data_paths(self, train_path: Path, val_path: Path):\n",
    "        \"\"\"Verify that data paths exist\"\"\"\n",
    "        if not train_path.exists():\n",
    "            raise FileNotFoundError(f\"Training directory not found: {train_path}\")\n",
    "\n",
    "        if not val_path.exists():\n",
    "            raise FileNotFoundError(f\"Validation directory not found: {val_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOInference:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path: str = \"yolov8m.pt\",\n",
    "        weights_path: Optional[str] = None,\n",
    "        detection_config: Optional[DetectionConfig] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize YOLO model with optional custom weights\n",
    "        \"\"\"\n",
    "        if weights_path:\n",
    "            self.model = YOLO(weights_path)\n",
    "\n",
    "        else:\n",
    "            self.model = YOLO(model_path)\n",
    "\n",
    "        self.detection_config = detection_config or DetectionConfig()\n",
    "        self.tracker = DetectionTracker(self.detection_config.temporal_window)\n",
    "\n",
    "    def post_process(self, results):\n",
    "        if results.boxes is None or len(results.boxes) == 0:\n",
    "            return results\n",
    "\n",
    "        boxes = results.boxes.cpu().numpy()\n",
    "        areas, confidences = [], []\n",
    "\n",
    "        for box in boxes:\n",
    "            xyxy = box.xyxy[0]\n",
    "            area = (xyxy[2] - xyxy[0]) * (xyxy[3] - xyxy[1])\n",
    "            areas.append(area)\n",
    "            confidences.append(float(box.conf[0]))\n",
    "\n",
    "        areas = np.array(areas)\n",
    "        confidences = np.array(confidences)\n",
    "        mask = (areas >= self.detection_config.min_area) & (\n",
    "            confidences >= self.detection_config.conf_threshold\n",
    "        )\n",
    "\n",
    "        results.boxes = results.boxes[mask]\n",
    "        return results\n",
    "\n",
    "    def predict_image(\n",
    "        self,\n",
    "        image_path: str,\n",
    "        save_path: Optional[str] = None,\n",
    "        conf_threshold: float = 0.3,\n",
    "        iou_threshold: float = 0.7,\n",
    "    ) -> Tuple[np.ndarray, Any]:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Failed to read image: {image_path}\")\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        conf_threshold = conf_threshold or self.detection_config.conf_threshold\n",
    "        iou_threshold = iou_threshold or self.detection_config.iou_threshold\n",
    "\n",
    "        results = self.model(\n",
    "            image, verbose=False, conf=conf_threshold, iou=iou_threshold, max_det=20\n",
    "        )[0]\n",
    "\n",
    "        results = self.post_process(results)\n",
    "        annotated_image = image.copy()\n",
    "\n",
    "        if results.boxes is not None and len(results.boxes) > 0:\n",
    "            boxes = results.boxes.cpu().numpy()\n",
    "            confidences = [float(box.conf[0]) for box in boxes]\n",
    "            sorted_indices = np.argsort(confidences)[::-1]\n",
    "\n",
    "            for idx in sorted_indices:\n",
    "                box = boxes[idx]\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                confidence = float(box.conf[0])\n",
    "\n",
    "                cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "                label = f\"cow {confidence:.2f}\"\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                font_scale = 0.6\n",
    "                thickness = 2\n",
    "\n",
    "                (label_width, label_height), baseline = cv2.getTextSize(\n",
    "                    label, font, font_scale, thickness\n",
    "                )\n",
    "\n",
    "                label_patch = (\n",
    "                    np.ones(\n",
    "                        (label_height + 2 * baseline, label_width + 2 * baseline, 3),\n",
    "                        dtype=np.uint8,\n",
    "                    )\n",
    "                    * 255\n",
    "                )\n",
    "\n",
    "                cv2.putText(\n",
    "                    label_patch,\n",
    "                    label,\n",
    "                    (baseline, label_height),\n",
    "                    font,\n",
    "                    font_scale,\n",
    "                    (0, 0, 0),\n",
    "                    thickness,\n",
    "                )\n",
    "\n",
    "                label_y = max(y1 - label_height - baseline, 0)\n",
    "                label_x = max(x1, 0)\n",
    "\n",
    "                if (\n",
    "                    label_y + label_height <= image.shape[0]\n",
    "                    and label_x + label_width <= image.shape[1]\n",
    "                ):\n",
    "                    try:\n",
    "                        roi = annotated_image[\n",
    "                            label_y : label_y + label_height + 2 * baseline,\n",
    "                            label_x : label_x + label_width + 2 * baseline,\n",
    "                        ]\n",
    "\n",
    "                        alpha = 0.7\n",
    "                        cv2.addWeighted(label_patch, alpha, roi, 1 - alpha, 0, roi)\n",
    "\n",
    "                        annotated_image[\n",
    "                            label_y : label_y + label_height + 2 * baseline,\n",
    "                            label_x : label_x + label_width + 2 * baseline,\n",
    "                        ] = roi\n",
    "                    except Exception as e:\n",
    "                        cv2.putText(\n",
    "                            annotated_image,\n",
    "                            label,\n",
    "                            (label_x, label_y + label_height),\n",
    "                            font,\n",
    "                            font_scale,\n",
    "                            (0, 0, 0),\n",
    "                            thickness,\n",
    "                        )\n",
    "\n",
    "        if save_path:\n",
    "            save_dir = Path(save_path).parent\n",
    "            save_dir.mkdir(parents=True, exist_ok=True)\n",
    "            cv2.imwrite(\n",
    "                str(save_path), cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR)\n",
    "            )\n",
    "\n",
    "        return annotated_image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inference_pipeline(\n",
    "    base_model_path: str = \"yolov8m.pt\",\n",
    "    weights_path: str = \"runs/detect/train29/weights/last.pt\",\n",
    "    **config_kwargs,\n",
    ") -> YOLOInference:\n",
    "    \"\"\"Creates an inference pipeline with specified weights.\"\"\"\n",
    "    consistency_config = ConsistencyConfig(\n",
    "        **{k: v for k, v in config_kwargs.items() if hasattr(ConsistencyConfig, k)}\n",
    "    )\n",
    "\n",
    "    detection_config = DetectionConfig(\n",
    "        **{k: v for k, v in config_kwargs.items() if hasattr(DetectionConfig, k)}\n",
    "    )\n",
    "\n",
    "    return YOLOInference(\n",
    "        model_path=base_model_path,\n",
    "        weights_path=weights_path,\n",
    "        consistency_config=consistency_config,\n",
    "        detection_config=detection_config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_config = DetectionConfig(\n",
    "    conf_threshold=0.4,\n",
    "    iou_threshold=0.70,\n",
    "    min_area=300,\n",
    "    max_overlap_ratio=0.65,\n",
    "    enable_temporal=False,\n",
    ")\n",
    "\n",
    "training_config = TrainingConfig(epochs=100, image_size=640, batch_size=16, dropout=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 17:20:26,886 - INFO - Loaded model from yolov9c.pt\n"
     ]
    }
   ],
   "source": [
    "trainer = YOLOTrainer(\n",
    "    model_path=\"yolov9c.pt\",\n",
    "    training_config=training_config,\n",
    "    detection_config=detection_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training device: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training device: {trainer.training_config.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Ultralytics 8.3.34 ðŸš€ Python-3.10.13 torch-2.4.1.post302 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov9c.pt, data=/home/carlos/developer/cow-project/data/yolo/data.yaml, epochs=50, time=None, patience=20, batch=4, imgsz=320, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train14, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.3, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.3, copy_paste=0.3, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732144827.865939    3566 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732144827.883609    3566 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  1    212864  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 256, 128, 64, 1]        \n",
      "  3                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n",
      "  4                  -1  1    847616  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 512, 256, 128, 1]       \n",
      "  5                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n",
      "  6                  -1  1   2857472  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 512, 512, 256, 1]       \n",
      "  7                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n",
      "  8                  -1  1   2857472  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 512, 512, 256, 1]       \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPELAN         [512, 512, 256]               \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1   3119616  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 512, 512, 256, 1]      \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    912640  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 256, 256, 128, 1]      \n",
      " 16                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1   2988544  ultralytics.nn.modules.block.RepNCSPELAN4    [768, 512, 512, 256, 1]       \n",
      " 19                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   3119616  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 512, 512, 256, 1]      \n",
      " 22        [15, 18, 21]  1   5583571  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "YOLOv9c summary: 618 layers, 25,530,003 parameters, 25,529,987 gradients, 103.7 GFLOPs\n",
      "\n",
      "Transferred 931/937 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train14', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/carlos/developer/cow-project/data/yolo/train/labels.cache... 6469 images, 1218 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7283/7283 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlos/miniconda3/envs/ml/lib/python3.10/site-packages/albumentations/check_version.py:49: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "  data = fetch_version_info()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/carlos/developer/cow-project/data/yolo/valid/labels.cache... 1618 images, 144 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1658/1658 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train14/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 154 weight(decay=0.0), 161 weight(decay=0.0005), 160 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 320 train, 320 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train14\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50     0.866G      1.338      1.224      1.522         14        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [05:47<00:00,  5.24it/s] \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:15<00:00, 13.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.888      0.864      0.918       0.66\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      1.37G      1.321      1.153      1.522         31        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:37<00:00,  6.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:19<00:00, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.898      0.889      0.931      0.685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      1.37G      1.272      1.101      1.495         17        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [05:10<00:00,  5.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:14<00:00, 14.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.862      0.857      0.899      0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      1.36G      1.202      1.031      1.453         28        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:09<00:00,  7.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 104/208 [00:07<00:07, 14.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 2.400s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:17<00:00, 12.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.907      0.907      0.933      0.695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      1.38G      1.153     0.9759      1.417         41        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [03:54<00:00,  7.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:17<00:00, 11.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.903      0.915      0.945      0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      1.37G      1.126      0.949      1.404         26        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [03:58<00:00,  7.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:14<00:00, 14.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.909       0.91      0.944      0.727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      1.39G      1.098     0.9197      1.386         14        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [03:52<00:00,  7.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:14<00:00, 14.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.908      0.922      0.946      0.728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      1.37G      1.075     0.8934      1.367         17        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [03:51<00:00,  7.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:14<00:00, 14.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.912      0.926      0.947      0.738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      1.36G      1.061     0.8721      1.359         54        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:08<00:00,  7.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 74/208 [00:05<00:08, 15.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 2.400s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:17<00:00, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.907       0.94      0.946      0.746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      1.38G      1.046     0.8601      1.349         17        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:24<00:00,  6.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  20%|â–ˆâ–ˆ        | 42/208 [00:03<00:14, 11.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 2.400s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:21<00:00,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.916      0.935      0.951      0.752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      1.37G      1.021     0.8449      1.336         36        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:03<00:00,  7.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:14<00:00, 14.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.918      0.934       0.95      0.754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      1.39G      1.012     0.8327      1.329         29        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:10<00:00,  7.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:17<00:00, 12.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.916      0.937      0.951      0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      1.39G      1.002     0.8258      1.321         34        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:16<00:00,  7.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:19<00:00, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.913      0.933      0.951      0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      1.38G     0.9939     0.8277      1.318         10        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:33<00:00,  6.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:14<00:00, 14.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.915      0.937      0.952      0.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      1.39G     0.9836     0.8063      1.316         43        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:02<00:00,  7.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:14<00:00, 14.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.917      0.937      0.952      0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      1.38G     0.9767     0.7984      1.306         20        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:00<00:00,  7.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:17<00:00, 12.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.916      0.934      0.952      0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      1.36G     0.9642     0.7921      1.298         30        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:20<00:00,  6.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:21<00:00,  9.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.923      0.938      0.954       0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      1.39G     0.9509     0.7784      1.287         21        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:33<00:00,  6.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:18<00:00, 11.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.919      0.942      0.956      0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      1.37G     0.9397     0.7738      1.283         38        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:50<00:00,  6.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:20<00:00,  9.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636       0.92      0.942      0.953      0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      1.37G     0.9364     0.7637      1.277         22        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:34<00:00,  6.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:18<00:00, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.926      0.945      0.954      0.783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      1.39G     0.9305     0.7671      1.275         18        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:02<00:00,  7.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:21<00:00,  9.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.915       0.95      0.954       0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      1.37G     0.9309     0.7563      1.277         33        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:00<00:00,  7.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:19<00:00, 10.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.919      0.942      0.951      0.778\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      1.36G     0.9206     0.7532       1.27         37        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [03:52<00:00,  7.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:14<00:00, 14.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636       0.92      0.942      0.956      0.786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      1.36G     0.9169     0.7461      1.265         13        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [03:54<00:00,  7.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:14<00:00, 14.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.923       0.94      0.955      0.786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      1.39G     0.9129      0.742      1.262         33        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [03:54<00:00,  7.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:17<00:00, 11.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.916      0.949      0.957      0.792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      1.39G     0.8936      0.733      1.254         48        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [03:51<00:00,  7.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:17<00:00, 12.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.919      0.945      0.954      0.786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      1.39G     0.8949     0.7266      1.253         17        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [03:53<00:00,  7.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:17<00:00, 12.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.917      0.949      0.955      0.795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      1.38G     0.8926      0.728      1.252         63        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [03:50<00:00,  7.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:17<00:00, 12.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.921      0.946      0.955       0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50       1.4G     0.8798     0.7106      1.242         32        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [03:54<00:00,  7.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:15<00:00, 13.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.919      0.946      0.956      0.791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50      1.38G     0.8813     0.7137      1.243         68        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:12<00:00,  7.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:18<00:00, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.921      0.948      0.955      0.796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      1.39G     0.8761     0.7109       1.24         42        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:37<00:00,  6.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:18<00:00, 11.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.923      0.947      0.956      0.796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      1.36G     0.8711     0.7015      1.242         35        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:37<00:00,  6.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:21<00:00,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.918      0.945      0.957      0.797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      1.36G     0.8573     0.6979      1.229         29        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [03:51<00:00,  7.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:18<00:00, 11.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.919      0.952      0.957      0.801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      1.36G     0.8548     0.7002      1.228         20        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:00<00:00,  7.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:18<00:00, 11.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.918      0.948      0.955      0.796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50       1.4G     0.8459     0.6871      1.222         10        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:02<00:00,  7.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:14<00:00, 14.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.916       0.95      0.954      0.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      1.39G     0.8447     0.6846       1.22         25        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:10<00:00,  7.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:18<00:00, 11.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.916       0.95      0.956      0.796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      1.38G     0.8399     0.6806      1.221         34        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [03:57<00:00,  7.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:18<00:00, 11.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.918       0.95      0.957      0.801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      1.38G     0.8326     0.6798      1.213         30        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:04<00:00,  7.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:14<00:00, 14.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.918      0.947      0.955      0.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      1.39G     0.8336     0.6776      1.216         33        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:01<00:00,  7.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:14<00:00, 14.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.916      0.953      0.956      0.802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      1.39G     0.8208     0.6689      1.205         17        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:06<00:00,  7.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:18<00:00, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.917      0.954      0.956      0.807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      1.39G     0.6886     0.6438      1.122         17        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:07<00:00,  7.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:14<00:00, 14.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.918      0.952      0.957      0.803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      1.38G     0.6798     0.6239      1.118          7        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:06<00:00,  7.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:14<00:00, 14.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.918      0.947      0.956      0.801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      1.36G     0.6719     0.7036       1.11         20        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:32<00:00,  6.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:14<00:00, 13.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.921      0.952      0.957      0.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      1.38G     0.6673     0.5827      1.109         14        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:30<00:00,  6.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:15<00:00, 13.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.927      0.943      0.957      0.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      1.37G     0.6584     0.6451      1.104          6        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:52<00:00,  6.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:14<00:00, 13.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.922      0.948      0.959      0.809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      1.38G      0.645     0.6788      1.097         14        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:38<00:00,  6.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:18<00:00, 11.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.923      0.948      0.956      0.806\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      1.39G     0.6432     0.6673      1.093         13        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [05:09<00:00,  5.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 176/208 [00:15<00:02, 10.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 2.400s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:22<00:00,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.921      0.947      0.956      0.805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      1.38G     0.6345      0.607      1.091         15        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:52<00:00,  6.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:19<00:00, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.923      0.946      0.957       0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      1.38G     0.6285     0.5469      1.084         13        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:07<00:00,  7.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:18<00:00, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.925      0.949      0.957      0.811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      1.36G      0.621     0.6488      1.075         12        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [04:04<00:00,  7.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:14<00:00, 14.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.922      0.949      0.956      0.811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 3.809 hours.\n",
      "Optimizer stripped from runs/detect/train14/weights/last.pt, 51.5MB\n",
      "Optimizer stripped from runs/detect/train14/weights/best.pt, 51.5MB\n",
      "\n",
      "Validating runs/detect/train14/weights/best.pt...\n",
      "Ultralytics 8.3.34 ðŸš€ Python-3.10.13 torch-2.4.1.post302 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "YOLOv9c summary (fused): 384 layers, 25,320,019 parameters, 0 gradients, 102.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [00:24<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.918      0.945      0.955      0.804\n",
      "Speed: 0.1ms preprocess, 10.2ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train14\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model, results = trainer.train(\"../../data/yolo/data.yaml\", epochs=50, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = YOLOInference(\n",
    "    \"yolov9c.pt\",\n",
    "    \"runs/detect/train14/weights/best.pt\",\n",
    "    detection_config=detection_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 detections\n"
     ]
    }
   ],
   "source": [
    "image, results = detector.predict_image(\n",
    "    \"../../data/extended/day/5/2024-05-13-18-20-03_jpg.rf.c5fbf2f48caf77a7b952411adc0cdf39.jpg\",\n",
    "    save_path=\"output.jpg\",\n",
    ")\n",
    "\n",
    "print(f\"Found {len(results.boxes) if results.boxes is not None else 0} detections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples_per_class(\n",
    "    detector: YOLOInference,\n",
    "    data_dir: str = \"../../data\",\n",
    "    samples_per_class: int = 10,\n",
    "    figsize: tuple = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize detection results for samples from each class\n",
    "    \"\"\"\n",
    "    class_dirs = sorted([d for d in Path(data_dir).glob(\"day/*\") if d.is_dir()])\n",
    "    n_classes = len(class_dirs)\n",
    "\n",
    "    if figsize is None:\n",
    "        figsize = (20, 4 * len(class_dirs))\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    for class_idx, class_dir in enumerate(class_dirs):\n",
    "        print(f\"Processing class {class_dir.name}\")\n",
    "\n",
    "        all_samples = list(class_dir.rglob(\"*.jpg\"))\n",
    "        if not all_samples:\n",
    "            continue\n",
    "\n",
    "        selected_samples = random.sample(all_samples, min(10, len(all_samples)))\n",
    "        for sample_idx, sample in enumerate(selected_samples):\n",
    "            try:\n",
    "                image, results = detector.predict_image(str(sample))\n",
    "\n",
    "                ax = fig.add_subplot(n_classes, 10, class_idx * 10 + sample_idx + 1)\n",
    "\n",
    "                ax.imshow(image)\n",
    "                ax.set_title(f\"Class {class_dir.name}\\n{len(results.boxes)} dets\")\n",
    "                ax.axis(\"off\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {sample}: {e}\")\n",
    "                continue\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"outputs_inference\")\n",
    "output_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [05:31<00:56, 28.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 2.050s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [06:51<00:00, 31.64s/it]\n"
     ]
    }
   ],
   "source": [
    "for class_dir in tqdm(list(Path(\"../../data/extended/day/\").glob(\"*\"))):\n",
    "    if not class_dir.is_dir():\n",
    "        continue\n",
    "\n",
    "    class_output = output_dir / class_dir.name\n",
    "    class_output.mkdir(exist_ok=True)\n",
    "\n",
    "    for sample in class_dir.rglob(\"*.jpg\"):\n",
    "        image, results = detector.predict_image(\n",
    "            str(sample), save_path=str(class_output / sample.name)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [05:18<00:00, 28.91s/it]\n"
     ]
    }
   ],
   "source": [
    "for class_dir in tqdm(list(Path(\"../../data/extended/night/\").glob(\"*\"))):\n",
    "    if not class_dir.is_dir():\n",
    "        continue\n",
    "\n",
    "    class_output = output_dir / class_dir.name\n",
    "    class_output.mkdir(exist_ok=True)\n",
    "\n",
    "    for sample in class_dir.rglob(\"*.jpg\"):\n",
    "        image, results = detector.predict_image(\n",
    "            str(sample), save_path=str(class_output / sample.name)\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
