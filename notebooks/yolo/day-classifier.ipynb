{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 10:44:58.354340: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-11 10:44:58.361697: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-11 10:44:58.371517: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-11 10:44:58.374403: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-11 10:44:58.381822: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from collections import deque\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    epochs: int = 100\n",
    "    image_size: int = 250\n",
    "    batch_size: int = 16\n",
    "    device: str = \"0\"\n",
    "    patience: int = 20\n",
    "    dropout: float = 0.2\n",
    "    augment: bool = True\n",
    "    mosaic: float = 1.0\n",
    "    mixup: float = 0.3\n",
    "    copy_paste: float = 0.3\n",
    "    degrees: float = 45.0\n",
    "    translate: float = 0.2\n",
    "    scale: float = 0.5\n",
    "    shear: float = 10.0\n",
    "    perspective: float = 0.0005\n",
    "    flipud: float = 0.5\n",
    "    fliplr: float = 0.5\n",
    "    hsv_h: float = 0.015\n",
    "    hsv_s: float = 0.7\n",
    "    hsv_v: float = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DetectionConfig:\n",
    "    conf_threshold: float = 0.30\n",
    "    iou_threshold: float = 0.60\n",
    "    min_area: int = 500\n",
    "    max_overlap_ratio: float = 0.8\n",
    "    temporal_window: int = 3\n",
    "    enable_nms: bool = True\n",
    "    enable_temporal: bool = True\n",
    "    enable_size_filter: bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ConsistencyConfig:\n",
    "    num_inference_passes: int = 3\n",
    "    confidence_threshold: float = 0.3\n",
    "    consistency_threshold: float = 0.7\n",
    "\n",
    "    enable_tta: bool = True\n",
    "    tta_scales: List[float] = None\n",
    "    tta_flips: bool = True\n",
    "\n",
    "    min_detection_votes: int = 2\n",
    "    calibrate_confidence: bool = True\n",
    "    confidence_scaling_factor: float = 1.2\n",
    "    min_relative_size: float = 0.01\n",
    "    max_relative_size: float = 0.8\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.tta_scales is None:\n",
    "            self.tta_scales = [0.9, 1.0, 1.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection Tracker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionTracker:\n",
    "    def __init__(self, window_size: int = 3):\n",
    "        self.window_size = window_size\n",
    "        self.detection_history = deque(maxlen=window_size)\n",
    "\n",
    "    def update(self, detections: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Updates the detection history with the new detections and returns the\n",
    "        filtered detections.\n",
    "\n",
    "        Args:\n",
    "            detections (np.ndarray): The detections to be added to the history.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The filtered detections.\n",
    "        \"\"\"\n",
    "        if len(detections) == 0:\n",
    "            return detections\n",
    "\n",
    "        self.detection_history.append(detections)\n",
    "\n",
    "        if len(self.detection_history) < 2:\n",
    "            return detections\n",
    "\n",
    "        weights = np.linspace(0.5, 1.0, len(self.detection_history))\n",
    "        weights /= np.sum(weights)\n",
    "\n",
    "        smoothed = np.zeros_like(detections)\n",
    "        for i, (det, w) in enumerate(zip(self.detection_history, weights)):\n",
    "            if det.shape == detections.shape:\n",
    "                smoothed += w * det\n",
    "\n",
    "        return smoothed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOBase:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path: Union[str, Path],\n",
    "        detection_config: Optional[DetectionConfig] = None,\n",
    "    ):\n",
    "        self.model_path = Path(model_path)\n",
    "        self.detection_config = detection_config or DetectionConfig()\n",
    "        self.tracker = DetectionTracker(self.detection_config.temporal_window)\n",
    "        self.model = None\n",
    "\n",
    "    def _load_model(self, weights_path: Optional[Path] = None) -> bool:\n",
    "        try:\n",
    "            if weights_path is not None and weights_path.exists():\n",
    "                self.model = YOLO(str(self.model_path))\n",
    "                self.model.load(str(weights_path))\n",
    "                logging.info(\n",
    "                    f\"Loaded base model from {self.model_path} with weights from {weights_path}\"\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                self.model = YOLO(str(self.model_path))\n",
    "                logging.info(f\"Loaded model from {self.model_path}\")\n",
    "\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to load model: {e}\")\n",
    "            return False\n",
    "\n",
    "    def _compute_intersection(self, box1: np.ndarray, box2: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Computes the intersection area between two bounding boxes.\n",
    "\n",
    "        Args:\n",
    "            box1 (np.ndarray): The first bounding box.\n",
    "            box2 (np.ndarray): The second bounding box.\n",
    "\n",
    "        Returns:\n",
    "            float: The intersection area.\n",
    "        \"\"\"\n",
    "        x1 = max(box1[0], box2[0])\n",
    "        y1 = max(box1[1], box2[1])\n",
    "        x2 = min(box1[2], box2[2])\n",
    "        y2 = min(box1[3], box2[3])\n",
    "\n",
    "        return max(0, x2 - x1) * max(0, y2 - y1)\n",
    "\n",
    "    def post_process_detection(\n",
    "        self, boxes: np.ndarray, scores: np.ndarray, class_ids: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Post-processes the raw detections by applying NMS and size filtering.\n",
    "\n",
    "        Args:\n",
    "            boxes (np.ndarray): The detected bounding boxes.\n",
    "            scores (np.ndarray): The detection scores.\n",
    "            class_ids (np.ndarray): The detected class IDs.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray, np.ndarray]: The post-processed detections.\n",
    "        \"\"\"\n",
    "\n",
    "        if len(boxes) == 0:\n",
    "            return boxes, scores, class_ids\n",
    "\n",
    "        if self.detection_config.enable_nms:\n",
    "            indices = cv2.dnn.NMSBoxes(\n",
    "                boxes.tolist(),\n",
    "                scores.tolist(),\n",
    "                self.detection_config.conf_threshold,\n",
    "                self.detection_config.iou_threshold,\n",
    "            )\n",
    "            boxes = boxes[indices.flatten()]\n",
    "            scores = scores[indices.flatten()]\n",
    "            class_ids = class_ids[indices.flatten()]\n",
    "\n",
    "        if self.detection_config.enable_size_filter:\n",
    "            areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "            mask = areas >= self.detection_config.min_area\n",
    "            boxes = boxes[mask]\n",
    "            scores = scores[mask]\n",
    "            class_ids = class_ids[mask]\n",
    "\n",
    "        final_boxes, final_scores, final_class_ids = [], [], []\n",
    "        for idx in range(len(boxes)):\n",
    "            overlap_too_high = False\n",
    "            box_area = (boxes[idx, 2] - boxes[idx, 0]) * (boxes[idx, 3] - boxes[idx, 1])\n",
    "\n",
    "            for j in range(len(final_boxes)):\n",
    "                intersection = self._compute_intersection(boxes[idx], final_boxes[j])\n",
    "                if intersection / box_area > self.detection_config.max_overlap_ratio:\n",
    "                    overlap_too_high = True\n",
    "                    break\n",
    "\n",
    "            if not overlap_too_high:\n",
    "                final_boxes.append(boxes[idx])\n",
    "                final_scores.append(scores[idx])\n",
    "                final_class_ids.append(class_ids[idx])\n",
    "\n",
    "        return np.array(final_boxes), np.array(final_scores), np.array(final_class_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOTrainer(YOLOBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path: Union[str, Path] = \"yolov8n.pt\",\n",
    "        training_config: Optional[TrainingConfig] = None,\n",
    "        detection_config: Optional[DetectionConfig] = None,\n",
    "    ):\n",
    "        super().__init__(model_path, detection_config)\n",
    "\n",
    "        self.training_config = training_config or TrainingConfig()\n",
    "        self._load_model()\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        data_yaml_path: Union[str, Path],\n",
    "        epochs: Optional[int] = 50,\n",
    "        image_size: Optional[int] = 320,\n",
    "        batch_size: Optional[int] = 16,\n",
    "    ):\n",
    "        data_yaml_path = Path(data_yaml_path).resolve()\n",
    "        data_dir = data_yaml_path.parent\n",
    "\n",
    "        train_path = (data_dir / \"train\" / \"images\").resolve()\n",
    "        val_path = (data_dir / \"valid\" / \"images\").resolve()\n",
    "        self._verify_data_paths(train_path, val_path)\n",
    "\n",
    "        data_config = self._create_data_config(train_path, val_path)\n",
    "        with open(data_yaml_path, \"w\") as f:\n",
    "            yaml.safe_dump(data_config, f, sort_keys=False)\n",
    "\n",
    "        self.results = self.model.train(\n",
    "            data=data_yaml_path,\n",
    "            epochs=epochs or self.training_config.epochs,\n",
    "            imgsz=image_size or self.training_config.image_size,\n",
    "            batch=batch_size or self.training_config.batch_size,\n",
    "            device=self.training_config.device,\n",
    "            patience=self.training_config.patience,\n",
    "            save=True,\n",
    "            plots=True,\n",
    "            augment=self.training_config.augment,\n",
    "            dropout=self.training_config.dropout,\n",
    "            **{\n",
    "                k: v\n",
    "                for k, v in vars(self.training_config).items()\n",
    "                if k in [\"mosaic\", \"mixup\", \"copy_paste\"]\n",
    "            },\n",
    "        )\n",
    "\n",
    "        return self.model, self.results\n",
    "\n",
    "    def _create_data_config(self, train_path: Path, val_path: Path) -> dict:\n",
    "        \"\"\"Create YOLO training configuration\"\"\"\n",
    "        config = {\n",
    "            \"train\": str(train_path),\n",
    "            \"val\": str(val_path),\n",
    "            \"nc\": 1,\n",
    "            \"names\": [\"cow\"],\n",
    "        }\n",
    "\n",
    "        augment_params = {\n",
    "            k: v\n",
    "            for k, v in vars(self.training_config).items()\n",
    "            if k\n",
    "            in [\n",
    "                \"mosaic\",\n",
    "                \"mixup\",\n",
    "                \"copy_paste\",\n",
    "                \"degrees\",\n",
    "                \"translate\",\n",
    "                \"scale\",\n",
    "                \"shear\",\n",
    "                \"perspective\",\n",
    "                \"flipud\",\n",
    "                \"fliplr\",\n",
    "                \"hsv_h\",\n",
    "                \"hsv_s\",\n",
    "                \"hsv_v\",\n",
    "            ]\n",
    "        }\n",
    "        config.update(augment_params)\n",
    "        return config\n",
    "\n",
    "    def _verify_data_paths(self, train_path: Path, val_path: Path):\n",
    "        \"\"\"Verify that data paths exist\"\"\"\n",
    "        if not train_path.exists():\n",
    "            raise FileNotFoundError(f\"Training directory not found: {train_path}\")\n",
    "\n",
    "        if not val_path.exists():\n",
    "            raise FileNotFoundError(f\"Validation directory not found: {val_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOInference:\n",
    "    def __init__(\n",
    "        self, model_path: str = \"yolov8m.pt\", weights_path: Optional[str] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize YOLO model with optional custom weights\n",
    "        \"\"\"\n",
    "        if weights_path:\n",
    "            self.model = YOLO(weights_path)\n",
    "\n",
    "        else:\n",
    "            self.model = YOLO(model_path)\n",
    "\n",
    "    def predict_image(\n",
    "        self,\n",
    "        image_path: str,\n",
    "        save_path: Optional[str] = None,\n",
    "        conf_threshold: float = 0.3,\n",
    "        iou_threshold: float = 0.7,\n",
    "    ) -> Tuple[np.ndarray, Any]:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Could not read image: {image_path}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Run inference with NMS parameters\n",
    "        results = self.model(\n",
    "            image, verbose=False, conf=conf_threshold, iou=iou_threshold, max_det=20\n",
    "        )[0]\n",
    "\n",
    "        # Draw boxes\n",
    "        annotated_image = image.copy()\n",
    "        if results.boxes is not None and len(results.boxes) > 0:\n",
    "            boxes = results.boxes.cpu().numpy()\n",
    "\n",
    "            # Sort boxes by confidence\n",
    "            confidences = [float(box.conf[0]) for box in boxes]\n",
    "            sorted_indices = np.argsort(confidences)[::-1]\n",
    "\n",
    "            for idx in sorted_indices:\n",
    "                box = boxes[idx]\n",
    "                # Get coordinates and confidence\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                confidence = float(box.conf[0])\n",
    "\n",
    "                # Draw box\n",
    "                cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "                # Create label\n",
    "                label = f\"{confidence:.2f}\"\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                font_scale = 0.6\n",
    "                thickness = 2\n",
    "\n",
    "                # Get label size\n",
    "                (label_width, label_height), baseline = cv2.getTextSize(\n",
    "                    label, font, font_scale, thickness\n",
    "                )\n",
    "\n",
    "                # Draw label background\n",
    "                label_patch = (\n",
    "                    np.ones(\n",
    "                        (label_height + 2 * baseline, label_width + 2 * baseline, 3),\n",
    "                        dtype=np.uint8,\n",
    "                    )\n",
    "                    * 255\n",
    "                )\n",
    "                cv2.putText(\n",
    "                    label_patch,\n",
    "                    label,\n",
    "                    (baseline, label_height),\n",
    "                    font,\n",
    "                    font_scale,\n",
    "                    (0, 0, 0),\n",
    "                    thickness,\n",
    "                )\n",
    "\n",
    "                # Calculate label position\n",
    "                label_y = max(y1 - label_height - baseline, 0)\n",
    "                label_x = max(x1, 0)\n",
    "\n",
    "                # Add label to image using alpha blending\n",
    "                if (\n",
    "                    label_y + label_height <= image.shape[0]\n",
    "                    and label_x + label_width <= image.shape[1]\n",
    "                ):\n",
    "                    alpha = 0.7\n",
    "                    label_height, label_width = label_patch.shape[:2]\n",
    "                    roi = annotated_image[\n",
    "                        label_y : label_y + label_height,\n",
    "                        label_x : label_x + label_width,\n",
    "                    ]\n",
    "                    try:\n",
    "                        cv2.addWeighted(label_patch, alpha, roi, 1 - alpha, 0, roi)\n",
    "                    except Exception:\n",
    "                        # Fallback to simpler label if blending fails\n",
    "                        cv2.putText(\n",
    "                            annotated_image,\n",
    "                            label,\n",
    "                            (label_x, label_y + label_height),\n",
    "                            font,\n",
    "                            font_scale,\n",
    "                            (0, 0, 0),\n",
    "                            thickness,\n",
    "                        )\n",
    "\n",
    "        # Save if path provided\n",
    "        if save_path:\n",
    "            save_dir = Path(save_path).parent\n",
    "            save_dir.mkdir(parents=True, exist_ok=True)\n",
    "            cv2.imwrite(save_path, cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        return annotated_image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inference_pipeline(\n",
    "    base_model_path: str = \"yolov8m.pt\",\n",
    "    weights_path: str = \"runs/detect/train29/weights/last.pt\",\n",
    "    **config_kwargs,\n",
    ") -> YOLOInference:\n",
    "    \"\"\"Creates an inference pipeline with specified weights.\"\"\"\n",
    "    consistency_config = ConsistencyConfig(\n",
    "        **{k: v for k, v in config_kwargs.items() if hasattr(ConsistencyConfig, k)}\n",
    "    )\n",
    "\n",
    "    detection_config = DetectionConfig(\n",
    "        **{k: v for k, v in config_kwargs.items() if hasattr(DetectionConfig, k)}\n",
    "    )\n",
    "\n",
    "    return YOLOInference(\n",
    "        model_path=base_model_path,\n",
    "        weights_path=weights_path,\n",
    "        consistency_config=consistency_config,\n",
    "        detection_config=detection_config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_config = DetectionConfig(\n",
    "    conf_threshold=0.3, iou_threshold=0.6, min_area=500, temporal_window=3\n",
    ")\n",
    "\n",
    "training_config = TrainingConfig(epochs=50, image_size=640, batch_size=16, dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 10:45:01,292 - INFO - Loaded model from yolov8m.pt\n"
     ]
    }
   ],
   "source": [
    "trainer = YOLOTrainer(\n",
    "    model_path=\"yolov8x.pt\",\n",
    "    training_config=training_config,\n",
    "    detection_config=detection_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.29 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.28 🚀 Python-3.10.13 torch-2.4.1.post302 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/home/carlos/developer/cow-project/data/yolo/data.yaml, epochs=50, time=None, patience=20, batch=16, imgsz=320, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train36, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.2, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.3, copy_paste=0.3, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train36\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 295 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train36', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/carlos/developer/cow-project/data/yolo/train/labels.cache... 6469 images, 1218 backgrounds, 0 corrupt: 100%|██████████| 7283/7283 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlos/miniconda3/envs/ml/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/carlos/developer/cow-project/data/yolo/valid/labels.cache... 1618 images, 144 backgrounds, 0 corrupt: 100%|██████████| 1658/1658 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train36/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 320 train, 320 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train36\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50       2.4G       1.24      1.117      1.393         47        320: 100%|██████████| 456/456 [01:20<00:00,  5.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.844      0.865      0.901      0.645\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      2.18G      1.242      1.045      1.397         29        320: 100%|██████████| 456/456 [01:13<00:00,  6.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.893      0.898      0.929      0.676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      2.18G      1.213      1.012      1.385         28        320: 100%|██████████| 456/456 [01:14<00:00,  6.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:11<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.868      0.898      0.894      0.634\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      2.19G      1.155     0.9598      1.352         25        320: 100%|██████████| 456/456 [01:13<00:00,  6.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:09<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.891      0.868       0.92      0.677\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      2.17G      1.117       0.92      1.325         11        320: 100%|██████████| 456/456 [01:15<00:00,  6.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:12<00:00,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.909      0.925      0.944      0.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      2.19G      1.084     0.8903      1.309         20        320: 100%|██████████| 456/456 [01:15<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:09<00:00,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.917      0.911      0.943      0.733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      2.18G      1.064     0.8738        1.3         16        320: 100%|██████████| 456/456 [01:18<00:00,  5.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:12<00:00,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.912       0.93      0.945      0.734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      2.19G      1.037     0.8416      1.284         44        320: 100%|██████████| 456/456 [01:15<00:00,  6.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:09<00:00,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.916      0.928       0.95       0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      2.17G       1.02     0.8248      1.269         17        320: 100%|██████████| 456/456 [01:14<00:00,  6.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.917      0.925      0.948      0.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      2.18G      1.008     0.8178      1.265         24        320: 100%|██████████| 456/456 [01:16<00:00,  5.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.914      0.927      0.946      0.747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      2.19G     0.9923     0.7995      1.256         27        320: 100%|██████████| 456/456 [01:13<00:00,  6.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.927      0.928      0.944      0.746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      2.18G     0.9893      0.798      1.256         47        320: 100%|██████████| 456/456 [01:14<00:00,  6.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:11<00:00,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.919       0.93      0.954      0.757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      2.19G     0.9729     0.7832      1.245         23        320: 100%|██████████| 456/456 [01:14<00:00,  6.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.923      0.933      0.951      0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      2.17G     0.9606     0.7685       1.24         25        320: 100%|██████████| 456/456 [01:14<00:00,  6.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636       0.92      0.939      0.953      0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      2.18G     0.9481     0.7618      1.232         32        320: 100%|██████████| 456/456 [01:14<00:00,  6.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.918      0.937      0.953      0.767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      2.19G     0.9438     0.7544      1.227         53        320: 100%|██████████| 456/456 [01:14<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.922      0.939      0.955      0.776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      2.17G     0.9375     0.7481      1.221         38        320: 100%|██████████| 456/456 [01:14<00:00,  6.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:11<00:00,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.917      0.943      0.955      0.774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      2.19G     0.9222     0.7361      1.214         32        320: 100%|██████████| 456/456 [01:15<00:00,  6.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:09<00:00,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.922      0.946      0.957      0.782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      2.18G     0.9215     0.7369       1.21         32        320: 100%|██████████| 456/456 [01:14<00:00,  6.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:11<00:00,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.916      0.945      0.954      0.783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      2.19G     0.9121     0.7296      1.207         44        320: 100%|██████████| 456/456 [01:13<00:00,  6.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.922      0.942      0.955      0.776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      2.19G     0.9098     0.7266      1.205         27        320: 100%|██████████| 456/456 [01:14<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.919      0.951      0.957      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      2.18G     0.9026     0.7143        1.2         24        320: 100%|██████████| 456/456 [01:18<00:00,  5.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.913      0.946      0.951       0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      2.17G     0.8929      0.711      1.197         11        320: 100%|██████████| 456/456 [01:15<00:00,  6.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.918      0.952      0.955       0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      2.19G     0.8886     0.7075      1.192         11        320: 100%|██████████| 456/456 [01:15<00:00,  6.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:11<00:00,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.921      0.946      0.954      0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      2.19G     0.8902     0.7016      1.196         12        320: 100%|██████████| 456/456 [01:13<00:00,  6.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.922      0.951      0.958      0.792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      2.18G     0.8781        0.7      1.188         44        320: 100%|██████████| 456/456 [01:14<00:00,  6.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:11<00:00,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636       0.92      0.949      0.956      0.788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      2.17G     0.8669      0.686      1.178         16        320: 100%|██████████| 456/456 [01:14<00:00,  6.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.916      0.949      0.956      0.793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      2.17G       0.87     0.6933      1.179         41        320: 100%|██████████| 456/456 [01:14<00:00,  6.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.917      0.944      0.957      0.796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      2.18G     0.8608     0.6855      1.175         35        320: 100%|██████████| 456/456 [01:17<00:00,  5.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.916      0.951      0.953      0.793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50      2.19G     0.8514     0.6812      1.175         41        320: 100%|██████████| 456/456 [01:16<00:00,  5.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.917      0.944      0.956        0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      2.19G     0.8491     0.6715       1.17         22        320: 100%|██████████| 456/456 [01:14<00:00,  6.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:11<00:00,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.918      0.952      0.958      0.797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      2.19G     0.8487     0.6679      1.172         44        320: 100%|██████████| 456/456 [01:14<00:00,  6.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.926      0.942      0.957      0.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      2.17G     0.8406     0.6683      1.165         31        320: 100%|██████████| 456/456 [01:15<00:00,  6.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:11<00:00,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.921      0.948      0.959      0.802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      2.18G     0.8357     0.6653      1.162         25        320: 100%|██████████| 456/456 [01:18<00:00,  5.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.921      0.948      0.955        0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      2.17G     0.8236     0.6563      1.158         30        320: 100%|██████████| 456/456 [01:13<00:00,  6.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:13<00:00,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.921      0.946      0.957        0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      2.16G     0.8231     0.6469      1.154         30        320: 100%|██████████| 456/456 [01:13<00:00,  6.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.918       0.95      0.957      0.807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      2.17G     0.8179     0.6524      1.157         47        320: 100%|██████████| 456/456 [01:14<00:00,  6.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.926      0.947      0.958      0.808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      2.19G     0.8135     0.6434      1.153         27        320: 100%|██████████| 456/456 [01:13<00:00,  6.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:11<00:00,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.923      0.948      0.958      0.807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      2.19G     0.8098     0.6443      1.147         30        320: 100%|██████████| 456/456 [01:14<00:00,  6.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.919      0.952      0.957      0.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50       2.2G     0.8071     0.6369      1.145         16        320: 100%|██████████| 456/456 [01:14<00:00,  6.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.919      0.949      0.958      0.808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      2.16G     0.6687     0.5156      1.062         16        320: 100%|██████████| 456/456 [01:14<00:00,  6.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:12<00:00,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.919      0.945      0.956      0.801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      2.15G     0.6576     0.5107      1.058          7        320: 100%|██████████| 456/456 [01:14<00:00,  6.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:09<00:00,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.917      0.951      0.957      0.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      2.15G     0.6442        0.5      1.047         19        320: 100%|██████████| 456/456 [01:15<00:00,  6.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:12<00:00,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.921      0.946      0.957      0.803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      2.15G     0.6367     0.4929      1.048         14        320: 100%|██████████| 456/456 [01:15<00:00,  6.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636       0.92      0.946      0.958      0.808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      2.15G     0.6336     0.4867      1.043          6        320: 100%|██████████| 456/456 [01:15<00:00,  6.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.922      0.942      0.959      0.809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      2.16G     0.6257     0.4846      1.037         14        320: 100%|██████████| 456/456 [01:14<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  17%|█▋        | 9/52 [00:01<00:06,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:11<00:00,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636       0.92      0.942      0.956      0.808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      2.15G     0.6159     0.4808      1.034         13        320: 100%|██████████| 456/456 [01:18<00:00,  5.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.921      0.945      0.959       0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      2.16G     0.6114     0.4801      1.032         15        320: 100%|██████████| 456/456 [01:13<00:00,  6.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:11<00:00,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.922      0.948      0.959      0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      2.16G     0.6074     0.4724      1.027         13        320: 100%|██████████| 456/456 [01:14<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.915      0.954      0.959      0.813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      2.16G     0.6011     0.4665      1.026         12        320: 100%|██████████| 456/456 [01:15<00:00,  6.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:08<00:00,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.925      0.943       0.96      0.814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 1.190 hours.\n",
      "Optimizer stripped from runs/detect/train36/weights/last.pt, 52.0MB\n",
      "Optimizer stripped from runs/detect/train36/weights/best.pt, 52.0MB\n",
      "\n",
      "Validating runs/detect/train36/weights/best.pt...\n",
      "Ultralytics 8.3.28 🚀 Python-3.10.13 torch-2.4.1.post302 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "Model summary (fused): 218 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [00:17<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1658       6636      0.924      0.942       0.96      0.806\n",
      "Speed: 0.0ms preprocess, 4.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train36\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model, results = trainer.train(\"../../data/yolo/data.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = YOLOInference(\"yolov8x.pt\", \"runs/detect/train36/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 detections\n"
     ]
    }
   ],
   "source": [
    "image, results = detector.predict_image(\n",
    "    \"../../data/day/4/2024-05-17-11-20-03_jpg.rf.d22ac7c5629960c1b011ed3a501cf535.jpg\",\n",
    "    save_path=\"output.jpg\",\n",
    ")\n",
    "\n",
    "print(f\"Found {len(results.boxes) if results.boxes is not None else 0} detections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples_per_class(\n",
    "    detector: YOLOInference,\n",
    "    data_dir: str = \"../../data\",\n",
    "    samples_per_class: int = 10,\n",
    "    figsize: tuple = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize detection results for samples from each class\n",
    "    \"\"\"\n",
    "    class_dirs = sorted([d for d in Path(data_dir).glob(\"day/*\") if d.is_dir()])\n",
    "    n_classes = len(class_dirs)\n",
    "\n",
    "    if figsize is None:\n",
    "        figsize = (20, 4 * len(class_dirs))\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    for class_idx, class_dir in enumerate(class_dirs):\n",
    "        print(f\"Processing class {class_dir.name}\")\n",
    "\n",
    "        all_samples = list(class_dir.rglob(\"*.jpg\"))\n",
    "        if not all_samples:\n",
    "            continue\n",
    "\n",
    "        selected_samples = random.sample(all_samples, min(10, len(all_samples)))\n",
    "        for sample_idx, sample in enumerate(selected_samples):\n",
    "            try:\n",
    "                image, results = detector.predict_image(str(sample))\n",
    "\n",
    "                ax = fig.add_subplot(n_classes, 10, class_idx * 10 + sample_idx + 1)\n",
    "\n",
    "                ax.imshow(image)\n",
    "                ax.set_title(f\"Class {class_dir.name}\\n{len(results.boxes)} dets\")\n",
    "                ax.axis(\"off\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {sample}: {e}\")\n",
    "                continue\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"outputs_inference\")\n",
    "output_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [04:30<00:00, 20.82s/it]\n"
     ]
    }
   ],
   "source": [
    "for class_dir in tqdm(list(Path(\"../../data/day\").glob(\"*\"))):\n",
    "    if not class_dir.is_dir():\n",
    "        continue\n",
    "\n",
    "    class_output = output_dir / class_dir.name\n",
    "    class_output.mkdir(exist_ok=True)\n",
    "\n",
    "    for sample in class_dir.rglob(\"*.jpg\"):\n",
    "        image, results = detector.predict_image(\n",
    "            str(sample), save_path=str(class_output / sample.name)\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
