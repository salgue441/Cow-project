{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import yaml\n",
    "from typing import Tuple, List, Dict\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CattleDataset:\n",
    "    \"\"\"\n",
    "    A dataset loader for YOLO8 format cattle images.\n",
    "    Implements modern TensorFlow data loading practices.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str,\n",
    "        img_size: Tuple[int, int] = (640, 640),\n",
    "        batch_size: int = 32,\n",
    "        augment: bool = True,\n",
    "    ):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.load_yaml_config()\n",
    "        self.augment = augment\n",
    "        if augment:\n",
    "            self.aug_pipeline = A.Compose(\n",
    "                [\n",
    "                    A.RandomBrightnessContrast(p=0.5),\n",
    "                    A.HorizontalFlip(p=0.5),\n",
    "                    A.RandomRotate90(p=0.5),\n",
    "                    A.Blur(blur_limit=3, p=0.3),\n",
    "                ],\n",
    "                bbox_params=A.BboxParams(format=\"yolo\", label_fields=[\"class_labels\"]),\n",
    "            )\n",
    "\n",
    "    def load_yaml_config(self):\n",
    "        yaml_path = self.data_dir / \"dataset.yaml\"\n",
    "        with open(yaml_path, \"r\") as f:\n",
    "            self.config = yaml.safe_load(f)\n",
    "\n",
    "        self.class_names = self.config[\"names\"]\n",
    "        self.num_classes = len(self.class_names)\n",
    "\n",
    "    def load_image(self, image_path: str) -> tf.Tensor:\n",
    "        img = tf.io.read_file(image_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, self.img_size)\n",
    "        img = tf.cast(img, tf.float32) / 255.0\n",
    "\n",
    "        return img\n",
    "\n",
    "    def load_labels(self, label_path: str) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "        try:\n",
    "            with open(label_path, \"r\") as f:\n",
    "                labels = np.array(\n",
    "                    [x.split() for x in f.read().splitlines()], dtype=np.float32\n",
    "                )\n",
    "        except Exception:\n",
    "            labels = np.zeros((0, 5), dtype=np.float32)\n",
    "\n",
    "        if len(labels):\n",
    "            boxes = labels[:, 1:]\n",
    "            classes = labels[:, 0].astype(np.int32)\n",
    "\n",
    "        else:\n",
    "            boxes = np.zeros((0, 4), dtype=np.float32)\n",
    "            classes = np.zeros((0,), dtype=np.int32)\n",
    "\n",
    "        return boxes, classes\n",
    "\n",
    "    def create_dataset(self, split: str = \"train\") -> tf.data.Dataset:\n",
    "        img_paths = sorted(list((self.data_dir / split / \"images\").glob(\"*.jpg\")))\n",
    "        label_paths = [\n",
    "            str(p).replace(\"images\", \"labels\").replace(\".jpg\", \".txt\")\n",
    "            for p in img_paths\n",
    "        ]\n",
    "\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            ([str(p) for p in img_paths], label_paths)\n",
    "        )\n",
    "\n",
    "        dataset = dataset.map(\n",
    "            lambda img_path, label_path: tf.py_function(\n",
    "                self._load_sample,\n",
    "                [img_path, label_path],\n",
    "                [tf.float32, tf.float32, tf.int32],\n",
    "            ),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE,\n",
    "        )\n",
    "\n",
    "        dataset = dataset.map(\n",
    "            lambda img, boxes, classes: (\n",
    "                tf.ensure_shape(img, (self.img_size[0], self.img_size[1], 3)),\n",
    "                tf.ensure_shape(boxes, (None, 4)),\n",
    "                tf.ensure_shape(classes, (None,)),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        dataset = dataset.batch(self.batch_size)\n",
    "        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def _load_sample(\n",
    "        self, img_path: str, label_path: str\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        img_path = img_path.numpy().decode(\"utf-8\")\n",
    "        label_path = label_path.numpy().decode(\"utf-8\")\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        boxes, classes = self.load_labels(label_path)\n",
    "\n",
    "        if self.augment and len(boxes):\n",
    "            transformed = self.aug_pipeline(\n",
    "                image=img, bboxes=boxes, class_labels=classes\n",
    "            )\n",
    "            img = transformed[\"image\"]\n",
    "            boxes = np.array(transformed[\"bboxes\"])\n",
    "            classes = np.array(transformed[\"class_labels\"])\n",
    "\n",
    "        img = cv2.resize(img, self.img_size)\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "\n",
    "        return img, boxes, classes\n",
    "\n",
    "    def visualize_batch(\n",
    "        self, batch: Tuple[tf.Tensor, tf.Tensor, tf.Tensor], num_samples: int = 4\n",
    "    ):\n",
    "        images, boxes, classes = batch\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "        axes = axes.ravel()\n",
    "\n",
    "        for idx in range(min(num_samples, len(images))):\n",
    "            img = images[idx].numpy()\n",
    "            img_boxes = boxes[idx].numpy()\n",
    "            img_classes = classes[idx].numpy()\n",
    "\n",
    "            img_draw = img.copy()\n",
    "            for box, cls in zip(img_boxes, img_classes):\n",
    "                x, y, w, h = box\n",
    "                x1 = int((x - w / 2) * self.img_size[1])\n",
    "                y1 = int((y - h / 2) * self.img_size[0])\n",
    "                x2 = int((x + w / 2) * self.img_size[1])\n",
    "                y2 = int((y + h / 2) * self.img_size[0])\n",
    "\n",
    "                cv2.rectangle(img_draw, (x1, y1), (x2, y2), (1, 0, 0), 2)\n",
    "                cv2.putText(\n",
    "                    img_draw,\n",
    "                    self.class_names[cls],\n",
    "                    (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    (1, 0, 0),\n",
    "                    2,\n",
    "                )\n",
    "\n",
    "            axes[idx].imshow(img_draw)\n",
    "            axes[idx].axis(\"off\")\n",
    "            axes[idx].set_title(f\"Sample {idx+1}\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO Model Creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOLoss(tf.keras.losses.Loss):\n",
    "    \"\"\"Custom YOLO loss implementation\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int, anchors: np.ndarray):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.anchors = anchors\n",
    "        self.ignore_thresh = 0.5\n",
    "        self.lambda_coord = 5.0\n",
    "        self.lambda_noobj = 0.5\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # Extract components from predictions\n",
    "        pred_xy = y_pred[..., 0:2]\n",
    "        pred_wh = y_pred[..., 2:4]\n",
    "        pred_conf = y_pred[..., 4:5]\n",
    "        pred_class = y_pred[..., 5:]\n",
    "\n",
    "        # Extract components from ground truth\n",
    "        true_xy = y_true[..., 0:2]\n",
    "        true_wh = y_true[..., 2:4]\n",
    "        true_conf = y_true[..., 4:5]\n",
    "        true_class = y_true[..., 5:]\n",
    "\n",
    "        # Calculate masks for objects and no-objects\n",
    "        object_mask = true_conf\n",
    "        no_object_mask = 1 - object_mask\n",
    "\n",
    "        # Calculate losses\n",
    "        xy_loss = self.lambda_coord * object_mask * tf.square(true_xy - pred_xy)\n",
    "        wh_loss = (\n",
    "            self.lambda_coord\n",
    "            * object_mask\n",
    "            * tf.square(\n",
    "                tf.sqrt(true_wh) - tf.sqrt(tf.clip_by_value(pred_wh, 1e-10, 1.0))\n",
    "            )\n",
    "        )\n",
    "\n",
    "        conf_loss = object_mask * tf.square(\n",
    "            1 - pred_conf\n",
    "        ) + self.lambda_noobj * no_object_mask * tf.square(0 - pred_conf)\n",
    "\n",
    "        class_loss = (\n",
    "            object_mask\n",
    "            * tf.keras.losses.categorical_crossentropy(\n",
    "                true_class, pred_class, from_logits=True\n",
    "            )[..., tf.newaxis]\n",
    "        )\n",
    "\n",
    "        return tf.reduce_sum(xy_loss + wh_loss + conf_loss + class_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOBlock(tf.keras.layers.Layer):\n",
    "    \"\"\"YOLO convolutional block\"\"\"\n",
    "\n",
    "    def __init__(self, filters: int, kernel_size: int, strides: int = 1):\n",
    "        super().__init__()\n",
    "        self.conv = tf.keras.layers.Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding=\"same\",\n",
    "            use_bias=False,\n",
    "        )\n",
    "        self.bn = tf.keras.layers.BatchNormalization()\n",
    "        self.activation = tf.keras.layers.LeakyReLU(alpha=0.1)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "\n",
    "        return self.activation(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes: int, input_shape: Tuple[int, int, int]):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Backbone\n",
    "        self.backbone = [\n",
    "            YOLOBlock(32, 3),\n",
    "            tf.keras.layers.MaxPooling2D(2, 2),\n",
    "            YOLOBlock(64, 3),\n",
    "            tf.keras.layers.MaxPooling2D(2, 2),\n",
    "            YOLOBlock(128, 3),\n",
    "            YOLOBlock(64, 1),\n",
    "            YOLOBlock(128, 3),\n",
    "            tf.keras.layers.MaxPooling2D(2, 2),\n",
    "            YOLOBlock(256, 3),\n",
    "            YOLOBlock(128, 1),\n",
    "            YOLOBlock(256, 3),\n",
    "            tf.keras.layers.MaxPooling2D(2, 2),\n",
    "            YOLOBlock(512, 3),\n",
    "            YOLOBlock(256, 1),\n",
    "            YOLOBlock(512, 3),\n",
    "            YOLOBlock(256, 1),\n",
    "            YOLOBlock(512, 3),\n",
    "        ]\n",
    "\n",
    "        # Detection head\n",
    "        self.head = [\n",
    "            YOLOBlock(1024, 3),\n",
    "            YOLOBlock(512, 1),\n",
    "            YOLOBlock(1024, 3),\n",
    "            YOLOBlock(512, 1),\n",
    "            YOLOBlock(1024, 3),\n",
    "            tf.keras.layers.Conv2D(3 * (5 + num_classes), 1, padding=\"same\"),\n",
    "        ]\n",
    "\n",
    "    def call(self, x):\n",
    "        for layer in self.backbone:\n",
    "            x = layer(x)\n",
    "\n",
    "        for layer in self.head:\n",
    "            x = layer(x)\n",
    "\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        output_shape = tf.shape(x)[1:3]\n",
    "        output = tf.reshape(\n",
    "            x, [batch_size, output_shape[0], output_shape[1], 3, 5 + self.num_classes]\n",
    "        )\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOTrainer:\n",
    "    \"\"\"YOLO model trainer\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int,\n",
    "        input_shape: Tuple[int, int, int] = (640, 640, 3),\n",
    "        learning_rate: float = 1e-4,\n",
    "        weight_decay: float = 1e-4,\n",
    "    ):\n",
    "        self.num_classes = num_classes\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "        self.model = YOLO(num_classes, input_shape)\n",
    "        self.optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=learning_rate, weight_decay=weight_decay\n",
    "        )\n",
    "\n",
    "        self.anchors = np.array(\n",
    "            [\n",
    "                [[10, 13], [16, 30], [33, 23]],\n",
    "                [[30, 61], [62, 45], [59, 119]],\n",
    "                [[116, 90], [156, 198], [373, 326]],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.loss_fn = YOLOLoss(num_classes, self.anchors)\n",
    "        self.train_loss = tf.keras.metrics.Mean(\"train_loss\", dtype=tf.float32)\n",
    "        self.val_loss = tf.keras.metrics.Mean(\"val_loss\", dtype=tf.float32)\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, images, labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.model(images, training=True)\n",
    "            loss = self.loss_fn(labels, predictions)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "\n",
    "        self.train_loss.update_state(loss)\n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def val_step(self, images, labels):\n",
    "        predictions = self.model(images, training=False)\n",
    "        loss = self.loss_fn(labels, predictions)\n",
    "        self.val_loss.update_state(loss)\n",
    "        return loss\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        train_dataset: tf.data.Dataset,\n",
    "        val_dataset: tf.data.Dataset,\n",
    "        epochs: int = 100,\n",
    "        callbacks: List[tf.keras.callbacks.Callback] = None,\n",
    "    ):\n",
    "        if callbacks is None:\n",
    "            callbacks = [\n",
    "                tf.keras.callbacks.ModelCheckpoint(\n",
    "                    \"yolo_cattle_{epoch:02d}.h5\",\n",
    "                    save_best_only=True,\n",
    "                    monitor=\"val_loss\",\n",
    "                ),\n",
    "                tf.keras.callbacks.EarlyStopping(patience=10, monitor=\"val_loss\"),\n",
    "                tf.keras.callbacks.TensorBoard(log_dir=\"./logs\"),\n",
    "            ]\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.train_loss.reset_states()\n",
    "            self.val_loss.reset_states()\n",
    "\n",
    "            for images, labels in train_dataset:\n",
    "                loss = self.train_step(images, labels)\n",
    "\n",
    "            for images, labels in val_dataset:\n",
    "                loss = self.val_step(images, labels)\n",
    "\n",
    "            # Log metrics\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1}, \"\n",
    "                f\"Train Loss: {self.train_loss.result():.4f}, \"\n",
    "                f\"Val Loss: {self.val_loss.result():.4f}\"\n",
    "            )\n",
    "\n",
    "            # Execute callbacks\n",
    "            for callback in callbacks:\n",
    "                callback.on_epoch_end(\n",
    "                    epoch,\n",
    "                    {\n",
    "                        \"loss\": self.train_loss.result(),\n",
    "                        \"val_loss\": self.val_loss.result(),\n",
    "                    },\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CattleDataset(\n",
    "    data_dir=\"../../data/yolo\", img_size=(640, 640), batch_size=32, augment=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset.create_dataset(split=\"train\")\n",
    "for batch in train_ds.take(1):\n",
    "    dataset.visualize_batch(batch, num_samples=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = dataset.create_dataset(split=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = YOLOTrainer(\n",
    "    num_classes=dataset.num_classes, input_shape=(640, 640, 3), learning_rate=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(train_ds, val_ds, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
