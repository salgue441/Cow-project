# Spark Configuration File

# Application Settings
spark.app.name ML-PySpark-Project

# Master URL
spark.master spark://spark-master:7077

# Executor Settings
spark.executor.memory 4g
spark.executor.cores 2
spark.executor.instances 2

# Driver Settings
spark.driver.memory 4g
spark.driver.maxResultSize 2g

# Shuffle Settings
spark.shuffle.file.buffer 64k
spark.shuffle.compress true

# Network Settings
spark.network.timeout 120s
spark.rpc.message.maxSize 256

# Memory Settings
spark.memory.fraction 0.6
spark.memory.storageFraction 0.5

# Serialization Settings
spark.serializer org.apache.spark.serializer.KryoSerializer
spark.kryoserializer.buffer.max 1024m

# SQL Settings
spark.sql.shuffle.partitions 100
spark.sql.autoBroadcastJoinThreshold 10m

# Logging Settings
spark.eventLog.enabled true
spark.eventLog.dir /tmp/spark-events

# Python Settings
spark.pyspark.python python3
spark.pyspark.driver.python python3

# ML-specific Settings
spark.ml.pipelineModel.writeMode overwrite

# History Server Settings
spark.history.fs.logDirectory /tmp/spark-events
spark.history.ui.port 18080

# Dynamic Allocation (if using)
# spark.dynamicAllocation.enabled            true
# spark.dynamicAllocation.minExecutors       1
# spark.dynamicAllocation.maxExecutors       5
# spark.dynamicAllocation.initialExecutors   1

# Speculative Execution (if needed)
# spark.speculation                          true
# spark.speculation.multiplier               1.5

# Compression and Spill Settings
spark.rdd.compress true
spark.shuffle.spill.compress true
